
/**
 * @file ops.h
 * TensorFlow raw_ops mappings
 */

#ifndef CPPFLOW2_RAW_OPS_H
#define CPPFLOW2_RAW_OPS_H

#include <tensorflow/c/eager/c_api.h>
#include <tensorflow/c/tf_datatype.h>
#include <tensorflow/c/tf_tensor.h>

#include "tensor.h"
#include "datatype.h"

#include <cstdint>
#include <vector>
#include <limits>
#include <algorithm>


namespace cppflow::ops {

inline void Abort(const std::string& error_msg="", bool exit_without_error=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Abort", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "error_msg", (void*) error_msg.c_str(), error_msg.size());
    TFE_OpSetAttrBool(op.get(), "exit_without_error", (unsigned char)exit_without_error);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Abs(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Abs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AccumulateNV2(const std::vector<Tensor>& inputs, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulateNV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void AccumulatorApplyGradient(const Tensor& handle, const Tensor& local_step, const Tensor& gradient, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorApplyGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), local_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor AccumulatorNumAccumulated(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorNumAccumulated", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void AccumulatorSetGlobalStep(const Tensor& handle, const Tensor& new_global_step) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorSetGlobalStep", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), new_global_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor AccumulatorTakeGradient(const Tensor& handle, const Tensor& num_required, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AccumulatorTakeGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_required.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Acos(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Acos", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Acosh(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Acosh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Add(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Add", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AddManySparseToTensorsMap(const Tensor& sparse_indices, const Tensor& sparse_values, const Tensor& sparse_shape, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddManySparseToTensorsMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AddN(const std::vector<Tensor>& inputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AddSparseToTensorsMap(const Tensor& sparse_indices, const Tensor& sparse_values, const Tensor& sparse_shape, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddSparseToTensorsMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AddV2(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AddV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AdjustContrast(const Tensor& images, const Tensor& contrast_factor, const Tensor& min_value, const Tensor& max_value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustContrast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), contrast_factor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AdjustContrastv2(const Tensor& images, const Tensor& contrast_factor) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustContrastv2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), contrast_factor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AdjustHue(const Tensor& images, const Tensor& delta) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustHue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AdjustSaturation(const Tensor& images, const Tensor& scale) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AdjustSaturation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor All(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "All", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> AllCandidateSampler(const Tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AllCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor AllToAll(const Tensor& input, const Tensor& group_assignment, int64_t concat_dimension, int64_t split_dimension, int64_t split_count) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AllToAll", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_assignment.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "concat_dimension", concat_dimension);
    TFE_OpSetAttrInt(op.get(), "split_dimension", split_dimension);
    TFE_OpSetAttrInt(op.get(), "split_count", split_count);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Angle(const Tensor& input, datatype Tout=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Angle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AnonymousIterator(const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> AnonymousIteratorV2(const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousIteratorV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> AnonymousMemoryCache() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMemoryCache", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> AnonymousMultiDeviceIterator(const std::vector< std::string>& devices, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousMultiDeviceIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> devices_sizes; devices_sizes.reserve(devices.size());
    std::transform(devices.begin(), devices.end(), std::back_inserter(devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "devices", reinterpret_cast<const void *const *>(devices.data()), devices_sizes.data(), devices.size());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> AnonymousRandomSeedGenerator(const Tensor& seed, const Tensor& seed2) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousRandomSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> AnonymousSeedGenerator(const Tensor& seed, const Tensor& seed2, const Tensor& reshuffle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AnonymousSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reshuffle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Any(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Any", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAdaMax(const Tensor& var, const Tensor& m, const Tensor& v, const Tensor& beta1_power, const Tensor& lr, const Tensor& beta1, const Tensor& beta2, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdaMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAdadelta(const Tensor& var, const Tensor& accum, const Tensor& accum_update, const Tensor& lr, const Tensor& rho, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAdagradDA(const Tensor& var, const Tensor& gradient_accumulator, const Tensor& gradient_squared_accumulator, const Tensor& grad, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& global_step, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAdagradV2(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& epsilon, const Tensor& grad, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAdam(const Tensor& var, const Tensor& m, const Tensor& v, const Tensor& beta1_power, const Tensor& beta2_power, const Tensor& lr, const Tensor& beta1, const Tensor& beta2, const Tensor& epsilon, const Tensor& grad, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAdam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyAddSign(const Tensor& var, const Tensor& m, const Tensor& lr, const Tensor& alpha, const Tensor& sign_decay, const Tensor& beta, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyAddSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyCenteredRMSProp(const Tensor& var, const Tensor& mg, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyFtrl(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyFtrlV2(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& l2_shrinkage, const Tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyGradientDescent(const Tensor& var, const Tensor& alpha, const Tensor& delta, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyMomentum(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& momentum, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyPowerSign(const Tensor& var, const Tensor& m, const Tensor& lr, const Tensor& logbase, const Tensor& sign_decay, const Tensor& beta, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyPowerSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), logbase.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyProximalAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyProximalGradientDescent(const Tensor& var, const Tensor& alpha, const Tensor& l1, const Tensor& l2, const Tensor& delta, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApplyRMSProp(const Tensor& var, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ApproximateEqual(const Tensor& x, const Tensor& y, float tolerance=1.0000e-05) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ApproximateEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "tolerance", tolerance);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ArgMax(const Tensor& input, const Tensor& dimension, datatype Tidx=static_cast<datatype>(3), datatype output_type=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ArgMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dimension.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ArgMin(const Tensor& input, const Tensor& dimension, datatype Tidx=static_cast<datatype>(3), datatype output_type=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ArgMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dimension.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AsString(const Tensor& input, int64_t precision=-1, bool scientific=false, bool shortest=false, int64_t width=-1, const std::string& fill="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AsString", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "precision", precision);
    TFE_OpSetAttrBool(op.get(), "scientific", (unsigned char)scientific);
    TFE_OpSetAttrBool(op.get(), "shortest", (unsigned char)shortest);
    TFE_OpSetAttrInt(op.get(), "width", width);
    TFE_OpSetAttrString(op.get(), "fill", (void*) fill.c_str(), fill.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Asin(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Asin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Asinh(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Asinh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void Assert(const Tensor& condition, const std::vector<Tensor>& data, int64_t summarize=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Assert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), condition.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), data.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "summarize", summarize);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor AssertCardinalityDataset(const Tensor& input_dataset, const Tensor& cardinality, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssertCardinalityDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cardinality.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AssertNextDataset(const Tensor& input_dataset, const Tensor& transformations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssertNextDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transformations.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Assign(const Tensor& ref, const Tensor& value, bool validate_shape=true, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Assign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "validate_shape", (unsigned char)validate_shape);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AssignAdd(const Tensor& ref, const Tensor& value, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void AssignAddVariableOp(const Tensor& resource, const Tensor& value, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignAddVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor AssignSub(const Tensor& ref, const Tensor& value, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void AssignSubVariableOp(const Tensor& resource, const Tensor& value, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignSubVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void AssignVariableOp(const Tensor& resource, const Tensor& value, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AssignVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Atan(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Atan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Atan2(const Tensor& y, const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Atan2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Atanh(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Atanh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AudioSpectrogram(const Tensor& input, int64_t window_size, int64_t stride, bool magnitude_squared=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AudioSpectrogram", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "window_size", window_size);
    TFE_OpSetAttrInt(op.get(), "stride", stride);
    TFE_OpSetAttrBool(op.get(), "magnitude_squared", (unsigned char)magnitude_squared);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AudioSummary(const Tensor& tag, const Tensor& input_tensor, float sample_rate, int64_t max_outputs=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AudioSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "sample_rate", sample_rate);
    TFE_OpSetAttrInt(op.get(), "max_outputs", max_outputs);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AudioSummaryV2(const Tensor& tag, const Tensor& input_tensor, const Tensor& sample_rate, int64_t max_outputs=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AudioSummaryV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_outputs", max_outputs);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AutoShardDataset(const Tensor& input_dataset, const Tensor& num_workers, const Tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t auto_shard_policy=0, int64_t num_replicas=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AutoShardDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_workers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "auto_shard_policy", auto_shard_policy);
    TFE_OpSetAttrInt(op.get(), "num_replicas", num_replicas);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AvgPool(const Tensor& value, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AvgPool3D(const Tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPool3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AvgPool3DGrad(const Tensor& orig_input_shape, const Tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPool3DGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor AvgPoolGrad(const Tensor& orig_input_shape, const Tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "AvgPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BandedTriangularSolve(const Tensor& matrix, const Tensor& rhs, bool lower=true, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BandedTriangularSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "lower", (unsigned char)lower);
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Barrier(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Barrier", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void BarrierClose(const Tensor& handle, bool cancel_pending_enqueues=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "cancel_pending_enqueues", (unsigned char)cancel_pending_enqueues);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor BarrierIncompleteSize(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierIncompleteSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void BarrierInsertMany(const Tensor& handle, const Tensor& keys, const Tensor& values, int64_t component_index) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierInsertMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "component_index", component_index);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor BarrierReadySize(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierReadySize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BarrierTakeMany(const Tensor& handle, const Tensor& num_elements, const std::vector<datatype>& component_types, bool allow_small_batch=false, bool wait_for_incomplete=false, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BarrierTakeMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_elements.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrBool(op.get(), "allow_small_batch", (unsigned char)allow_small_batch);
    TFE_OpSetAttrBool(op.get(), "wait_for_incomplete", (unsigned char)wait_for_incomplete);
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> Batch(const std::vector<Tensor>& in_tensors, int64_t num_batch_threads, int64_t max_batch_size, int64_t batch_timeout_micros, const std::vector<int64_t>& allowed_batch_sizes, int64_t grad_timeout_micros, int64_t max_enqueued_batches=10, const std::string& container="", const std::string& shared_name="", const std::string& batching_queue="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Batch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> in_tensors_handles; in_tensors_handles.reserve(in_tensors.size());
    std::transform(in_tensors.begin(), in_tensors.end(), std::back_inserter(in_tensors_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), in_tensors_handles.data(), in_tensors.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_batch_threads", num_batch_threads);
    TFE_OpSetAttrInt(op.get(), "max_batch_size", max_batch_size);
    TFE_OpSetAttrInt(op.get(), "batch_timeout_micros", batch_timeout_micros);
    TFE_OpSetAttrIntList(op.get(), "allowed_batch_sizes", allowed_batch_sizes.data(), allowed_batch_sizes.size());
    TFE_OpSetAttrInt(op.get(), "grad_timeout_micros", grad_timeout_micros);
    TFE_OpSetAttrInt(op.get(), "max_enqueued_batches", max_enqueued_batches);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "batching_queue", (void*) batching_queue.c_str(), batching_queue.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BatchCholesky(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchCholesky", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchCholeskyGrad(const Tensor& l, const Tensor& grad) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchCholeskyGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), l.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchDataset(const Tensor& input_dataset, const Tensor& batch_size, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchDatasetV2(const Tensor& input_dataset, const Tensor& batch_size, const Tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool parallel_copy=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "parallel_copy", (unsigned char)parallel_copy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchFFT(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchFFT2D(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchFFT3D(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchIFFT(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchIFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchIFFT2D(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchIFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchIFFT3D(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchIFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatMul(const Tensor& x, const Tensor& y, bool adj_x=false, bool adj_y=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adj_x", (unsigned char)adj_x);
    TFE_OpSetAttrBool(op.get(), "adj_y", (unsigned char)adj_y);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatMulV2(const Tensor& x, const Tensor& y, bool adj_x=false, bool adj_y=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatMulV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adj_x", (unsigned char)adj_x);
    TFE_OpSetAttrBool(op.get(), "adj_y", (unsigned char)adj_y);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixBandPart(const Tensor& input, const Tensor& num_lower, const Tensor& num_upper) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixBandPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_lower.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_upper.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixDeterminant(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixDeterminant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixDiag(const Tensor& diagonal) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixDiagPart(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixDiagPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixInverse(const Tensor& input, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixInverse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixSetDiag(const Tensor& input, const Tensor& diagonal) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixSetDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixSolve(const Tensor& matrix, const Tensor& rhs, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixSolveLs(const Tensor& matrix, const Tensor& rhs, const Tensor& l2_regularizer, bool fast=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixSolveLs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_regularizer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "fast", (unsigned char)fast);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchMatrixTriangularSolve(const Tensor& matrix, const Tensor& rhs, bool lower=true, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchMatrixTriangularSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "lower", (unsigned char)lower);
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchNormWithGlobalNormalization(const Tensor& t, const Tensor& m, const Tensor& v, const Tensor& beta, const Tensor& gamma, float variance_epsilon, bool scale_after_normalization) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchNormWithGlobalNormalization", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrBool(op.get(), "scale_after_normalization", (unsigned char)scale_after_normalization);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BatchNormWithGlobalNormalizationGrad(const Tensor& t, const Tensor& m, const Tensor& v, const Tensor& gamma, const Tensor& backprop, float variance_epsilon, bool scale_after_normalization) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchNormWithGlobalNormalizationGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrBool(op.get(), "scale_after_normalization", (unsigned char)scale_after_normalization);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BatchSelfAdjointEig(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchSelfAdjointEig", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BatchSelfAdjointEigV2(const Tensor& input, bool compute_v=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchSelfAdjointEigV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_v", (unsigned char)compute_v);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BatchSvd(const Tensor& input, bool compute_uv=true, bool full_matrices=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchSvd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_uv", (unsigned char)compute_uv);
    TFE_OpSetAttrBool(op.get(), "full_matrices", (unsigned char)full_matrices);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BatchToSpace(const Tensor& input, const Tensor& crops, int64_t block_size, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchToSpace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crops.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BatchToSpaceND(const Tensor& input, const Tensor& block_shape, const Tensor& crops, datatype Tblock_shape=static_cast<datatype>(3), datatype Tcrops=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BatchToSpaceND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crops.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tblock_shape", Tblock_shape);
    TFE_OpSetAttrType(op.get(), "Tcrops", Tcrops);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselI0(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselI0e(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI0e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselI1(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselI1e(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselI1e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselJ0(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselJ0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselJ1(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselJ1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselK0(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselK0e(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK0e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselK1(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselK1e(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselK1e", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselY0(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselY0", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BesselY1(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BesselY1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Betainc(const Tensor& a, const Tensor& b, const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Betainc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BiasAdd(const Tensor& value, const Tensor& bias, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BiasAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BiasAddGrad(const Tensor& out_backprop, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BiasAddGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BiasAddV1(const Tensor& value, const Tensor& bias) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BiasAddV1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Bincount(const Tensor& arr, const Tensor& size, const Tensor& weights) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Bincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), arr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Bitcast(const Tensor& input, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Bitcast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BitwiseAnd(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BitwiseAnd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BitwiseOr(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BitwiseOr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BitwiseXor(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BitwiseXor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BlockLSTM(const Tensor& seq_len_max, const Tensor& x, const Tensor& cs_prev, const Tensor& h_prev, const Tensor& w, const Tensor& wci, const Tensor& wcf, const Tensor& wco, const Tensor& b, float forget_bias=1.0000e+00, float cell_clip=3.0000e+00, bool use_peephole=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTM", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "forget_bias", forget_bias);
    TFE_OpSetAttrFloat(op.get(), "cell_clip", cell_clip);
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    constexpr auto __kNumOutputs = 7;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BlockLSTMGrad(const Tensor& seq_len_max, const Tensor& x, const Tensor& cs_prev, const Tensor& h_prev, const Tensor& w, const Tensor& wci, const Tensor& wcf, const Tensor& wco, const Tensor& b, const Tensor& i, const Tensor& cs, const Tensor& f, const Tensor& o, const Tensor& ci, const Tensor& co, const Tensor& h, const Tensor& cs_grad, const Tensor& h_grad, bool use_peephole) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTMGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), f.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), o.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), co.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    constexpr auto __kNumOutputs = 8;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BlockLSTMGradV2(const Tensor& seq_len_max, const Tensor& x, const Tensor& cs_prev, const Tensor& h_prev, const Tensor& w, const Tensor& wci, const Tensor& wcf, const Tensor& wco, const Tensor& b, const Tensor& i, const Tensor& cs, const Tensor& f, const Tensor& o, const Tensor& ci, const Tensor& co, const Tensor& h, const Tensor& cs_grad, const Tensor& h_grad, bool use_peephole) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTMGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), f.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), o.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), co.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    constexpr auto __kNumOutputs = 8;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BlockLSTMV2(const Tensor& seq_len_max, const Tensor& x, const Tensor& cs_prev, const Tensor& h_prev, const Tensor& w, const Tensor& wci, const Tensor& wcf, const Tensor& wco, const Tensor& b, float cell_clip=0.0000e+00, bool use_peephole=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BlockLSTMV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seq_len_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "cell_clip", cell_clip);
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    constexpr auto __kNumOutputs = 7;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BoostedTreesAggregateStats(const Tensor& node_ids, const Tensor& gradients, const Tensor& hessians, const Tensor& feature, int64_t max_splits, int64_t num_buckets) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesAggregateStats", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hessians.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BoostedTreesBucketize(const std::vector<Tensor>& float_values, const std::vector<Tensor>& bucket_boundaries) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesBucketize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> float_values_handles; float_values_handles.reserve(float_values.size());
    std::transform(float_values.begin(), float_values.end(), std::back_inserter(float_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), float_values_handles.data(), float_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucket_boundaries_handles; bucket_boundaries_handles.reserve(bucket_boundaries.size());
    std::transform(bucket_boundaries.begin(), bucket_boundaries.end(), std::back_inserter(bucket_boundaries_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), bucket_boundaries_handles.data(), bucket_boundaries.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", float_values.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BoostedTreesCalculateBestFeatureSplit(const Tensor& node_id_range, const Tensor& stats_summary, const Tensor& l1, const Tensor& l2, const Tensor& tree_complexity, const Tensor& min_node_weight, int64_t logits_dimension, const std::string& split_type="inequality") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCalculateBestFeatureSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);
    TFE_OpSetAttrString(op.get(), "split_type", (void*) split_type.c_str(), split_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 7;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BoostedTreesCalculateBestFeatureSplitV2(const Tensor& node_id_range, const std::vector<Tensor>& stats_summaries_list, const Tensor& split_types, const Tensor& candidate_feature_ids, const Tensor& l1, const Tensor& l2, const Tensor& tree_complexity, const Tensor& min_node_weight, int64_t logits_dimension) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCalculateBestFeatureSplitV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> stats_summaries_list_handles; stats_summaries_list_handles.reserve(stats_summaries_list.size());
    std::transform(stats_summaries_list.begin(), stats_summaries_list.end(), std::back_inserter(stats_summaries_list_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), stats_summaries_list_handles.data(), stats_summaries_list.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), split_types.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), candidate_feature_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", stats_summaries_list.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    constexpr auto __kNumOutputs = 8;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BoostedTreesCalculateBestGainsPerFeature(const Tensor& node_id_range, const std::vector<Tensor>& stats_summary_list, const Tensor& l1, const Tensor& l2, const Tensor& tree_complexity, const Tensor& min_node_weight, int64_t max_splits) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCalculateBestGainsPerFeature", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> stats_summary_list_handles; stats_summary_list_handles.reserve(stats_summary_list.size());
    std::transform(stats_summary_list.begin(), stats_summary_list.end(), std::back_inserter(stats_summary_list_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), stats_summary_list_handles.data(), stats_summary_list.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_features", stats_summary_list.size());

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BoostedTreesCenterBias(const Tensor& tree_ensemble_handle, const Tensor& mean_gradients, const Tensor& mean_hessians, const Tensor& l1, const Tensor& l2) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCenterBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean_gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean_hessians.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void BoostedTreesCreateEnsemble(const Tensor& tree_ensemble_handle, const Tensor& stamp_token, const Tensor& tree_ensemble_serialized) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCreateEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stamp_token.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_ensemble_serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void BoostedTreesCreateQuantileStreamResource(const Tensor& quantile_stream_resource_handle, const Tensor& epsilon, const Tensor& num_streams, int64_t max_elements=1099511627776) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesCreateQuantileStreamResource", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_streams.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_elements", max_elements);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void BoostedTreesDeserializeEnsemble(const Tensor& tree_ensemble_handle, const Tensor& stamp_token, const Tensor& tree_ensemble_serialized) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesDeserializeEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stamp_token.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_ensemble_serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor BoostedTreesEnsembleResourceHandleOp(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesEnsembleResourceHandleOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BoostedTreesExampleDebugOutputs(const Tensor& tree_ensemble_handle, const std::vector<Tensor>& bucketized_features, int64_t logits_dimension) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesExampleDebugOutputs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_handles; bucketized_features_handles.reserve(bucketized_features.size());
    std::transform(bucketized_features.begin(), bucketized_features.end(), std::back_inserter(bucketized_features_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), bucketized_features_handles.data(), bucketized_features.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bucketized_features", bucketized_features.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BoostedTreesFlushQuantileSummaries(const Tensor& quantile_stream_resource_handle, int64_t num_features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesFlushQuantileSummaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", num_features);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BoostedTreesGetEnsembleStates(const Tensor& tree_ensemble_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesGetEnsembleStates", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BoostedTreesMakeQuantileSummaries(const std::vector<Tensor>& float_values, const Tensor& example_weights, const Tensor& epsilon) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesMakeQuantileSummaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> float_values_handles; float_values_handles.reserve(float_values.size());
    std::transform(float_values.begin(), float_values.end(), std::back_inserter(float_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), float_values_handles.data(), float_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", float_values.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BoostedTreesMakeStatsSummary(const Tensor& node_ids, const Tensor& gradients, const Tensor& hessians, const std::vector<Tensor>& bucketized_features_list, int64_t max_splits, int64_t num_buckets) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesMakeStatsSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hessians.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_list_handles; bucketized_features_list_handles.reserve(bucketized_features_list.size());
    std::transform(bucketized_features_list.begin(), bucketized_features_list.end(), std::back_inserter(bucketized_features_list_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), bucketized_features_list_handles.data(), bucketized_features_list.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrInt(op.get(), "num_features", bucketized_features_list.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BoostedTreesPredict(const Tensor& tree_ensemble_handle, const std::vector<Tensor>& bucketized_features, int64_t logits_dimension) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesPredict", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_handles; bucketized_features_handles.reserve(bucketized_features.size());
    std::transform(bucketized_features.begin(), bucketized_features.end(), std::back_inserter(bucketized_features_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), bucketized_features_handles.data(), bucketized_features.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bucketized_features", bucketized_features.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void BoostedTreesQuantileStreamResourceAddSummaries(const Tensor& quantile_stream_resource_handle, const std::vector<Tensor>& summaries) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceAddSummaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> summaries_handles; summaries_handles.reserve(summaries.size());
    std::transform(summaries.begin(), summaries.end(), std::back_inserter(summaries_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), summaries_handles.data(), summaries.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", summaries.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void BoostedTreesQuantileStreamResourceDeserialize(const Tensor& quantile_stream_resource_handle, const std::vector<Tensor>& bucket_boundaries) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceDeserialize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucket_boundaries_handles; bucket_boundaries_handles.reserve(bucket_boundaries.size());
    std::transform(bucket_boundaries.begin(), bucket_boundaries.end(), std::back_inserter(bucket_boundaries_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), bucket_boundaries_handles.data(), bucket_boundaries.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_streams", bucket_boundaries.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void BoostedTreesQuantileStreamResourceFlush(const Tensor& quantile_stream_resource_handle, const Tensor& num_buckets, bool generate_quantiles=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceFlush", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_buckets.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "generate_quantiles", (unsigned char)generate_quantiles);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor BoostedTreesQuantileStreamResourceGetBucketBoundaries(const Tensor& quantile_stream_resource_handle, int64_t num_features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceGetBucketBoundaries", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", num_features);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BoostedTreesQuantileStreamResourceHandleOp(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesQuantileStreamResourceHandleOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BoostedTreesSerializeEnsemble(const Tensor& tree_ensemble_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesSerializeEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BoostedTreesSparseAggregateStats(const Tensor& node_ids, const Tensor& gradients, const Tensor& hessians, const Tensor& feature_indices, const Tensor& feature_values, const Tensor& feature_shape, int64_t max_splits, int64_t num_buckets) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesSparseAggregateStats", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hessians.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_splits", max_splits);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BoostedTreesSparseCalculateBestFeatureSplit(const Tensor& node_id_range, const Tensor& stats_summary_indices, const Tensor& stats_summary_values, const Tensor& stats_summary_shape, const Tensor& l1, const Tensor& l2, const Tensor& tree_complexity, const Tensor& min_node_weight, int64_t logits_dimension, const std::string& split_type="inequality") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesSparseCalculateBestFeatureSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), node_id_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_summary_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tree_complexity.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_node_weight.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);
    TFE_OpSetAttrString(op.get(), "split_type", (void*) split_type.c_str(), split_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 7;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> BoostedTreesTrainingPredict(const Tensor& tree_ensemble_handle, const Tensor& cached_tree_ids, const Tensor& cached_node_ids, const std::vector<Tensor>& bucketized_features, int64_t logits_dimension) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesTrainingPredict", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cached_tree_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cached_node_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> bucketized_features_handles; bucketized_features_handles.reserve(bucketized_features.size());
    std::transform(bucketized_features.begin(), bucketized_features.end(), std::back_inserter(bucketized_features_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), bucketized_features_handles.data(), bucketized_features.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bucketized_features", bucketized_features.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline void BoostedTreesUpdateEnsemble(const Tensor& tree_ensemble_handle, const Tensor& feature_ids, const std::vector<Tensor>& node_ids, const std::vector<Tensor>& gains, const std::vector<Tensor>& thresholds, const std::vector<Tensor>& left_node_contribs, const std::vector<Tensor>& right_node_contribs, const Tensor& max_depth, const Tensor& learning_rate, int64_t pruning_mode) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesUpdateEnsemble", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> node_ids_handles; node_ids_handles.reserve(node_ids.size());
    std::transform(node_ids.begin(), node_ids.end(), std::back_inserter(node_ids_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), node_ids_handles.data(), node_ids.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> gains_handles; gains_handles.reserve(gains.size());
    std::transform(gains.begin(), gains.end(), std::back_inserter(gains_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), gains_handles.data(), gains.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> thresholds_handles; thresholds_handles.reserve(thresholds.size());
    std::transform(thresholds.begin(), thresholds.end(), std::back_inserter(thresholds_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), thresholds_handles.data(), thresholds.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> left_node_contribs_handles; left_node_contribs_handles.reserve(left_node_contribs.size());
    std::transform(left_node_contribs.begin(), left_node_contribs.end(), std::back_inserter(left_node_contribs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), left_node_contribs_handles.data(), left_node_contribs.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> right_node_contribs_handles; right_node_contribs_handles.reserve(right_node_contribs.size());
    std::transform(right_node_contribs.begin(), right_node_contribs.end(), std::back_inserter(right_node_contribs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), right_node_contribs_handles.data(), right_node_contribs.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_depth.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "pruning_mode", pruning_mode);
    TFE_OpSetAttrInt(op.get(), "num_features", node_ids.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void BoostedTreesUpdateEnsembleV2(const Tensor& tree_ensemble_handle, const std::vector<Tensor>& feature_ids, const std::vector<Tensor>& dimension_ids, const std::vector<Tensor>& node_ids, const std::vector<Tensor>& gains, const std::vector<Tensor>& thresholds, const std::vector<Tensor>& left_node_contribs, const std::vector<Tensor>& right_node_contribs, const std::vector<Tensor>& split_types, const Tensor& max_depth, const Tensor& learning_rate, const Tensor& pruning_mode, int64_t logits_dimension=1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BoostedTreesUpdateEnsembleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> feature_ids_handles; feature_ids_handles.reserve(feature_ids.size());
    std::transform(feature_ids.begin(), feature_ids.end(), std::back_inserter(feature_ids_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), feature_ids_handles.data(), feature_ids.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dimension_ids_handles; dimension_ids_handles.reserve(dimension_ids.size());
    std::transform(dimension_ids.begin(), dimension_ids.end(), std::back_inserter(dimension_ids_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dimension_ids_handles.data(), dimension_ids.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> node_ids_handles; node_ids_handles.reserve(node_ids.size());
    std::transform(node_ids.begin(), node_ids.end(), std::back_inserter(node_ids_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), node_ids_handles.data(), node_ids.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> gains_handles; gains_handles.reserve(gains.size());
    std::transform(gains.begin(), gains.end(), std::back_inserter(gains_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), gains_handles.data(), gains.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> thresholds_handles; thresholds_handles.reserve(thresholds.size());
    std::transform(thresholds.begin(), thresholds.end(), std::back_inserter(thresholds_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), thresholds_handles.data(), thresholds.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> left_node_contribs_handles; left_node_contribs_handles.reserve(left_node_contribs.size());
    std::transform(left_node_contribs.begin(), left_node_contribs.end(), std::back_inserter(left_node_contribs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), left_node_contribs_handles.data(), left_node_contribs.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> right_node_contribs_handles; right_node_contribs_handles.reserve(right_node_contribs.size());
    std::transform(right_node_contribs.begin(), right_node_contribs.end(), std::back_inserter(right_node_contribs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), right_node_contribs_handles.data(), right_node_contribs.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> split_types_handles; split_types_handles.reserve(split_types.size());
    std::transform(split_types.begin(), split_types.end(), std::back_inserter(split_types_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), split_types_handles.data(), split_types.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_depth.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), learning_rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pruning_mode.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", dimension_ids.size());
    TFE_OpSetAttrInt(op.get(), "logits_dimension", logits_dimension);
    TFE_OpSetAttrInt(op.get(), "num_groups", feature_ids.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor BroadcastArgs(const Tensor& s0, const Tensor& s1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BroadcastArgs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), s0.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), s1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> BroadcastGradientArgs(const Tensor& s0, const Tensor& s1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BroadcastGradientArgs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), s0.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), s1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor BroadcastTo(const Tensor& input, const Tensor& shape, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BroadcastTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Bucketize(const Tensor& input, const std::vector<float>& boundaries) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Bucketize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "boundaries", boundaries.data(), boundaries.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor BytesProducedStatsDataset(const Tensor& input_dataset, const Tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "BytesProducedStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> CSRSparseMatrixComponents(const Tensor& csr_sparse_matrix, const Tensor& index, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSRSparseMatrixComponents", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), csr_sparse_matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor CSRSparseMatrixToDense(const Tensor& sparse_input, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSRSparseMatrixToDense", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> CSRSparseMatrixToSparseTensor(const Tensor& sparse_matrix, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSRSparseMatrixToSparseTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor CSVDataset(const Tensor& filenames, const Tensor& compression_type, const Tensor& buffer_size, const Tensor& header, const Tensor& field_delim, const Tensor& use_quote_delim, const Tensor& na_value, const Tensor& select_cols, const std::vector<Tensor>& record_defaults, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSVDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), field_delim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), use_quote_delim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), na_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), select_cols.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), record_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CSVDatasetV2(const Tensor& filenames, const Tensor& compression_type, const Tensor& buffer_size, const Tensor& header, const Tensor& field_delim, const Tensor& use_quote_delim, const Tensor& na_value, const Tensor& select_cols, const std::vector<Tensor>& record_defaults, const Tensor& exclude_cols, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CSVDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), field_delim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), use_quote_delim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), na_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), select_cols.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), record_defaults.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), exclude_cols.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> CTCBeamSearchDecoder(const Tensor& inputs, const Tensor& sequence_length, int64_t beam_width, int64_t top_paths, bool merge_repeated=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCBeamSearchDecoder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "beam_width", beam_width);
    TFE_OpSetAttrInt(op.get(), "top_paths", top_paths);
    TFE_OpSetAttrBool(op.get(), "merge_repeated", (unsigned char)merge_repeated);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CTCGreedyDecoder(const Tensor& inputs, const Tensor& sequence_length, bool merge_repeated=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCGreedyDecoder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "merge_repeated", (unsigned char)merge_repeated);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CTCLoss(const Tensor& inputs, const Tensor& labels_indices, const Tensor& labels_values, const Tensor& sequence_length, bool preprocess_collapse_repeated=false, bool ctc_merge_repeated=true, bool ignore_longer_outputs_than_inputs=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCLoss", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "preprocess_collapse_repeated", (unsigned char)preprocess_collapse_repeated);
    TFE_OpSetAttrBool(op.get(), "ctc_merge_repeated", (unsigned char)ctc_merge_repeated);
    TFE_OpSetAttrBool(op.get(), "ignore_longer_outputs_than_inputs", (unsigned char)ignore_longer_outputs_than_inputs);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CTCLossV2(const Tensor& inputs, const Tensor& labels_indices, const Tensor& labels_values, const Tensor& sequence_length, bool preprocess_collapse_repeated=false, bool ctc_merge_repeated=true, bool ignore_longer_outputs_than_inputs=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CTCLossV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "preprocess_collapse_repeated", (unsigned char)preprocess_collapse_repeated);
    TFE_OpSetAttrBool(op.get(), "ctc_merge_repeated", (unsigned char)ctc_merge_repeated);
    TFE_OpSetAttrBool(op.get(), "ignore_longer_outputs_than_inputs", (unsigned char)ignore_longer_outputs_than_inputs);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor CacheDataset(const Tensor& input_dataset, const Tensor& filename, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CacheDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CacheDatasetV2(const Tensor& input_dataset, const Tensor& filename, const Tensor& cache, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CacheDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cache.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Cast(const Tensor& x, datatype SrcT, datatype DstT, bool Truncate=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "SrcT", SrcT);
    TFE_OpSetAttrType(op.get(), "DstT", DstT);
    TFE_OpSetAttrBool(op.get(), "Truncate", (unsigned char)Truncate);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Ceil(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Ceil", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CheckNumerics(const Tensor& input_tensor, const std::string& message) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CheckNumerics", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CheckNumericsV2(const Tensor& input_tensor, const std::string& message) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CheckNumericsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Cholesky(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cholesky", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CholeskyGrad(const Tensor& l, const Tensor& grad) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CholeskyGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), l.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ChooseFastestDataset(const std::vector<Tensor>& input_datasets, int64_t num_experiments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ChooseFastestDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_datasets_handles; input_datasets_handles.reserve(input_datasets.size());
    std::transform(input_datasets.begin(), input_datasets.end(), std::back_inserter(input_datasets_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_datasets_handles.data(), input_datasets.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", input_datasets.size());
    TFE_OpSetAttrInt(op.get(), "num_experiments", num_experiments);
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ClipByValue(const Tensor& t, const Tensor& clip_value_min, const Tensor& clip_value_max) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ClipByValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), clip_value_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), clip_value_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void CloseSummaryWriter(const Tensor& writer) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CloseSummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor CollectiveBcastRecv(int64_t group_size, int64_t group_key, int64_t instance_key, const std::vector<int64_t>& shape, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastRecv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveBcastRecvV2(const Tensor& group_size, const Tensor& group_key, const Tensor& instance_key, const Tensor& shape, datatype Tshape=static_cast<datatype>(3), const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastRecvV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), group_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveBcastSend(const Tensor& input, int64_t group_size, int64_t group_key, int64_t instance_key, const std::vector<int64_t>& shape, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastSend", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveBcastSendV2(const Tensor& input, const Tensor& group_size, const Tensor& group_key, const Tensor& instance_key, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveBcastSendV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveGather(const Tensor& input, int64_t group_size, int64_t group_key, int64_t instance_key, const std::vector<int64_t>& shape, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveGatherV2(const Tensor& input, const Tensor& group_size, const Tensor& group_key, const Tensor& instance_key, const std::vector<Tensor>& ordering_token, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveGatherV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ordering_token_handles; ordering_token_handles.reserve(ordering_token.size());
    std::transform(ordering_token.begin(), ordering_token.end(), std::back_inserter(ordering_token_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), ordering_token_handles.data(), ordering_token.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);
    TFE_OpSetAttrInt(op.get(), "Nordering_token", ordering_token.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectivePermute(const Tensor& input, const Tensor& source_target_pairs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectivePermute", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), source_target_pairs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveReduce(const Tensor& input, int64_t group_size, int64_t group_key, int64_t instance_key, const std::string& merge_op, const std::string& final_op, const std::vector<int64_t>& subdiv_offsets, const std::vector<int64_t>& wait_for, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveReduce", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "group_size", group_size);
    TFE_OpSetAttrInt(op.get(), "group_key", group_key);
    TFE_OpSetAttrInt(op.get(), "instance_key", instance_key);
    TFE_OpSetAttrString(op.get(), "merge_op", (void*) merge_op.c_str(), merge_op.size());
    TFE_OpSetAttrString(op.get(), "final_op", (void*) final_op.c_str(), final_op.size());
    TFE_OpSetAttrIntList(op.get(), "subdiv_offsets", subdiv_offsets.data(), subdiv_offsets.size());
    TFE_OpSetAttrIntList(op.get(), "wait_for", wait_for.data(), wait_for.size());
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CollectiveReduceV2(const Tensor& input, const Tensor& group_size, const Tensor& group_key, const Tensor& instance_key, const std::vector<Tensor>& ordering_token, const std::string& merge_op, const std::string& final_op, const std::string& communication_hint="auto", float timeout_seconds=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CollectiveReduceV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), instance_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ordering_token_handles; ordering_token_handles.reserve(ordering_token.size());
    std::transform(ordering_token.begin(), ordering_token.end(), std::back_inserter(ordering_token_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), ordering_token_handles.data(), ordering_token.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "merge_op", (void*) merge_op.c_str(), merge_op.size());
    TFE_OpSetAttrString(op.get(), "final_op", (void*) final_op.c_str(), final_op.size());
    TFE_OpSetAttrString(op.get(), "communication_hint", (void*) communication_hint.c_str(), communication_hint.size());
    TFE_OpSetAttrFloat(op.get(), "timeout_seconds", timeout_seconds);
    TFE_OpSetAttrInt(op.get(), "Nordering_token", ordering_token.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> CombinedNonMaxSuppression(const Tensor& boxes, const Tensor& scores, const Tensor& max_output_size_per_class, const Tensor& max_total_size, const Tensor& iou_threshold, const Tensor& score_threshold, bool pad_per_class=false, bool clip_boxes=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CombinedNonMaxSuppression", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size_per_class.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_total_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "pad_per_class", (unsigned char)pad_per_class);
    TFE_OpSetAttrBool(op.get(), "clip_boxes", (unsigned char)clip_boxes);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor CompareAndBitpack(const Tensor& input, const Tensor& threshold) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CompareAndBitpack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Complex(const Tensor& real, const Tensor& imag, datatype Tout=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Complex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), real.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), imag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ComplexAbs(const Tensor& x, datatype Tout=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ComplexAbs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CompressElement(const std::vector<Tensor>& components, const std::vector<datatype>& input_types) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CompressElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "input_types", reinterpret_cast<const enum TF_DataType *>(input_types.data()), input_types.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> ComputeAccidentalHits(const Tensor& true_classes, const Tensor& sampled_candidates, int64_t num_true, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ComputeAccidentalHits", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sampled_candidates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor ComputeBatchSize(const Tensor& input_dataset) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ComputeBatchSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Concat(const Tensor& concat_dim, const std::vector<Tensor>& values) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Concat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), concat_dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ConcatOffset(const Tensor& concat_dim, const std::vector<Tensor>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConcatOffset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), concat_dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shape_handles; shape_handles.reserve(shape.size());
    std::transform(shape.begin(), shape.end(), std::back_inserter(shape_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), shape_handles.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", shape.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ConcatV2(const std::vector<Tensor>& values, const Tensor& axis, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConcatV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ConcatenateDataset(const Tensor& input_dataset, const Tensor& another_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConcatenateDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), another_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ConditionalAccumulator(datatype dtype, const std::vector<int64_t>& shape, const std::string& container="", const std::string& shared_name="", const std::string& reduction_type="MEAN") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConditionalAccumulator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "reduction_type", (void*) reduction_type.c_str(), reduction_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ConfigureDistributedTPU(const std::string& embedding_config="", const std::string& tpu_embedding_config="", bool is_global_init=false, bool enable_whole_mesh_compilations=false, bool compilation_failure_closes_chips=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConfigureDistributedTPU", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "embedding_config", (void*) embedding_config.c_str(), embedding_config.size());
    TFE_OpSetAttrString(op.get(), "tpu_embedding_config", (void*) tpu_embedding_config.c_str(), tpu_embedding_config.size());
    TFE_OpSetAttrBool(op.get(), "is_global_init", (unsigned char)is_global_init);
    TFE_OpSetAttrBool(op.get(), "enable_whole_mesh_compilations", (unsigned char)enable_whole_mesh_compilations);
    TFE_OpSetAttrBool(op.get(), "compilation_failure_closes_chips", (unsigned char)compilation_failure_closes_chips);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ConfigureTPUEmbedding(const std::string& config) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConfigureTPUEmbedding", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Conj(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conj", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ConjugateTranspose(const Tensor& x, const Tensor& perm, datatype Tperm=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConjugateTranspose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), perm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tperm", Tperm);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Const(const Tensor& value, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Const", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrTensor(op.get(), "value", value.get_tensor().get(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ConsumeMutexLock(const Tensor& mutex_lock) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ConsumeMutexLock", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), mutex_lock.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ControlTrigger() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ControlTrigger", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Conv2D(const Tensor& input, const Tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv2DBackpropFilter(const Tensor& input, const Tensor& filter_sizes, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2DBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv2DBackpropInput(const Tensor& input_sizes, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, bool use_cudnn_on_gpu=true, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv2DBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrBool(op.get(), "use_cudnn_on_gpu", (unsigned char)use_cudnn_on_gpu);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv3D(const Tensor& input, const Tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::string& data_format="NDHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv3DBackpropFilter(const Tensor& input, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv3DBackpropFilterV2(const Tensor& input, const Tensor& filter_sizes, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::string& data_format="NDHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropFilterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv3DBackpropInput(const Tensor& input, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Conv3DBackpropInputV2(const Tensor& input_sizes, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::string& data_format="NDHWC", datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Conv3DBackpropInputV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Copy(const Tensor& input, const std::vector< std::string>& debug_ops_spec, const std::string& tensor_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Copy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_ops_spec_sizes; debug_ops_spec_sizes.reserve(debug_ops_spec.size());
    std::transform(debug_ops_spec.begin(), debug_ops_spec.end(), std::back_inserter(debug_ops_spec_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_ops_spec", reinterpret_cast<const void *const *>(debug_ops_spec.data()), debug_ops_spec_sizes.data(), debug_ops_spec.size());
    
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CopyHost(const Tensor& input, const std::vector< std::string>& debug_ops_spec, const std::string& tensor_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CopyHost", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_ops_spec_sizes; debug_ops_spec_sizes.reserve(debug_ops_spec.size());
    std::transform(debug_ops_spec.begin(), debug_ops_spec.end(), std::back_inserter(debug_ops_spec_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_ops_spec", reinterpret_cast<const void *const *>(debug_ops_spec.data()), debug_ops_spec_sizes.data(), debug_ops_spec.size());
    
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Cos(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cos", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Cosh(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cosh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CountUpTo(const Tensor& ref, int64_t limit) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CountUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "limit", limit);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void CreateSummaryDbWriter(const Tensor& writer, const Tensor& db_uri, const Tensor& experiment_name, const Tensor& run_name, const Tensor& user_name) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CreateSummaryDbWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), db_uri.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), experiment_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), run_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), user_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void CreateSummaryFileWriter(const Tensor& writer, const Tensor& logdir, const Tensor& max_queue, const Tensor& flush_millis, const Tensor& filename_suffix) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CreateSummaryFileWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), logdir.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_queue.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flush_millis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename_suffix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor CropAndResize(const Tensor& image, const Tensor& boxes, const Tensor& box_ind, const Tensor& crop_size, const std::string& method="bilinear", float extrapolation_value=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CropAndResize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), box_ind.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crop_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "method", (void*) method.c_str(), method.size());
    TFE_OpSetAttrFloat(op.get(), "extrapolation_value", extrapolation_value);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CropAndResizeGradBoxes(const Tensor& grads, const Tensor& image, const Tensor& boxes, const Tensor& box_ind, const std::string& method="bilinear") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CropAndResizeGradBoxes", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), box_ind.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "method", (void*) method.c_str(), method.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CropAndResizeGradImage(const Tensor& grads, const Tensor& boxes, const Tensor& box_ind, const Tensor& image_size, const std::string& method="bilinear") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CropAndResizeGradImage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), box_ind.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), image_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "method", (void*) method.c_str(), method.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Cross(const Tensor& a, const Tensor& b) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cross", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CrossReplicaSum(const Tensor& input, const Tensor& group_assignment) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CrossReplicaSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), group_assignment.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> CudnnRNN(const Tensor& input, const Tensor& input_h, const Tensor& input_c, const Tensor& params, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CudnnRNNBackprop(const Tensor& input, const Tensor& input_h, const Tensor& input_c, const Tensor& params, const Tensor& output, const Tensor& output_h, const Tensor& output_c, const Tensor& output_backprop, const Tensor& output_h_backprop, const Tensor& output_c_backprop, const Tensor& reserve_space, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNBackprop", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CudnnRNNBackpropV2(const Tensor& input, const Tensor& input_h, const Tensor& input_c, const Tensor& params, const Tensor& output, const Tensor& output_h, const Tensor& output_c, const Tensor& output_backprop, const Tensor& output_h_backprop, const Tensor& output_c_backprop, const Tensor& reserve_space, const Tensor& host_reserved, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNBackpropV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), host_reserved.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CudnnRNNBackpropV3(const Tensor& input, const Tensor& input_h, const Tensor& input_c, const Tensor& params, const Tensor& sequence_lengths, const Tensor& output, const Tensor& output_h, const Tensor& output_c, const Tensor& output_backprop, const Tensor& output_h_backprop, const Tensor& output_c_backprop, const Tensor& reserve_space, const Tensor& host_reserved, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0, bool time_major=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNBackpropV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_h_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_c_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), host_reserved.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);
    TFE_OpSetAttrBool(op.get(), "time_major", (unsigned char)time_major);

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor CudnnRNNCanonicalToParams(const Tensor& num_layers, const Tensor& num_units, const Tensor& input_size, const std::vector<Tensor>& weights, const std::vector<Tensor>& biases, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNCanonicalToParams", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> weights_handles; weights_handles.reserve(weights.size());
    std::transform(weights.begin(), weights.end(), std::back_inserter(weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), weights_handles.data(), weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> biases_handles; biases_handles.reserve(biases.size());
    std::transform(biases.begin(), biases.end(), std::back_inserter(biases_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), biases_handles.data(), biases.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params", weights.size());
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CudnnRNNCanonicalToParamsV2(const Tensor& num_layers, const Tensor& num_units, const Tensor& input_size, const std::vector<Tensor>& weights, const std::vector<Tensor>& biases, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNCanonicalToParamsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> weights_handles; weights_handles.reserve(weights.size());
    std::transform(weights.begin(), weights.end(), std::back_inserter(weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), weights_handles.data(), weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> biases_handles; biases_handles.reserve(biases.size());
    std::transform(biases.begin(), biases.end(), std::back_inserter(biases_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), biases_handles.data(), biases.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params_weights", weights.size());
    TFE_OpSetAttrInt(op.get(), "num_params_biases", biases.size());
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CudnnRNNParamsSize(const Tensor& num_layers, const Tensor& num_units, const Tensor& input_size, datatype S, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNParamsSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> CudnnRNNParamsToCanonical(const Tensor& num_layers, const Tensor& num_units, const Tensor& input_size, const Tensor& params, int64_t num_params, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNParamsToCanonical", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params", num_params);
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CudnnRNNParamsToCanonicalV2(const Tensor& num_layers, const Tensor& num_units, const Tensor& input_size, const Tensor& params, int64_t num_params_weights, int64_t num_params_biases, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNParamsToCanonicalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), num_layers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_units.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_params_weights", num_params_weights);
    TFE_OpSetAttrInt(op.get(), "num_params_biases", num_params_biases);
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CudnnRNNV2(const Tensor& input, const Tensor& input_h, const Tensor& input_c, const Tensor& params, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> CudnnRNNV3(const Tensor& input, const Tensor& input_h, const Tensor& input_c, const Tensor& params, const Tensor& sequence_lengths, const std::string& rnn_mode="lstm", const std::string& input_mode="linear_input", const std::string& direction="unidirectional", float dropout=0.0000e+00, int64_t seed=0, int64_t seed2=0, int64_t num_proj=0, bool is_training=true, bool time_major=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CudnnRNNV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sequence_lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "rnn_mode", (void*) rnn_mode.c_str(), rnn_mode.size());
    TFE_OpSetAttrString(op.get(), "input_mode", (void*) input_mode.c_str(), input_mode.size());
    TFE_OpSetAttrString(op.get(), "direction", (void*) direction.c_str(), direction.size());
    TFE_OpSetAttrFloat(op.get(), "dropout", dropout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "num_proj", num_proj);
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);
    TFE_OpSetAttrBool(op.get(), "time_major", (unsigned char)time_major);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Cumprod(const Tensor& x, const Tensor& axis, bool exclusive=false, bool reverse=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cumprod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "exclusive", (unsigned char)exclusive);
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Cumsum(const Tensor& x, const Tensor& axis, bool exclusive=false, bool reverse=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Cumsum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "exclusive", (unsigned char)exclusive);
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor CumulativeLogsumexp(const Tensor& x, const Tensor& axis, bool exclusive=false, bool reverse=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "CumulativeLogsumexp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "exclusive", (unsigned char)exclusive);
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DataFormatDimMap(const Tensor& x, const std::string& src_format="NHWC", const std::string& dst_format="NCHW") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataFormatDimMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "src_format", (void*) src_format.c_str(), src_format.size());
    TFE_OpSetAttrString(op.get(), "dst_format", (void*) dst_format.c_str(), dst_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DataFormatVecPermute(const Tensor& x, const std::string& src_format="NHWC", const std::string& dst_format="NCHW") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataFormatVecPermute", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "src_format", (void*) src_format.c_str(), src_format.size());
    TFE_OpSetAttrString(op.get(), "dst_format", (void*) dst_format.c_str(), dst_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DataServiceDataset(const Tensor& dataset_id, const Tensor& processing_mode, const Tensor& address, const Tensor& protocol, const Tensor& job_name, const Tensor& max_outstanding_requests, const Tensor& iteration_counter, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t task_refresh_interval_hint_ms=-1, const std::string& data_transfer_protocol="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataServiceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset_id.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), processing_mode.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), job_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_outstanding_requests.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iteration_counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "task_refresh_interval_hint_ms", task_refresh_interval_hint_ms);
    TFE_OpSetAttrString(op.get(), "data_transfer_protocol", (void*) data_transfer_protocol.c_str(), data_transfer_protocol.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DataServiceDatasetV2(const Tensor& dataset_id, const Tensor& processing_mode, const Tensor& address, const Tensor& protocol, const Tensor& job_name, const Tensor& consumer_index, const Tensor& num_consumers, const Tensor& max_outstanding_requests, const Tensor& iteration_counter, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t task_refresh_interval_hint_ms=-1, const std::string& data_transfer_protocol="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DataServiceDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset_id.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), processing_mode.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), job_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), consumer_index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_consumers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_outstanding_requests.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iteration_counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "task_refresh_interval_hint_ms", task_refresh_interval_hint_ms);
    TFE_OpSetAttrString(op.get(), "data_transfer_protocol", (void*) data_transfer_protocol.c_str(), data_transfer_protocol.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DatasetCardinality(const Tensor& input_dataset) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetCardinality", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DatasetFromGraph(const Tensor& graph_def) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetFromGraph", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), graph_def.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DatasetToGraph(const Tensor& input_dataset, const std::vector< std::string>& stateful_whitelist, bool allow_stateful=false, bool strip_device_assignment=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToGraph", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> stateful_whitelist_sizes; stateful_whitelist_sizes.reserve(stateful_whitelist.size());
    std::transform(stateful_whitelist.begin(), stateful_whitelist.end(), std::back_inserter(stateful_whitelist_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "stateful_whitelist", reinterpret_cast<const void *const *>(stateful_whitelist.data()), stateful_whitelist_sizes.data(), stateful_whitelist.size());
    
    TFE_OpSetAttrBool(op.get(), "allow_stateful", (unsigned char)allow_stateful);
    TFE_OpSetAttrBool(op.get(), "strip_device_assignment", (unsigned char)strip_device_assignment);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DatasetToGraphV2(const Tensor& input_dataset, int64_t external_state_policy=0, bool strip_device_assignment=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToGraphV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);
    TFE_OpSetAttrBool(op.get(), "strip_device_assignment", (unsigned char)strip_device_assignment);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DatasetToSingleElement(const Tensor& dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToSingleElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void DatasetToTFRecord(const Tensor& input_dataset, const Tensor& filename, const Tensor& compression_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DatasetToTFRecord", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Dawsn(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dawsn", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugGradientIdentity(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugGradientIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugGradientRefIdentity(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugGradientRefIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugIdentity(const Tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", bool gated_grpc=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), debug_urls.size());
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugIdentityV2(const Tensor& input, const std::vector< std::string>& debug_urls, const std::string& tfdbg_context_id="", const std::string& op_name="", int64_t output_slot=-1, int64_t tensor_debug_mode=-1, int64_t circular_buffer_size=1000, const std::string& tfdbg_run_id="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugIdentityV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), debug_urls.size());
    
    TFE_OpSetAttrString(op.get(), "tfdbg_context_id", (void*) tfdbg_context_id.c_str(), tfdbg_context_id.size());
    TFE_OpSetAttrString(op.get(), "op_name", (void*) op_name.c_str(), op_name.size());
    TFE_OpSetAttrInt(op.get(), "output_slot", output_slot);
    TFE_OpSetAttrInt(op.get(), "tensor_debug_mode", tensor_debug_mode);
    TFE_OpSetAttrInt(op.get(), "circular_buffer_size", circular_buffer_size);
    TFE_OpSetAttrString(op.get(), "tfdbg_run_id", (void*) tfdbg_run_id.c_str(), tfdbg_run_id.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugNanCount(const Tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", bool gated_grpc=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugNanCount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), debug_urls.size());
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugNumericSummary(const Tensor& input, const std::vector< std::string>& debug_urls, const std::string& device_name="", const std::string& tensor_name="", float lower_bound=-std::numeric_limits<float>::infinity(), float upper_bound=std::numeric_limits<float>::infinity(), bool mute_if_healthy=false, bool gated_grpc=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugNumericSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> debug_urls_sizes; debug_urls_sizes.reserve(debug_urls.size());
    std::transform(debug_urls.begin(), debug_urls.end(), std::back_inserter(debug_urls_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "debug_urls", reinterpret_cast<const void *const *>(debug_urls.data()), debug_urls_sizes.data(), debug_urls.size());
    
    TFE_OpSetAttrString(op.get(), "device_name", (void*) device_name.c_str(), device_name.size());
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrFloat(op.get(), "lower_bound", lower_bound);
    TFE_OpSetAttrFloat(op.get(), "upper_bound", upper_bound);
    TFE_OpSetAttrBool(op.get(), "mute_if_healthy", (unsigned char)mute_if_healthy);
    TFE_OpSetAttrBool(op.get(), "gated_grpc", (unsigned char)gated_grpc);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DebugNumericSummaryV2(const Tensor& input, datatype output_dtype=static_cast<datatype>(1), int64_t tensor_debug_mode=-1, int64_t tensor_id=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DebugNumericSummaryV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);
    TFE_OpSetAttrInt(op.get(), "tensor_debug_mode", tensor_debug_mode);
    TFE_OpSetAttrInt(op.get(), "tensor_id", tensor_id);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeAndCropJpeg(const Tensor& contents, const Tensor& crop_window, int64_t channels=0, int64_t ratio=1, bool fancy_upscaling=true, bool try_recover_truncated=false, float acceptable_fraction=1.0000e+00, const std::string& dct_method="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeAndCropJpeg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), crop_window.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrInt(op.get(), "ratio", ratio);
    TFE_OpSetAttrBool(op.get(), "fancy_upscaling", (unsigned char)fancy_upscaling);
    TFE_OpSetAttrBool(op.get(), "try_recover_truncated", (unsigned char)try_recover_truncated);
    TFE_OpSetAttrFloat(op.get(), "acceptable_fraction", acceptable_fraction);
    TFE_OpSetAttrString(op.get(), "dct_method", (void*) dct_method.c_str(), dct_method.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeBase64(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeBase64", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeBmp(const Tensor& contents, int64_t channels=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeBmp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeCSV(const Tensor& records, const std::vector<Tensor>& record_defaults, const std::vector<datatype>& OUT_TYPE, const std::vector<int64_t>& select_cols, const std::string& field_delim=",", bool use_quote_delim=true, const std::string& na_value="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeCSV", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), records.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), record_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "OUT_TYPE", reinterpret_cast<const enum TF_DataType *>(OUT_TYPE.data()), OUT_TYPE.size());
    TFE_OpSetAttrIntList(op.get(), "select_cols", select_cols.data(), select_cols.size());
    TFE_OpSetAttrString(op.get(), "field_delim", (void*) field_delim.c_str(), field_delim.size());
    TFE_OpSetAttrBool(op.get(), "use_quote_delim", (unsigned char)use_quote_delim);
    TFE_OpSetAttrString(op.get(), "na_value", (void*) na_value.c_str(), na_value.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeCompressed(const Tensor& bytes, const std::string& compression_type="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeCompressed", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeGif(const Tensor& contents) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeGif", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeImage(const Tensor& contents, int64_t channels=0, datatype dtype=static_cast<datatype>(4), bool expand_animations=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeImage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "expand_animations", (unsigned char)expand_animations);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeJSONExample(const Tensor& json_examples) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeJSONExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), json_examples.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodeJpeg(const Tensor& contents, int64_t channels=0, int64_t ratio=1, bool fancy_upscaling=true, bool try_recover_truncated=false, float acceptable_fraction=1.0000e+00, const std::string& dct_method="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeJpeg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrInt(op.get(), "ratio", ratio);
    TFE_OpSetAttrBool(op.get(), "fancy_upscaling", (unsigned char)fancy_upscaling);
    TFE_OpSetAttrBool(op.get(), "try_recover_truncated", (unsigned char)try_recover_truncated);
    TFE_OpSetAttrFloat(op.get(), "acceptable_fraction", acceptable_fraction);
    TFE_OpSetAttrString(op.get(), "dct_method", (void*) dct_method.c_str(), dct_method.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodePaddedRaw(const Tensor& input_bytes, const Tensor& fixed_length, datatype out_type, bool little_endian=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodePaddedRaw", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fixed_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrBool(op.get(), "little_endian", (unsigned char)little_endian);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DecodePng(const Tensor& contents, int64_t channels=0, datatype dtype=static_cast<datatype>(4)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodePng", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "channels", channels);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> DecodeProtoV2(const Tensor& bytes, const std::string& message_type, const std::vector< std::string>& field_names, const std::vector<datatype>& output_types, const std::string& descriptor_source="local://", const std::string& message_format="binary", bool sanitize=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeProtoV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message_type", (void*) message_type.c_str(), message_type.size());
    
    std::vector<std::size_t> field_names_sizes; field_names_sizes.reserve(field_names.size());
    std::transform(field_names.begin(), field_names.end(), std::back_inserter(field_names_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "field_names", reinterpret_cast<const void *const *>(field_names.data()), field_names_sizes.data(), field_names.size());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    TFE_OpSetAttrString(op.get(), "descriptor_source", (void*) descriptor_source.c_str(), descriptor_source.size());
    TFE_OpSetAttrString(op.get(), "message_format", (void*) message_format.c_str(), message_format.size());
    TFE_OpSetAttrBool(op.get(), "sanitize", (unsigned char)sanitize);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor DecodeRaw(const Tensor& bytes, datatype out_type, bool little_endian=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeRaw", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrBool(op.get(), "little_endian", (unsigned char)little_endian);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> DecodeWav(const Tensor& contents, int64_t desired_channels=-1, int64_t desired_samples=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DecodeWav", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "desired_channels", desired_channels);
    TFE_OpSetAttrInt(op.get(), "desired_samples", desired_samples);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor DeepCopy(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeepCopy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void DeleteIterator(const Tensor& handle, const Tensor& deleter) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void DeleteMemoryCache(const Tensor& handle, const Tensor& deleter) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteMemoryCache", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void DeleteMultiDeviceIterator(const Tensor& multi_device_iterator, const std::vector<Tensor>& iterators, const Tensor& deleter) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteMultiDeviceIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), multi_device_iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> iterators_handles; iterators_handles.reserve(iterators.size());
    std::transform(iterators.begin(), iterators.end(), std::back_inserter(iterators_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), iterators_handles.data(), iterators.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", iterators.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void DeleteRandomSeedGenerator(const Tensor& handle, const Tensor& deleter) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteRandomSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void DeleteSeedGenerator(const Tensor& handle, const Tensor& deleter) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteSeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void DeleteSessionTensor(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeleteSessionTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor DenseBincount(const Tensor& input, const Tensor& size, const Tensor& weights, datatype Tidx, bool binary_output=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseBincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> DenseCountSparseOutput(const Tensor& values, const Tensor& weights, bool binary_output, datatype output_type, int64_t minlength=-1, int64_t maxlength=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseCountSparseOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);
    TFE_OpSetAttrInt(op.get(), "minlength", minlength);
    TFE_OpSetAttrInt(op.get(), "maxlength", maxlength);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor DenseToCSRSparseMatrix(const Tensor& dense_input, const Tensor& indices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToCSRSparseMatrix", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dense_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> DenseToDenseSetOperation(const Tensor& set1, const Tensor& set2, const std::string& set_operation, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToDenseSetOperation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "set_operation", (void*) set_operation.c_str(), set_operation.size());
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor DenseToSparseBatchDataset(const Tensor& input_dataset, const Tensor& batch_size, const Tensor& row_shape, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToSparseBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> DenseToSparseSetOperation(const Tensor& set1, const Tensor& set2_indices, const Tensor& set2_values, const Tensor& set2_shape, const std::string& set_operation, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DenseToSparseSetOperation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "set_operation", (void*) set_operation.c_str(), set_operation.size());
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor DepthToSpace(const Tensor& input, int64_t block_size, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthToSpace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DepthwiseConv2dNative(const Tensor& input, const Tensor& filter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthwiseConv2dNative", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DepthwiseConv2dNativeBackpropFilter(const Tensor& input, const Tensor& filter_sizes, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthwiseConv2dNativeBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DepthwiseConv2dNativeBackpropInput(const Tensor& input_sizes, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::vector<int64_t>& dilations, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DepthwiseConv2dNativeBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Dequantize(const Tensor& input, const Tensor& min_range, const Tensor& max_range, const std::string& mode="MIN_COMBINED", bool narrow_range=false, int64_t axis=-1, datatype dtype=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void DeserializeIterator(const Tensor& resource_handle, const Tensor& serialized) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeserializeIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline std::vector<Tensor> DeserializeManySparse(const Tensor& serialized_sparse, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeserializeManySparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized_sparse.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> DeserializeSparse(const Tensor& serialized_sparse, datatype dtype, datatype Tserialized=static_cast<datatype>(7)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeserializeSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized_sparse.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tserialized", Tserialized);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline void DestroyResourceOp(const Tensor& resource, bool ignore_lookup_error=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DestroyResourceOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "ignore_lookup_error", (unsigned char)ignore_lookup_error);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor DestroyTemporaryVariable(const Tensor& ref, const std::string& var_name) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DestroyTemporaryVariable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "var_name", (void*) var_name.c_str(), var_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DeviceIndex(const std::vector< std::string>& device_names) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DeviceIndex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> device_names_sizes; device_names_sizes.reserve(device_names.size());
    std::transform(device_names.begin(), device_names.end(), std::back_inserter(device_names_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "device_names", reinterpret_cast<const void *const *>(device_names.data()), device_names_sizes.data(), device_names.size());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Diag(const Tensor& diagonal) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Diag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DiagPart(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DiagPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Digamma(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Digamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Dilation2D(const Tensor& input, const Tensor& filter, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dilation2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), rates.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Dilation2DBackpropFilter(const Tensor& input, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dilation2DBackpropFilter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), rates.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Dilation2DBackpropInput(const Tensor& input, const Tensor& filter, const Tensor& out_backprop, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Dilation2DBackpropInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), rates.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DirectedInterleaveDataset(const Tensor& selector_input_dataset, const std::vector<Tensor>& data_input_datasets, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DirectedInterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), selector_input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_input_datasets_handles; data_input_datasets_handles.reserve(data_input_datasets.size());
    std::transform(data_input_datasets.begin(), data_input_datasets.end(), std::back_inserter(data_input_datasets_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_input_datasets_handles.data(), data_input_datasets.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", data_input_datasets.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Div(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Div", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DivNoNan(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DivNoNan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DrawBoundingBoxes(const Tensor& images, const Tensor& boxes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DrawBoundingBoxes", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DrawBoundingBoxesV2(const Tensor& images, const Tensor& boxes, const Tensor& colors) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DrawBoundingBoxesV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), colors.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DummyIterationCounter() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DummyIterationCounter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DummyMemoryCache() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DummyMemoryCache", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DummySeedGenerator() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DummySeedGenerator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DynamicPartition(const Tensor& data, const Tensor& partitions, int64_t num_partitions) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DynamicPartition", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), partitions.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_partitions", num_partitions);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor DynamicStitch(const std::vector<Tensor>& indices, const std::vector<Tensor>& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "DynamicStitch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), data.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EagerPyFunc(const std::vector<Tensor>& input, const std::string& token, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout, bool is_async=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EagerPyFunc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), input.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "token", (void*) token.c_str(), token.size());
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), Tin.size());
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), Tout.size());
    TFE_OpSetAttrBool(op.get(), "is_async", (unsigned char)is_async);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EditDistance(const Tensor& hypothesis_indices, const Tensor& hypothesis_values, const Tensor& hypothesis_shape, const Tensor& truth_indices, const Tensor& truth_values, const Tensor& truth_shape, bool normalize=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EditDistance", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), hypothesis_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hypothesis_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), hypothesis_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), truth_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), truth_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), truth_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "normalize", (unsigned char)normalize);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> Eig(const Tensor& input, datatype Tout, bool compute_v=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Eig", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrBool(op.get(), "compute_v", (unsigned char)compute_v);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Einsum(const std::vector<Tensor>& inputs, const std::string& equation) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Einsum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "equation", (void*) equation.c_str(), equation.size());
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Elu(const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Elu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EluGrad(const Tensor& gradients, const Tensor& outputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), outputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Empty(const Tensor& shape, datatype dtype, bool init=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Empty", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "init", (unsigned char)init);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EmptyTensorList(const Tensor& element_shape, const Tensor& max_num_elements, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EmptyTensorList", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_num_elements.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EncodeBase64(const Tensor& input, bool pad=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeBase64", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "pad", (unsigned char)pad);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EncodeJpeg(const Tensor& image, const std::string& format="", int64_t quality=95, bool progressive=false, bool optimize_size=false, bool chroma_downsampling=true, const std::string& density_unit="in", int64_t x_density=300, int64_t y_density=300, const std::string& xmp_metadata="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeJpeg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "format", (void*) format.c_str(), format.size());
    TFE_OpSetAttrInt(op.get(), "quality", quality);
    TFE_OpSetAttrBool(op.get(), "progressive", (unsigned char)progressive);
    TFE_OpSetAttrBool(op.get(), "optimize_size", (unsigned char)optimize_size);
    TFE_OpSetAttrBool(op.get(), "chroma_downsampling", (unsigned char)chroma_downsampling);
    TFE_OpSetAttrString(op.get(), "density_unit", (void*) density_unit.c_str(), density_unit.size());
    TFE_OpSetAttrInt(op.get(), "x_density", x_density);
    TFE_OpSetAttrInt(op.get(), "y_density", y_density);
    TFE_OpSetAttrString(op.get(), "xmp_metadata", (void*) xmp_metadata.c_str(), xmp_metadata.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EncodeJpegVariableQuality(const Tensor& images, const Tensor& quality) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeJpegVariableQuality", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), quality.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EncodePng(const Tensor& image, int64_t compression=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodePng", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "compression", compression);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EncodeProto(const Tensor& sizes, const std::vector<Tensor>& values, const std::vector< std::string>& field_names, const std::string& message_type, const std::vector<datatype>& Tinput_types, const std::string& descriptor_source="local://") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeProto", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> field_names_sizes; field_names_sizes.reserve(field_names.size());
    std::transform(field_names.begin(), field_names.end(), std::back_inserter(field_names_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "field_names", reinterpret_cast<const void *const *>(field_names.data()), field_names_sizes.data(), field_names.size());
    
    TFE_OpSetAttrString(op.get(), "message_type", (void*) message_type.c_str(), message_type.size());
    TFE_OpSetAttrTypeList(op.get(), "Tinput_types", reinterpret_cast<const enum TF_DataType *>(Tinput_types.data()), Tinput_types.size());
    TFE_OpSetAttrString(op.get(), "descriptor_source", (void*) descriptor_source.c_str(), descriptor_source.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EncodeWav(const Tensor& audio, const Tensor& sample_rate) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EncodeWav", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), audio.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void EnqueueTPUEmbeddingIntegerBatch(const std::vector<Tensor>& batch, const Tensor& mode_override, int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingIntegerBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> batch_handles; batch_handles.reserve(batch.size());
    std::transform(batch.begin(), batch.end(), std::back_inserter(batch_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), batch_handles.data(), batch.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", batch.size());
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void EnqueueTPUEmbeddingRaggedTensorBatch(const std::vector<Tensor>& sample_splits, const std::vector<Tensor>& embedding_indices, const std::vector<Tensor>& aggregation_weights, const Tensor& mode_override, const std::vector< std::string>& combiners, const std::vector<int64_t>& table_ids, const std::vector<int64_t>& max_sequence_lengths, const std::vector<int64_t>& num_features, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingRaggedTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_splits_handles; sample_splits_handles.reserve(sample_splits.size());
    std::transform(sample_splits.begin(), sample_splits.end(), std::back_inserter(sample_splits_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sample_splits_handles.data(), sample_splits.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), embedding_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), aggregation_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_splits.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), combiners.size());
    
    TFE_OpSetAttrIntList(op.get(), "table_ids", table_ids.data(), table_ids.size());
    TFE_OpSetAttrIntList(op.get(), "max_sequence_lengths", max_sequence_lengths.data(), max_sequence_lengths.size());
    TFE_OpSetAttrIntList(op.get(), "num_features", num_features.data(), num_features.size());
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void EnqueueTPUEmbeddingSparseBatch(const std::vector<Tensor>& sample_indices, const std::vector<Tensor>& embedding_indices, const std::vector<Tensor>& aggregation_weights, const Tensor& mode_override, const std::vector< std::string>& combiners, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingSparseBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_indices_handles; sample_indices_handles.reserve(sample_indices.size());
    std::transform(sample_indices.begin(), sample_indices.end(), std::back_inserter(sample_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sample_indices_handles.data(), sample_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), embedding_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), aggregation_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_indices.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), combiners.size());
    
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void EnqueueTPUEmbeddingSparseTensorBatch(const std::vector<Tensor>& sample_indices, const std::vector<Tensor>& embedding_indices, const std::vector<Tensor>& aggregation_weights, const Tensor& mode_override, const std::vector< std::string>& combiners, const std::vector<int64_t>& table_ids, const std::vector<int64_t>& max_sequence_lengths, const std::vector<int64_t>& num_features, datatype T1=static_cast<datatype>(3), datatype T2=static_cast<datatype>(3), datatype T3=static_cast<datatype>(1), int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnqueueTPUEmbeddingSparseTensorBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sample_indices_handles; sample_indices_handles.reserve(sample_indices.size());
    std::transform(sample_indices.begin(), sample_indices.end(), std::back_inserter(sample_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sample_indices_handles.data(), sample_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> embedding_indices_handles; embedding_indices_handles.reserve(embedding_indices.size());
    std::transform(embedding_indices.begin(), embedding_indices.end(), std::back_inserter(embedding_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), embedding_indices_handles.data(), embedding_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> aggregation_weights_handles; aggregation_weights_handles.reserve(aggregation_weights.size());
    std::transform(aggregation_weights.begin(), aggregation_weights.end(), std::back_inserter(aggregation_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), aggregation_weights_handles.data(), aggregation_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mode_override.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", sample_indices.size());
    
    std::vector<std::size_t> combiners_sizes; combiners_sizes.reserve(combiners.size());
    std::transform(combiners.begin(), combiners.end(), std::back_inserter(combiners_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "combiners", reinterpret_cast<const void *const *>(combiners.data()), combiners_sizes.data(), combiners.size());
    
    TFE_OpSetAttrIntList(op.get(), "table_ids", table_ids.data(), table_ids.size());
    TFE_OpSetAttrIntList(op.get(), "max_sequence_lengths", max_sequence_lengths.data(), max_sequence_lengths.size());
    TFE_OpSetAttrIntList(op.get(), "num_features", num_features.data(), num_features.size());
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "T3", T3);
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor EnsureShape(const Tensor& input, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EnsureShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Enter(const Tensor& data, const std::string& frame_name, bool is_constant=false, int64_t parallel_iterations=10) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Enter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "frame_name", (void*) frame_name.c_str(), frame_name.size());
    TFE_OpSetAttrBool(op.get(), "is_constant", (unsigned char)is_constant);
    TFE_OpSetAttrInt(op.get(), "parallel_iterations", parallel_iterations);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Equal(const Tensor& x, const Tensor& y, bool incompatible_shape_error=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Equal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "incompatible_shape_error", (unsigned char)incompatible_shape_error);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Erf(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Erf", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Erfc(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Erfc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Erfinv(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Erfinv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor EuclideanNorm(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "EuclideanNorm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Exit(const Tensor& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Exit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Exp(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Exp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExpandDims(const Tensor& input, const Tensor& dim, datatype Tdim=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExpandDims", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tdim", Tdim);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalAssertNextDataset(const Tensor& input_dataset, const Tensor& transformations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalAssertNextDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transformations.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalAutoShardDataset(const Tensor& input_dataset, const Tensor& num_workers, const Tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t auto_shard_policy=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalAutoShardDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_workers.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "auto_shard_policy", auto_shard_policy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalBytesProducedStatsDataset(const Tensor& input_dataset, const Tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalBytesProducedStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalCSVDataset(const Tensor& filenames, const Tensor& compression_type, const Tensor& buffer_size, const Tensor& header, const Tensor& field_delim, const Tensor& use_quote_delim, const Tensor& na_value, const Tensor& select_cols, const std::vector<Tensor>& record_defaults, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalCSVDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), field_delim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), use_quote_delim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), na_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), select_cols.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> record_defaults_handles; record_defaults_handles.reserve(record_defaults.size());
    std::transform(record_defaults.begin(), record_defaults.end(), std::back_inserter(record_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), record_defaults_handles.data(), record_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalChooseFastestDataset(const std::vector<Tensor>& input_datasets, int64_t num_experiments, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalChooseFastestDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_datasets_handles; input_datasets_handles.reserve(input_datasets.size());
    std::transform(input_datasets.begin(), input_datasets.end(), std::back_inserter(input_datasets_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_datasets_handles.data(), input_datasets.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", input_datasets.size());
    TFE_OpSetAttrInt(op.get(), "num_experiments", num_experiments);
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalDatasetCardinality(const Tensor& input_dataset) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDatasetCardinality", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ExperimentalDatasetToTFRecord(const Tensor& input_dataset, const Tensor& filename, const Tensor& compression_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDatasetToTFRecord", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor ExperimentalDenseToSparseBatchDataset(const Tensor& input_dataset, const Tensor& batch_size, const Tensor& row_shape, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDenseToSparseBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalDirectedInterleaveDataset(const Tensor& selector_input_dataset, const std::vector<Tensor>& data_input_datasets, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalDirectedInterleaveDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), selector_input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_input_datasets_handles; data_input_datasets_handles.reserve(data_input_datasets.size());
    std::transform(data_input_datasets.begin(), data_input_datasets.end(), std::back_inserter(data_input_datasets_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_input_datasets_handles.data(), data_input_datasets.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", data_input_datasets.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalIgnoreErrorsDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool log_warning=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalIgnoreErrorsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "log_warning", (unsigned char)log_warning);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalIteratorGetDevice(const Tensor& resource) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalIteratorGetDevice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalLMDBDataset(const Tensor& filenames, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalLMDBDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalLatencyStatsDataset(const Tensor& input_dataset, const Tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalLatencyStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalMatchingFilesDataset(const Tensor& patterns) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalMatchingFilesDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), patterns.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalMaxIntraOpParallelismDataset(const Tensor& input_dataset, const Tensor& max_intra_op_parallelism, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalMaxIntraOpParallelismDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_intra_op_parallelism.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalNonSerializableDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalNonSerializableDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalParseExampleDataset(const Tensor& input_dataset, const Tensor& num_parallel_calls, const std::vector<Tensor>& dense_defaults, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool sloppy=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalParseExampleDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), sparse_keys.size());
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), dense_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), Tdense.size());
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "sloppy", (unsigned char)sloppy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalPrivateThreadPoolDataset(const Tensor& input_dataset, const Tensor& num_threads, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalPrivateThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_threads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalRandomDataset(const Tensor& seed, const Tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalRandomDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalRebatchDataset(const Tensor& input_dataset, const Tensor& num_replicas, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_fallback=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalRebatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_replicas.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_fallback", (unsigned char)use_fallback);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalSetStatsAggregatorDataset(const Tensor& input_dataset, const Tensor& stats_aggregator, const Tensor& tag, const Tensor& counter_prefix, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSetStatsAggregatorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_aggregator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter_prefix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalSleepDataset(const Tensor& input_dataset, const Tensor& sleep_microseconds, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSleepDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sleep_microseconds.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalSlidingWindowDataset(const Tensor& input_dataset, const Tensor& window_size, const Tensor& window_shift, const Tensor& window_stride, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSlidingWindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_shift.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_stride.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalSqlDataset(const Tensor& driver_name, const Tensor& data_source_name, const Tensor& query, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalSqlDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), driver_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), data_source_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), query.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalStatsAggregatorHandle(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalStatsAggregatorHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalStatsAggregatorSummary(const Tensor& iterator) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalStatsAggregatorSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalThreadPoolDataset(const Tensor& input_dataset, const Tensor& thread_pool, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), thread_pool.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalThreadPoolHandle(int64_t num_threads, const std::string& display_name, int64_t max_intra_op_parallelism=1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalThreadPoolHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_threads", num_threads);
    TFE_OpSetAttrString(op.get(), "display_name", (void*) display_name.c_str(), display_name.size());
    TFE_OpSetAttrInt(op.get(), "max_intra_op_parallelism", max_intra_op_parallelism);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalUnbatchDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalUnbatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExperimentalUniqueDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExperimentalUniqueDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Expint(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Expint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Expm1(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Expm1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExtractGlimpse(const Tensor& input, const Tensor& size, const Tensor& offsets, bool centered=true, bool normalized=true, bool uniform_noise=true, const std::string& noise="uniform") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractGlimpse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offsets.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "centered", (unsigned char)centered);
    TFE_OpSetAttrBool(op.get(), "normalized", (unsigned char)normalized);
    TFE_OpSetAttrBool(op.get(), "uniform_noise", (unsigned char)uniform_noise);
    TFE_OpSetAttrString(op.get(), "noise", (void*) noise.c_str(), noise.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExtractGlimpseV2(const Tensor& input, const Tensor& size, const Tensor& offsets, bool centered=true, bool normalized=true, bool uniform_noise=true, const std::string& noise="uniform") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractGlimpseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offsets.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "centered", (unsigned char)centered);
    TFE_OpSetAttrBool(op.get(), "normalized", (unsigned char)normalized);
    TFE_OpSetAttrBool(op.get(), "uniform_noise", (unsigned char)uniform_noise);
    TFE_OpSetAttrString(op.get(), "noise", (void*) noise.c_str(), noise.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExtractImagePatches(const Tensor& images, const std::vector<int64_t>& ksizes, const std::vector<int64_t>& strides, const std::vector<int64_t>& rates, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractImagePatches", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksizes", ksizes.data(), ksizes.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrIntList(op.get(), "rates", rates.data(), rates.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExtractJpegShape(const Tensor& contents, datatype output_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractJpegShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_type", output_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ExtractVolumePatches(const Tensor& input, const std::vector<int64_t>& ksizes, const std::vector<int64_t>& strides, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ExtractVolumePatches", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksizes", ksizes.data(), ksizes.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FFT(const Tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FFT2D(const Tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FFT3D(const Tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FIFOQueue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FIFOQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FIFOQueueV2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FIFOQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Fact() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Fact", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FakeParam(datatype dtype, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeParam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FakeQuantWithMinMaxArgs(const Tensor& inputs, float min=-6.0000e+00, float max=6.0000e+00, int64_t num_bits=8, bool narrow_range=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxArgs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "min", min);
    TFE_OpSetAttrFloat(op.get(), "max", max);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FakeQuantWithMinMaxArgsGradient(const Tensor& gradients, const Tensor& inputs, float min=-6.0000e+00, float max=6.0000e+00, int64_t num_bits=8, bool narrow_range=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxArgsGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "min", min);
    TFE_OpSetAttrFloat(op.get(), "max", max);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FakeQuantWithMinMaxVars(const Tensor& inputs, const Tensor& min, const Tensor& max, int64_t num_bits=8, bool narrow_range=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVars", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> FakeQuantWithMinMaxVarsGradient(const Tensor& gradients, const Tensor& inputs, const Tensor& min, const Tensor& max, int64_t num_bits=8, bool narrow_range=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVarsGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor FakeQuantWithMinMaxVarsPerChannel(const Tensor& inputs, const Tensor& min, const Tensor& max, int64_t num_bits=8, bool narrow_range=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVarsPerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> FakeQuantWithMinMaxVarsPerChannelGradient(const Tensor& gradients, const Tensor& inputs, const Tensor& min, const Tensor& max, int64_t num_bits=8, bool narrow_range=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQuantWithMinMaxVarsPerChannelGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor FakeQueue(const Tensor& resource) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FakeQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Fill(const Tensor& dims, const Tensor& value, datatype index_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Fill", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dims.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "index_type", index_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FilterByLastComponentDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FilterByLastComponentDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FinalizeDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool has_captured_ref=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FinalizeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "has_captured_ref", (unsigned char)has_captured_ref);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Fingerprint(const Tensor& data, const Tensor& method) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Fingerprint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), method.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FixedLengthRecordDataset(const Tensor& filenames, const Tensor& header_bytes, const Tensor& record_bytes, const Tensor& footer_bytes, const Tensor& buffer_size) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), record_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), footer_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FixedLengthRecordDatasetV2(const Tensor& filenames, const Tensor& header_bytes, const Tensor& record_bytes, const Tensor& footer_bytes, const Tensor& buffer_size, const Tensor& compression_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), header_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), record_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), footer_bytes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FixedLengthRecordReader(int64_t record_bytes, int64_t header_bytes=0, int64_t footer_bytes=0, int64_t hop_bytes=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "record_bytes", record_bytes);
    TFE_OpSetAttrInt(op.get(), "header_bytes", header_bytes);
    TFE_OpSetAttrInt(op.get(), "footer_bytes", footer_bytes);
    TFE_OpSetAttrInt(op.get(), "hop_bytes", hop_bytes);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FixedLengthRecordReaderV2(int64_t record_bytes, int64_t header_bytes=0, int64_t footer_bytes=0, int64_t hop_bytes=0, const std::string& container="", const std::string& shared_name="", const std::string& encoding="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedLengthRecordReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "record_bytes", record_bytes);
    TFE_OpSetAttrInt(op.get(), "header_bytes", header_bytes);
    TFE_OpSetAttrInt(op.get(), "footer_bytes", footer_bytes);
    TFE_OpSetAttrInt(op.get(), "hop_bytes", hop_bytes);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "encoding", (void*) encoding.c_str(), encoding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> FixedUnigramCandidateSampler(const Tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, const std::vector<float>& unigrams, const std::string& vocab_file="", float distortion=1.0000e+00, int64_t num_reserved_ids=0, int64_t num_shards=1, int64_t shard=0, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FixedUnigramCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrFloatList(op.get(), "unigrams", unigrams.data(), unigrams.size());
    TFE_OpSetAttrString(op.get(), "vocab_file", (void*) vocab_file.c_str(), vocab_file.size());
    TFE_OpSetAttrFloat(op.get(), "distortion", distortion);
    TFE_OpSetAttrInt(op.get(), "num_reserved_ids", num_reserved_ids);
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard", shard);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Floor(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Floor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FloorDiv(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FloorDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FloorMod(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FloorMod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void FlushSummaryWriter(const Tensor& writer) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FlushSummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline std::vector<Tensor> FractionalAvgPool(const Tensor& value, const std::vector<float>& pooling_ratio, bool pseudo_random=false, bool overlapping=false, bool deterministic=false, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalAvgPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "pooling_ratio", pooling_ratio.data(), pooling_ratio.size());
    TFE_OpSetAttrBool(op.get(), "pseudo_random", (unsigned char)pseudo_random);
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);
    TFE_OpSetAttrBool(op.get(), "deterministic", (unsigned char)deterministic);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor FractionalAvgPoolGrad(const Tensor& orig_input_input_tensor_shape, const Tensor& out_backprop, const Tensor& row_pooling_sequence, const Tensor& col_pooling_sequence, bool overlapping=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalAvgPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input_input_tensor_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_pooling_sequence.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_pooling_sequence.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> FractionalMaxPool(const Tensor& value, const std::vector<float>& pooling_ratio, bool pseudo_random=false, bool overlapping=false, bool deterministic=false, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalMaxPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "pooling_ratio", pooling_ratio.data(), pooling_ratio.size());
    TFE_OpSetAttrBool(op.get(), "pseudo_random", (unsigned char)pseudo_random);
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);
    TFE_OpSetAttrBool(op.get(), "deterministic", (unsigned char)deterministic);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor FractionalMaxPoolGrad(const Tensor& orig_input, const Tensor& orig_output, const Tensor& out_backprop, const Tensor& row_pooling_sequence, const Tensor& col_pooling_sequence, bool overlapping=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FractionalMaxPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), out_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_pooling_sequence.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_pooling_sequence.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "overlapping", (unsigned char)overlapping);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FresnelCos(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FresnelCos", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FresnelSin(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FresnelSin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> FusedBatchNorm(const Tensor& x, const Tensor& scale, const Tensor& offset, const Tensor& mean, const Tensor& variance, float epsilon=1.0000e-04, float exponential_avg_factor=1.0000e+00, const std::string& data_format="NHWC", bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNorm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), variance.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrFloat(op.get(), "exponential_avg_factor", exponential_avg_factor);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> FusedBatchNormGrad(const Tensor& y_backprop, const Tensor& x, const Tensor& scale, const Tensor& reserve_space_1, const Tensor& reserve_space_2, float epsilon=1.0000e-04, const std::string& data_format="NHWC", bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> FusedBatchNormGradV2(const Tensor& y_backprop, const Tensor& x, const Tensor& scale, const Tensor& reserve_space_1, const Tensor& reserve_space_2, datatype U, float epsilon=1.0000e-04, const std::string& data_format="NHWC", bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> FusedBatchNormGradV3(const Tensor& y_backprop, const Tensor& x, const Tensor& scale, const Tensor& reserve_space_1, const Tensor& reserve_space_2, const Tensor& reserve_space_3, datatype U, float epsilon=1.0000e-04, const std::string& data_format="NHWC", bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormGradV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y_backprop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reserve_space_3.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> FusedBatchNormV2(const Tensor& x, const Tensor& scale, const Tensor& offset, const Tensor& mean, const Tensor& variance, datatype U, float epsilon=1.0000e-04, float exponential_avg_factor=1.0000e+00, const std::string& data_format="NHWC", bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), variance.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrFloat(op.get(), "exponential_avg_factor", exponential_avg_factor);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> FusedBatchNormV3(const Tensor& x, const Tensor& scale, const Tensor& offset, const Tensor& mean, const Tensor& variance, datatype U, float epsilon=1.0000e-04, float exponential_avg_factor=1.0000e+00, const std::string& data_format="NHWC", bool is_training=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedBatchNormV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), offset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mean.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), variance.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "U", U);
    TFE_OpSetAttrFloat(op.get(), "epsilon", epsilon);
    TFE_OpSetAttrFloat(op.get(), "exponential_avg_factor", exponential_avg_factor);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrBool(op.get(), "is_training", (unsigned char)is_training);

    // Execute Op
    constexpr auto __kNumOutputs = 6;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor FusedPadConv2D(const Tensor& input, const Tensor& paddings, const Tensor& filter, const std::string& mode, const std::vector<int64_t>& strides, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedPadConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor FusedResizeAndPadConv2D(const Tensor& input, const Tensor& size, const Tensor& paddings, const Tensor& filter, const std::string& mode, const std::vector<int64_t>& strides, const std::string& padding, bool resize_align_corners=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "FusedResizeAndPadConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrBool(op.get(), "resize_align_corners", (unsigned char)resize_align_corners);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> GRUBlockCell(const Tensor& x, const Tensor& h_prev, const Tensor& w_ru, const Tensor& w_c, const Tensor& b_ru, const Tensor& b_c) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GRUBlockCell", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_ru.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_ru.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> GRUBlockCellGrad(const Tensor& x, const Tensor& h_prev, const Tensor& w_ru, const Tensor& w_c, const Tensor& b_ru, const Tensor& b_c, const Tensor& r, const Tensor& u, const Tensor& c, const Tensor& d_h) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GRUBlockCellGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_ru.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_ru.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), r.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), u.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), c.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), d_h.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Gather(const Tensor& params, const Tensor& indices, datatype Tparams, datatype Tindices, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Gather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tparams", Tparams);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GatherNd(const Tensor& params, const Tensor& indices, datatype Tparams, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GatherNd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tparams", Tparams);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GatherV2(const Tensor& params, const Tensor& indices, const Tensor& axis, datatype Tparams, datatype Tindices, datatype Taxis, int64_t batch_dims=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GatherV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), params.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tparams", Tparams);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);
    TFE_OpSetAttrInt(op.get(), "batch_dims", batch_dims);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> GenerateBoundingBoxProposals(const Tensor& scores, const Tensor& bbox_deltas, const Tensor& image_info, const Tensor& anchors, const Tensor& nms_threshold, const Tensor& pre_nms_topn, const Tensor& min_size, int64_t post_nms_topn=300) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GenerateBoundingBoxProposals", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bbox_deltas.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), image_info.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), anchors.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), nms_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pre_nms_topn.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "post_nms_topn", post_nms_topn);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> GenerateVocabRemapping(const Tensor& new_vocab_file, const Tensor& old_vocab_file, int64_t new_vocab_offset, int64_t num_new_vocab, int64_t old_vocab_size=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GenerateVocabRemapping", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), new_vocab_file.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), old_vocab_file.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "new_vocab_offset", new_vocab_offset);
    TFE_OpSetAttrInt(op.get(), "num_new_vocab", num_new_vocab);
    TFE_OpSetAttrInt(op.get(), "old_vocab_size", old_vocab_size);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor GetOptions(const Tensor& input_dataset) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetOptions", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GetSessionHandle(const Tensor& value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetSessionHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GetSessionHandleV2(const Tensor& value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetSessionHandleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GetSessionTensor(const Tensor& handle, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GetSessionTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Greater(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Greater", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GreaterEqual(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GreaterEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor GuaranteeConst(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "GuaranteeConst", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor HSVToRGB(const Tensor& images) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HSVToRGB", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor HashTable(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor HashTableV2(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HashTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor HistogramFixedWidth(const Tensor& values, const Tensor& value_range, const Tensor& nbins, datatype dtype=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HistogramFixedWidth", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), nbins.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor HistogramSummary(const Tensor& tag, const Tensor& values) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "HistogramSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IFFT(const Tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IFFT2D(const Tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IFFT3D(const Tensor& input, datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IRFFT(const Tensor& input, const Tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IRFFT2D(const Tensor& input, const Tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IRFFT3D(const Tensor& input, const Tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IRFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Identity(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Identity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IdentityN(const std::vector<Tensor>& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IdentityN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), input.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IdentityReader(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IdentityReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IdentityReaderV2(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IdentityReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Igamma(const Tensor& a, const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Igamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IgammaGradA(const Tensor& a, const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IgammaGradA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Igammac(const Tensor& a, const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Igammac", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IgnoreErrorsDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool log_warning=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IgnoreErrorsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "log_warning", (unsigned char)log_warning);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Imag(const Tensor& input, datatype Tout=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Imag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ImageProjectiveTransformV2(const Tensor& images, const Tensor& transforms, const Tensor& output_shape, datatype dtype, const std::string& interpolation, const std::string& fill_mode="CONSTANT") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImageProjectiveTransformV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transforms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "interpolation", (void*) interpolation.c_str(), interpolation.size());
    TFE_OpSetAttrString(op.get(), "fill_mode", (void*) fill_mode.c_str(), fill_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ImageProjectiveTransformV3(const Tensor& images, const Tensor& transforms, const Tensor& output_shape, const Tensor& fill_value, datatype dtype, const std::string& interpolation, const std::string& fill_mode="CONSTANT") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImageProjectiveTransformV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), transforms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fill_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "interpolation", (void*) interpolation.c_str(), interpolation.size());
    TFE_OpSetAttrString(op.get(), "fill_mode", (void*) fill_mode.c_str(), fill_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ImageSummary(const Tensor& tag, const Tensor& input_tensor, const Tensor& bad_color, int64_t max_images=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImageSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    TFE_OpSetAttrTensor(op.get(), "bad_color", bad_color.get_tensor().get(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "max_images", max_images);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ImmutableConst(datatype dtype, const std::vector<int64_t>& shape, const std::string& memory_region_name) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImmutableConst", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "memory_region_name", (void*) memory_region_name.c_str(), memory_region_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ImportEvent(const Tensor& writer, const Tensor& event) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ImportEvent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), event.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor InTopK(const Tensor& predictions, const Tensor& targets, int64_t k) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InTopK", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), predictions.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), targets.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "k", k);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InTopKV2(const Tensor& predictions, const Tensor& targets, const Tensor& k) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InTopKV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), predictions.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), targets.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InfeedDequeue(datatype dtype, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedDequeue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InfeedDequeueTuple(const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedDequeueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void InfeedEnqueue(const Tensor& input, datatype dtype, const std::vector<int64_t>& shape, const std::vector<int64_t>& layout, int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedEnqueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layout", layout.data(), layout.size());
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InfeedEnqueuePrelinearizedBuffer(const Tensor& input, int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedEnqueuePrelinearizedBuffer", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InfeedEnqueueTuple(const std::vector<Tensor>& inputs, const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes, const std::vector<int64_t>& layouts, int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InfeedEnqueueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layouts", layouts.data(), layouts.size());
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InitializeTable(const Tensor& table_handle, const Tensor& keys, const Tensor& values, datatype Tkey, datatype Tval) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkey", Tkey);
    TFE_OpSetAttrType(op.get(), "Tval", Tval);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InitializeTableFromDataset(const Tensor& table_handle, const Tensor& dataset) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableFromDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InitializeTableFromTextFile(const Tensor& table_handle, const Tensor& filename, int64_t key_index, int64_t value_index, int64_t vocab_size=-1, const std::string& delimiter="\t", int64_t offset=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableFromTextFile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_index", key_index);
    TFE_OpSetAttrInt(op.get(), "value_index", value_index);
    TFE_OpSetAttrInt(op.get(), "vocab_size", vocab_size);
    TFE_OpSetAttrString(op.get(), "delimiter", (void*) delimiter.c_str(), delimiter.size());
    TFE_OpSetAttrInt(op.get(), "offset", offset);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InitializeTableFromTextFileV2(const Tensor& table_handle, const Tensor& filename, int64_t key_index, int64_t value_index, int64_t vocab_size=-1, const std::string& delimiter="\t", int64_t offset=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableFromTextFileV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "key_index", key_index);
    TFE_OpSetAttrInt(op.get(), "value_index", value_index);
    TFE_OpSetAttrInt(op.get(), "vocab_size", vocab_size);
    TFE_OpSetAttrString(op.get(), "delimiter", (void*) delimiter.c_str(), delimiter.size());
    TFE_OpSetAttrInt(op.get(), "offset", offset);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void InitializeTableV2(const Tensor& table_handle, const Tensor& keys, const Tensor& values, datatype Tkey, datatype Tval) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InitializeTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkey", Tkey);
    TFE_OpSetAttrType(op.get(), "Tval", Tval);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor InplaceAdd(const Tensor& x, const Tensor& i, const Tensor& v) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InplaceAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InplaceSub(const Tensor& x, const Tensor& i, const Tensor& v) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InplaceSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InplaceUpdate(const Tensor& x, const Tensor& i, const Tensor& v) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InplaceUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Inv(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Inv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InvGrad(const Tensor& y, const Tensor& dy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InvGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Invert(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Invert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor InvertPermutation(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "InvertPermutation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IsBoostedTreesEnsembleInitialized(const Tensor& tree_ensemble_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsBoostedTreesEnsembleInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tree_ensemble_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IsBoostedTreesQuantileStreamResourceInitialized(const Tensor& quantile_stream_resource_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsBoostedTreesQuantileStreamResourceInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), quantile_stream_resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IsFinite(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsFinite", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IsInf(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsInf", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IsNan(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsNan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IsVariableInitialized(const Tensor& ref, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsVariableInitialized", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> IsotonicRegression(const Tensor& input, datatype output_dtype=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IsotonicRegression", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Iterator(const std::string& shared_name, const std::string& container, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Iterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorFromStringHandle(const Tensor& string_handle, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorFromStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorFromStringHandleV2(const Tensor& string_handle, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorFromStringHandleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorGetDevice(const Tensor& resource) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetDevice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorGetNext(const Tensor& iterator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetNext", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorGetNextAsOptional(const Tensor& iterator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetNextAsOptional", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorGetNextSync(const Tensor& iterator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorGetNextSync", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorToStringHandle(const Tensor& resource_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorToStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor IteratorV2(const std::string& shared_name, const std::string& container, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "IteratorV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor L2Loss(const Tensor& t) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "L2Loss", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LMDBDataset(const Tensor& filenames, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LMDBDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LMDBReader(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LMDBReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LRN(const Tensor& input, int64_t depth_radius=5, float bias=1.0000e+00, float alpha=1.0000e+00, float beta=5.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LRN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "depth_radius", depth_radius);
    TFE_OpSetAttrFloat(op.get(), "bias", bias);
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);
    TFE_OpSetAttrFloat(op.get(), "beta", beta);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LRNGrad(const Tensor& input_grads, const Tensor& input_image, const Tensor& output_image, int64_t depth_radius=5, float bias=1.0000e+00, float alpha=1.0000e+00, float beta=5.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LRNGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "depth_radius", depth_radius);
    TFE_OpSetAttrFloat(op.get(), "bias", bias);
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);
    TFE_OpSetAttrFloat(op.get(), "beta", beta);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> LSTMBlockCell(const Tensor& x, const Tensor& cs_prev, const Tensor& h_prev, const Tensor& w, const Tensor& wci, const Tensor& wcf, const Tensor& wco, const Tensor& b, float forget_bias=1.0000e+00, float cell_clip=3.0000e+00, bool use_peephole=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LSTMBlockCell", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "forget_bias", forget_bias);
    TFE_OpSetAttrFloat(op.get(), "cell_clip", cell_clip);
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    constexpr auto __kNumOutputs = 7;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> LSTMBlockCellGrad(const Tensor& x, const Tensor& cs_prev, const Tensor& h_prev, const Tensor& w, const Tensor& wci, const Tensor& wcf, const Tensor& wco, const Tensor& b, const Tensor& i, const Tensor& cs, const Tensor& f, const Tensor& o, const Tensor& ci, const Tensor& co, const Tensor& cs_grad, const Tensor& h_grad, bool use_peephole) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LSTMBlockCellGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_prev.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), w.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wcf.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), wco.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), i.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), f.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), o.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ci.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), co.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), cs_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), h_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_peephole", (unsigned char)use_peephole);

    // Execute Op
    constexpr auto __kNumOutputs = 5;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor LatencyStatsDataset(const Tensor& input_dataset, const Tensor& tag, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LatencyStatsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LeakyRelu(const Tensor& features, float alpha=2.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LeakyRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LeakyReluGrad(const Tensor& gradients, const Tensor& features, float alpha=2.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LeakyReluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "alpha", alpha);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> LearnedUnigramCandidateSampler(const Tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LearnedUnigramCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor LeftShift(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LeftShift", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Less(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Less", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LessEqual(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LessEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Lgamma(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Lgamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LinSpace(const Tensor& start, const Tensor& stop, const Tensor& num, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LinSpace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> ListDiff(const Tensor& x, const Tensor& y, datatype out_idx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ListDiff", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor LoadAndRemapMatrix(const Tensor& ckpt_path, const Tensor& old_input_tensor_name, const Tensor& row_remapping, const Tensor& col_remapping, const Tensor& initializing_values, int64_t num_rows, int64_t num_cols, int64_t max_rows_in_memory=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadAndRemapMatrix", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ckpt_path.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), old_input_tensor_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_remapping.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), col_remapping.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), initializing_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_rows", num_rows);
    TFE_OpSetAttrInt(op.get(), "num_cols", num_cols);
    TFE_OpSetAttrInt(op.get(), "max_rows_in_memory", max_rows_in_memory);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void LoadTPUEmbeddingADAMParameters(const Tensor& parameters, const Tensor& momenta, const Tensor& velocities, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingADAMParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), velocities.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingADAMParametersGradAccumDebug(const Tensor& parameters, const Tensor& momenta, const Tensor& velocities, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingADAMParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), velocities.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingAdadeltaParameters(const Tensor& parameters, const Tensor& accumulators, const Tensor& updates, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdadeltaParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingAdadeltaParametersGradAccumDebug(const Tensor& parameters, const Tensor& accumulators, const Tensor& updates, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdadeltaParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingAdagradParameters(const Tensor& parameters, const Tensor& accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingAdagradParametersGradAccumDebug(const Tensor& parameters, const Tensor& accumulators, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingAdagradParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingCenteredRMSPropParameters(const Tensor& parameters, const Tensor& ms, const Tensor& mom, const Tensor& mg, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingCenteredRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingFTRLParameters(const Tensor& parameters, const Tensor& accumulators, const Tensor& linears, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingFTRLParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linears.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingFTRLParametersGradAccumDebug(const Tensor& parameters, const Tensor& accumulators, const Tensor& linears, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingFTRLParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linears.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingFrequencyEstimatorParameters(const Tensor& parameters, const Tensor& last_hit_step, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingFrequencyEstimatorParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), last_hit_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingFrequencyEstimatorParametersGradAccumDebug(const Tensor& parameters, const Tensor& last_hit_step, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingFrequencyEstimatorParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), last_hit_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingMDLAdagradLightParameters(const Tensor& parameters, const Tensor& accumulators, const Tensor& weights, const Tensor& benefits, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingMDLAdagradLightParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), benefits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingMomentumParameters(const Tensor& parameters, const Tensor& momenta, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingMomentumParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingMomentumParametersGradAccumDebug(const Tensor& parameters, const Tensor& momenta, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingMomentumParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momenta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingProximalAdagradParameters(const Tensor& parameters, const Tensor& accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingProximalAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug(const Tensor& parameters, const Tensor& accumulators, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingProximalYogiParameters(const Tensor& parameters, const Tensor& v, const Tensor& m, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingProximalYogiParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingProximalYogiParametersGradAccumDebug(const Tensor& parameters, const Tensor& v, const Tensor& m, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingProximalYogiParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingRMSPropParameters(const Tensor& parameters, const Tensor& ms, const Tensor& mom, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingRMSPropParametersGradAccumDebug(const Tensor& parameters, const Tensor& ms, const Tensor& mom, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingRMSPropParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingStochasticGradientDescentParameters(const Tensor& parameters, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingStochasticGradientDescentParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LoadTPUEmbeddingStochasticGradientDescentParametersGradAccumDebug(const Tensor& parameters, const Tensor& gradient_accumulators, int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoadTPUEmbeddingStochasticGradientDescentParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), parameters.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulators.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Log(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Log", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Log1p(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Log1p", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> LogMatrixDeterminant(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogMatrixDeterminant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor LogSoftmax(const Tensor& logits) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogSoftmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> LogUniformCandidateSampler(const Tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogUniformCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor LogicalAnd(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogicalAnd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LogicalNot(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogicalNot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LogicalOr(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LogicalOr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> LookupTableExport(const Tensor& table_handle, datatype Tkeys, datatype Tvalues) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableExport", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkeys", Tkeys);
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> LookupTableExportV2(const Tensor& table_handle, datatype Tkeys, datatype Tvalues) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableExportV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tkeys", Tkeys);
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor LookupTableFind(const Tensor& table_handle, const Tensor& keys, const Tensor& default_value, datatype Tin, datatype Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableFind", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LookupTableFindV2(const Tensor& table_handle, const Tensor& keys, const Tensor& default_value, datatype Tin, datatype Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableFindV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void LookupTableImport(const Tensor& table_handle, const Tensor& keys, const Tensor& values, datatype Tin, datatype Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableImport", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LookupTableImportV2(const Tensor& table_handle, const Tensor& keys, const Tensor& values, datatype Tin, datatype Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableImportV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LookupTableInsert(const Tensor& table_handle, const Tensor& keys, const Tensor& values, datatype Tin, datatype Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableInsert", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LookupTableInsertV2(const Tensor& table_handle, const Tensor& keys, const Tensor& values, datatype Tin, datatype Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableInsertV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void LookupTableRemoveV2(const Tensor& table_handle, const Tensor& keys, datatype Tin) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableRemoveV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tin", Tin);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor LookupTableSize(const Tensor& table_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LookupTableSizeV2(const Tensor& table_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LookupTableSizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), table_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LoopCond(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LoopCond", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor LowerBound(const Tensor& sorted_inputs, const Tensor& values, datatype out_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "LowerBound", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sorted_inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> Lu(const Tensor& input, datatype output_idx_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Lu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "output_idx_type", output_idx_type);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline void MakeIterator(const Tensor& dataset, const Tensor& iterator) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MakeIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void MapClear(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapClear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor MapIncompleteSize(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapIncompleteSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MapPeek(const Tensor& key, const Tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapPeek", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MapSize(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void MapStage(const Tensor& key, const Tensor& indices, const std::vector<Tensor>& values, const std::vector<datatype>& dtypes, const std::vector<datatype>& fake_dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapStage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrTypeList(op.get(), "fake_dtypes", reinterpret_cast<const enum TF_DataType *>(fake_dtypes.data()), fake_dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor MapUnstage(const Tensor& key, const Tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapUnstage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> MapUnstageNoKey(const Tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MapUnstageNoKey", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor MatMul(const Tensor& a, const Tensor& b, bool transpose_a=false, bool transpose_b=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatchingFiles(const Tensor& pattern) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatchingFiles", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), pattern.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatchingFilesDataset(const Tensor& patterns) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatchingFilesDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), patterns.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixBandPart(const Tensor& input, const Tensor& num_lower, const Tensor& num_upper, datatype Tindex=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixBandPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_lower.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_upper.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindex", Tindex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDeterminant(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDeterminant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDiag(const Tensor& diagonal) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDiagPart(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagPart", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDiagPartV2(const Tensor& input, const Tensor& k, const Tensor& padding_value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagPartV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDiagPartV3(const Tensor& input, const Tensor& k, const Tensor& padding_value, const std::string& align="RIGHT_LEFT") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagPartV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "align", (void*) align.c_str(), align.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDiagV2(const Tensor& diagonal, const Tensor& k, const Tensor& num_rows, const Tensor& num_cols, const Tensor& padding_value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_rows.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_cols.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixDiagV3(const Tensor& diagonal, const Tensor& k, const Tensor& num_rows, const Tensor& num_cols, const Tensor& padding_value, const std::string& align="RIGHT_LEFT") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixDiagV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_rows.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_cols.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), padding_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "align", (void*) align.c_str(), align.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixExponential(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixExponential", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixInverse(const Tensor& input, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixInverse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixLogarithm(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixLogarithm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixSetDiag(const Tensor& input, const Tensor& diagonal) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSetDiag", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixSetDiagV2(const Tensor& input, const Tensor& diagonal, const Tensor& k) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSetDiagV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixSetDiagV3(const Tensor& input, const Tensor& diagonal, const Tensor& k, const std::string& align="RIGHT_LEFT") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSetDiagV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), diagonal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "align", (void*) align.c_str(), align.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixSolve(const Tensor& matrix, const Tensor& rhs, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixSolveLs(const Tensor& matrix, const Tensor& rhs, const Tensor& l2_regularizer, bool fast=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSolveLs", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_regularizer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "fast", (unsigned char)fast);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixSquareRoot(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixSquareRoot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MatrixTriangularSolve(const Tensor& matrix, const Tensor& rhs, bool lower=true, bool adjoint=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MatrixTriangularSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "lower", (unsigned char)lower);
    TFE_OpSetAttrBool(op.get(), "adjoint", (unsigned char)adjoint);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Max(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Max", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxIntraOpParallelismDataset(const Tensor& input_dataset, const Tensor& max_intra_op_parallelism, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxIntraOpParallelismDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_intra_op_parallelism.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPool(const Tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPool3D(const Tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPool3DGrad(const Tensor& orig_input, const Tensor& orig_output, const Tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC", datatype TInput=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool3DGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());
    TFE_OpSetAttrType(op.get(), "TInput", TInput);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPool3DGradGrad(const Tensor& orig_input, const Tensor& orig_output, const Tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NDHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPool3DGradGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolGrad(const Tensor& orig_input, const Tensor& orig_output, const Tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& explicit_paddings, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "explicit_paddings", explicit_paddings.data(), explicit_paddings.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolGradGrad(const Tensor& orig_input, const Tensor& orig_output, const Tensor& grad, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolGradGradV2(const Tensor& orig_input, const Tensor& orig_output, const Tensor& grad, const Tensor& ksize, const Tensor& strides, const std::string& padding, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ksize.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolGradGradWithArgmax(const Tensor& input, const Tensor& grad, const Tensor& argmax, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, datatype Targmax, bool include_batch_in_index=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradGradWithArgmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), argmax.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrType(op.get(), "Targmax", Targmax);
    TFE_OpSetAttrBool(op.get(), "include_batch_in_index", (unsigned char)include_batch_in_index);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolGradV2(const Tensor& orig_input, const Tensor& orig_output, const Tensor& grad, const Tensor& ksize, const Tensor& strides, const std::string& padding, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), orig_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), orig_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ksize.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolGradWithArgmax(const Tensor& input, const Tensor& grad, const Tensor& argmax, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, datatype Targmax, bool include_batch_in_index=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolGradWithArgmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), argmax.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrType(op.get(), "Targmax", Targmax);
    TFE_OpSetAttrBool(op.get(), "include_batch_in_index", (unsigned char)include_batch_in_index);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MaxPoolV2(const Tensor& input, const Tensor& ksize, const Tensor& strides, const std::string& padding, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ksize.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> MaxPoolWithArgmax(const Tensor& input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding, datatype Targmax=static_cast<datatype>(9), bool include_batch_in_index=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MaxPoolWithArgmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrType(op.get(), "Targmax", Targmax);
    TFE_OpSetAttrBool(op.get(), "include_batch_in_index", (unsigned char)include_batch_in_index);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Maximum(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Maximum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Mean(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mean", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> Merge(const std::vector<Tensor>& inputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Merge", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor MergeSummary(const std::vector<Tensor>& inputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MergeSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void MergeV2Checkpoints(const Tensor& checkpoint_prefixes, const Tensor& destination_prefix, bool delete_old_dirs=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MergeV2Checkpoints", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), checkpoint_prefixes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), destination_prefix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "delete_old_dirs", (unsigned char)delete_old_dirs);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Mfcc(const Tensor& spectrogram, const Tensor& sample_rate, float upper_frequency_limit=4.0000e+03, float lower_frequency_limit=2.0000e+01, int64_t filterbank_channel_count=40, int64_t dct_coefficient_count=13) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mfcc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), spectrogram.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "upper_frequency_limit", upper_frequency_limit);
    TFE_OpSetAttrFloat(op.get(), "lower_frequency_limit", lower_frequency_limit);
    TFE_OpSetAttrInt(op.get(), "filterbank_channel_count", filterbank_channel_count);
    TFE_OpSetAttrInt(op.get(), "dct_coefficient_count", dct_coefficient_count);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Min(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Min", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Minimum(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Minimum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MirrorPad(const Tensor& input, const Tensor& paddings, const std::string& mode, datatype Tpaddings=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MirrorPad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MirrorPadGrad(const Tensor& input, const Tensor& paddings, const std::string& mode, datatype Tpaddings=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MirrorPadGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Mod(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ModelDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t algorithm=0, int64_t cpu_budget=0, int64_t ram_budget=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ModelDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "algorithm", algorithm);
    TFE_OpSetAttrInt(op.get(), "cpu_budget", cpu_budget);
    TFE_OpSetAttrInt(op.get(), "ram_budget", ram_budget);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Mul(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Mul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MulNoNan(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MulNoNan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MultiDeviceIterator(const std::vector< std::string>& devices, const std::string& shared_name, const std::string& container, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    std::vector<std::size_t> devices_sizes; devices_sizes.reserve(devices.size());
    std::transform(devices.begin(), devices.end(), std::back_inserter(devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "devices", reinterpret_cast<const void *const *>(devices.data()), devices_sizes.data(), devices.size());
    
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MultiDeviceIteratorFromStringHandle(const Tensor& string_handle, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorFromStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MultiDeviceIteratorGetNextFromShard(const Tensor& multi_device_iterator, const Tensor& shard_num, const Tensor& incarnation_id, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorGetNextFromShard", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), multi_device_iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shard_num.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), incarnation_id.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MultiDeviceIteratorInit(const Tensor& dataset, const Tensor& multi_device_iterator, const Tensor& max_buffer_size) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorInit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), multi_device_iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MultiDeviceIteratorToStringHandle(const Tensor& multi_device_iterator) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MultiDeviceIteratorToStringHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), multi_device_iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Multinomial(const Tensor& logits, const Tensor& num_samples, int64_t seed=0, int64_t seed2=0, datatype output_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Multinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_samples.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutableDenseHashTable(const Tensor& empty_key, datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false, int64_t initial_num_buckets=131072, float max_load_factor=8.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableDenseHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), empty_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), value_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);
    TFE_OpSetAttrInt(op.get(), "initial_num_buckets", initial_num_buckets);
    TFE_OpSetAttrFloat(op.get(), "max_load_factor", max_load_factor);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutableDenseHashTableV2(const Tensor& empty_key, const Tensor& deleted_key, datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false, int64_t initial_num_buckets=131072, float max_load_factor=8.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableDenseHashTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), empty_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deleted_key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), value_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);
    TFE_OpSetAttrInt(op.get(), "initial_num_buckets", initial_num_buckets);
    TFE_OpSetAttrFloat(op.get(), "max_load_factor", max_load_factor);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutableHashTable(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutableHashTableOfTensors(datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTableOfTensors", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), value_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutableHashTableOfTensorsV2(datatype key_dtype, datatype value_dtype, const std::vector<int64_t>& value_shape, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTableOfTensorsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    
    TFE_OpSetAttrShape(op.get(), "value_shape", value_shape.data(), value_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutableHashTableV2(datatype key_dtype, datatype value_dtype, const std::string& container="", const std::string& shared_name="", bool use_node_name_sharing=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutableHashTableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "key_dtype", key_dtype);
    TFE_OpSetAttrType(op.get(), "value_dtype", value_dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrBool(op.get(), "use_node_name_sharing", (unsigned char)use_node_name_sharing);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutexLock(const Tensor& mutex) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutexLock", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), mutex.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor MutexV2(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "MutexV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NcclAllReduce(const Tensor& input, const std::string& reduction, int64_t num_devices, const std::string& shared_name) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NcclAllReduce", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "reduction", (void*) reduction.c_str(), reduction.size());
    TFE_OpSetAttrInt(op.get(), "num_devices", num_devices);
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NcclBroadcast(const Tensor& input, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NcclBroadcast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NcclReduce(const std::vector<Tensor>& input, const std::string& reduction) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NcclReduce", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), input.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "reduction", (void*) reduction.c_str(), reduction.size());
    TFE_OpSetAttrInt(op.get(), "num_devices", input.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Ndtri(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Ndtri", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Neg(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Neg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NextAfter(const Tensor& x1, const Tensor& x2) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NextAfter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NextIteration(const Tensor& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NextIteration", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void NoOp() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NoOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor NonDeterministicInts(const Tensor& shape, datatype dtype=static_cast<datatype>(9), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonDeterministicInts", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NonMaxSuppression(const Tensor& boxes, const Tensor& scores, const Tensor& max_output_size, float iou_threshold=5.0000e-01) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppression", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "iou_threshold", iou_threshold);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NonMaxSuppressionV2(const Tensor& boxes, const Tensor& scores, const Tensor& max_output_size, const Tensor& iou_threshold, datatype T_threshold=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T_threshold", T_threshold);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NonMaxSuppressionV3(const Tensor& boxes, const Tensor& scores, const Tensor& max_output_size, const Tensor& iou_threshold, const Tensor& score_threshold, datatype T_threshold=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T_threshold", T_threshold);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> NonMaxSuppressionV4(const Tensor& boxes, const Tensor& scores, const Tensor& max_output_size, const Tensor& iou_threshold, const Tensor& score_threshold, datatype T_threshold=static_cast<datatype>(1), bool pad_to_max_output_size=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV4", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T_threshold", T_threshold);
    TFE_OpSetAttrBool(op.get(), "pad_to_max_output_size", (unsigned char)pad_to_max_output_size);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> NonMaxSuppressionV5(const Tensor& boxes, const Tensor& scores, const Tensor& max_output_size, const Tensor& iou_threshold, const Tensor& score_threshold, const Tensor& soft_nms_sigma, bool pad_to_max_output_size=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionV5", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), iou_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), soft_nms_sigma.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "pad_to_max_output_size", (unsigned char)pad_to_max_output_size);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor NonMaxSuppressionWithOverlaps(const Tensor& overlaps, const Tensor& scores, const Tensor& max_output_size, const Tensor& overlap_threshold, const Tensor& score_threshold) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonMaxSuppressionWithOverlaps", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), overlaps.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scores.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_output_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), overlap_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), score_threshold.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NonSerializableDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NonSerializableDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NotEqual(const Tensor& x, const Tensor& y, bool incompatible_shape_error=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NotEqual", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "incompatible_shape_error", (unsigned char)incompatible_shape_error);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor NthElement(const Tensor& input, const Tensor& n, bool reverse=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "NthElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "reverse", (unsigned char)reverse);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OneHot(const Tensor& indices, const Tensor& depth, const Tensor& on_value, const Tensor& off_value, int64_t axis=-1, datatype TI=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OneHot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), depth.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), on_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), off_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "axis", axis);
    TFE_OpSetAttrType(op.get(), "TI", TI);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OnesLike(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OnesLike", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptimizeDataset(const Tensor& input_dataset, const Tensor& optimizations, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& optimization_configs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptimizeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> optimization_configs_sizes; optimization_configs_sizes.reserve(optimization_configs.size());
    std::transform(optimization_configs.begin(), optimization_configs.end(), std::back_inserter(optimization_configs_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "optimization_configs", reinterpret_cast<const void *const *>(optimization_configs.data()), optimization_configs_sizes.data(), optimization_configs.size());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptimizeDatasetV2(const Tensor& input_dataset, const Tensor& optimizations_enabled, const Tensor& optimizations_disabled, const Tensor& optimizations_default, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& optimization_configs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptimizeDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations_enabled.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations_disabled.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), optimizations_default.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> optimization_configs_sizes; optimization_configs_sizes.reserve(optimization_configs.size());
    std::transform(optimization_configs.begin(), optimization_configs.end(), std::back_inserter(optimization_configs_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "optimization_configs", reinterpret_cast<const void *const *>(optimization_configs.data()), optimization_configs_sizes.data(), optimization_configs.size());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptionalFromValue(const std::vector<Tensor>& components, const std::vector<datatype>& Toutput_types) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalFromValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), Toutput_types.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptionalGetValue(const Tensor& optional, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalGetValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), optional.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptionalHasValue(const Tensor& optional) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalHasValue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), optional.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptionalNone() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionalNone", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OptionsDataset(const Tensor& input_dataset, const std::string& serialized_options, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OptionsDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "serialized_options", (void*) serialized_options.c_str(), serialized_options.size());
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void OrderedMapClear(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapClear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor OrderedMapIncompleteSize(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapIncompleteSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OrderedMapPeek(const Tensor& key, const Tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapPeek", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OrderedMapSize(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void OrderedMapStage(const Tensor& key, const Tensor& indices, const std::vector<Tensor>& values, const std::vector<datatype>& dtypes, const std::vector<datatype>& fake_dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapStage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrTypeList(op.get(), "fake_dtypes", reinterpret_cast<const enum TF_DataType *>(fake_dtypes.data()), fake_dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor OrderedMapUnstage(const Tensor& key, const Tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapUnstage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> OrderedMapUnstageNoKey(const Tensor& indices, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OrderedMapUnstageNoKey", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor OutfeedDequeue(datatype dtype, const std::vector<int64_t>& shape, int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OutfeedDequeueTuple(const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes, int64_t device_ordinal=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "device_ordinal", device_ordinal);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OutfeedDequeueTupleV2(const Tensor& device_ordinal, const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeueTupleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), device_ordinal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor OutfeedDequeueV2(const Tensor& device_ordinal, datatype dtype, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedDequeueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), device_ordinal.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void OutfeedEnqueue(const Tensor& input, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedEnqueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void OutfeedEnqueueTuple(const std::vector<Tensor>& inputs, const std::vector<datatype>& dtypes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "OutfeedEnqueueTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Pack(const std::vector<Tensor>& values, int64_t axis=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Pack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Pad(const Tensor& input, const Tensor& paddings, datatype Tpaddings=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Pad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PadV2(const Tensor& input, const Tensor& paddings, const Tensor& constant_values, datatype Tpaddings=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PadV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), constant_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PaddedBatchDataset(const Tensor& input_dataset, const Tensor& batch_size, const std::vector<Tensor>& padded_shapes, const std::vector<Tensor>& padding_values, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddedBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padded_shapes_handles; padded_shapes_handles.reserve(padded_shapes.size());
    std::transform(padded_shapes.begin(), padded_shapes.end(), std::back_inserter(padded_shapes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), padded_shapes_handles.data(), padded_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padding_values_handles; padding_values_handles.reserve(padding_values.size());
    std::transform(padding_values.begin(), padding_values.end(), std::back_inserter(padding_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), padding_values_handles.data(), padding_values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), Toutput_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", padded_shapes.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PaddedBatchDatasetV2(const Tensor& input_dataset, const Tensor& batch_size, const std::vector<Tensor>& padded_shapes, const std::vector<Tensor>& padding_values, const Tensor& drop_remainder, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes, bool parallel_copy=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddedBatchDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padded_shapes_handles; padded_shapes_handles.reserve(padded_shapes.size());
    std::transform(padded_shapes.begin(), padded_shapes.end(), std::back_inserter(padded_shapes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), padded_shapes_handles.data(), padded_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> padding_values_handles; padding_values_handles.reserve(padding_values.size());
    std::transform(padding_values.begin(), padding_values.end(), std::back_inserter(padding_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), padding_values_handles.data(), padding_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), Toutput_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", padded_shapes.size());
    TFE_OpSetAttrBool(op.get(), "parallel_copy", (unsigned char)parallel_copy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PaddingFIFOQueue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddingFIFOQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PaddingFIFOQueueV2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PaddingFIFOQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ParallelBatchDataset(const Tensor& input_dataset, const Tensor& batch_size, const Tensor& num_parallel_calls, const Tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& deterministic="default") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelBatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ParallelConcat(const std::vector<Tensor>& values, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ParallelDynamicStitch(const std::vector<Tensor>& indices, const std::vector<Tensor>& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParallelDynamicStitch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), data.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ParameterizedTruncatedNormal(const Tensor& shape, const Tensor& means, const Tensor& stdevs, const Tensor& minvals, const Tensor& maxvals, datatype dtype, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParameterizedTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), means.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stdevs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minvals.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxvals.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> ParseExample(const Tensor& serialized, const Tensor& names, const std::vector<Tensor>& sparse_keys, const std::vector<Tensor>& dense_keys, const std::vector<Tensor>& dense_defaults, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), names.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_keys_handles; sparse_keys_handles.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_keys_handles.data(), sparse_keys.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_keys_handles; dense_keys_handles.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_keys_handles.data(), dense_keys.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "Nsparse", sparse_keys.size());
    TFE_OpSetAttrInt(op.get(), "Ndense", dense_keys.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), Tdense.size());
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor ParseExampleDataset(const Tensor& input_dataset, const Tensor& num_parallel_calls, const std::vector<Tensor>& dense_defaults, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& ragged_keys, const std::vector<datatype>& ragged_value_types, const std::vector<datatype>& ragged_split_types, bool sloppy=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExampleDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), sparse_keys.size());
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), dense_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), Tdense.size());
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> ragged_keys_sizes; ragged_keys_sizes.reserve(ragged_keys.size());
    std::transform(ragged_keys.begin(), ragged_keys.end(), std::back_inserter(ragged_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "ragged_keys", reinterpret_cast<const void *const *>(ragged_keys.data()), ragged_keys_sizes.data(), ragged_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "ragged_value_types", reinterpret_cast<const enum TF_DataType *>(ragged_value_types.data()), ragged_value_types.size());
    TFE_OpSetAttrTypeList(op.get(), "ragged_split_types", reinterpret_cast<const enum TF_DataType *>(ragged_split_types.data()), ragged_split_types.size());
    TFE_OpSetAttrBool(op.get(), "sloppy", (unsigned char)sloppy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ParseExampleDatasetV2(const Tensor& input_dataset, const Tensor& num_parallel_calls, const std::vector<Tensor>& dense_defaults, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::vector< std::string>& ragged_keys, const std::vector<datatype>& ragged_value_types, const std::vector<datatype>& ragged_split_types, const std::string& deterministic="default") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExampleDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_parallel_calls.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), sparse_keys.size());
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), dense_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), Tdense.size());
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> ragged_keys_sizes; ragged_keys_sizes.reserve(ragged_keys.size());
    std::transform(ragged_keys.begin(), ragged_keys.end(), std::back_inserter(ragged_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "ragged_keys", reinterpret_cast<const void *const *>(ragged_keys.data()), ragged_keys_sizes.data(), ragged_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "ragged_value_types", reinterpret_cast<const enum TF_DataType *>(ragged_value_types.data()), ragged_value_types.size());
    TFE_OpSetAttrTypeList(op.get(), "ragged_split_types", reinterpret_cast<const enum TF_DataType *>(ragged_split_types.data()), ragged_split_types.size());
    TFE_OpSetAttrString(op.get(), "deterministic", (void*) deterministic.c_str(), deterministic.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> ParseExampleV2(const Tensor& serialized, const Tensor& names, const Tensor& sparse_keys, const Tensor& dense_keys, const Tensor& ragged_keys, const std::vector<Tensor>& dense_defaults, const std::vector<datatype>& Tdense, int64_t num_sparse, const std::vector<datatype>& sparse_types, const std::vector<datatype>& ragged_value_types, const std::vector<datatype>& ragged_split_types, const std::vector< std::vector<int64_t>>& dense_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseExampleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), names.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ragged_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), Tdense.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse", num_sparse);
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "ragged_value_types", reinterpret_cast<const enum TF_DataType *>(ragged_value_types.data()), ragged_value_types.size());
    TFE_OpSetAttrTypeList(op.get(), "ragged_split_types", reinterpret_cast<const enum TF_DataType *>(ragged_split_types.data()), ragged_split_types.size());
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 6;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ParseSequenceExample(const Tensor& serialized, const Tensor& debug_name, const std::vector<Tensor>& context_dense_defaults, const std::vector< std::string>& feature_list_dense_missing_assumed_empty, const std::vector< std::string>& context_sparse_keys, const std::vector< std::string>& context_dense_keys, const std::vector< std::string>& feature_list_sparse_keys, const std::vector< std::string>& feature_list_dense_keys, const std::vector<datatype>& context_sparse_types, const std::vector<datatype>& Tcontext_dense, const std::vector<datatype>& feature_list_dense_types, const std::vector< std::vector<int64_t>>& context_dense_shapes, const std::vector<datatype>& feature_list_sparse_types, const std::vector< std::vector<int64_t>>& feature_list_dense_shapes, int64_t Ncontext_sparse=0, int64_t Ncontext_dense=0, int64_t Nfeature_list_sparse=0, int64_t Nfeature_list_dense=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSequenceExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), debug_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_defaults_handles; context_dense_defaults_handles.reserve(context_dense_defaults.size());
    std::transform(context_dense_defaults.begin(), context_dense_defaults.end(), std::back_inserter(context_dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), context_dense_defaults_handles.data(), context_dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> feature_list_dense_missing_assumed_empty_sizes; feature_list_dense_missing_assumed_empty_sizes.reserve(feature_list_dense_missing_assumed_empty.size());
    std::transform(feature_list_dense_missing_assumed_empty.begin(), feature_list_dense_missing_assumed_empty.end(), std::back_inserter(feature_list_dense_missing_assumed_empty_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "feature_list_dense_missing_assumed_empty", reinterpret_cast<const void *const *>(feature_list_dense_missing_assumed_empty.data()), feature_list_dense_missing_assumed_empty_sizes.data(), feature_list_dense_missing_assumed_empty.size());
    
    
    std::vector<std::size_t> context_sparse_keys_sizes; context_sparse_keys_sizes.reserve(context_sparse_keys.size());
    std::transform(context_sparse_keys.begin(), context_sparse_keys.end(), std::back_inserter(context_sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "context_sparse_keys", reinterpret_cast<const void *const *>(context_sparse_keys.data()), context_sparse_keys_sizes.data(), context_sparse_keys.size());
    
    
    std::vector<std::size_t> context_dense_keys_sizes; context_dense_keys_sizes.reserve(context_dense_keys.size());
    std::transform(context_dense_keys.begin(), context_dense_keys.end(), std::back_inserter(context_dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "context_dense_keys", reinterpret_cast<const void *const *>(context_dense_keys.data()), context_dense_keys_sizes.data(), context_dense_keys.size());
    
    
    std::vector<std::size_t> feature_list_sparse_keys_sizes; feature_list_sparse_keys_sizes.reserve(feature_list_sparse_keys.size());
    std::transform(feature_list_sparse_keys.begin(), feature_list_sparse_keys.end(), std::back_inserter(feature_list_sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "feature_list_sparse_keys", reinterpret_cast<const void *const *>(feature_list_sparse_keys.data()), feature_list_sparse_keys_sizes.data(), feature_list_sparse_keys.size());
    
    
    std::vector<std::size_t> feature_list_dense_keys_sizes; feature_list_dense_keys_sizes.reserve(feature_list_dense_keys.size());
    std::transform(feature_list_dense_keys.begin(), feature_list_dense_keys.end(), std::back_inserter(feature_list_dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "feature_list_dense_keys", reinterpret_cast<const void *const *>(feature_list_dense_keys.data()), feature_list_dense_keys_sizes.data(), feature_list_dense_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "context_sparse_types", reinterpret_cast<const enum TF_DataType *>(context_sparse_types.data()), context_sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tcontext_dense", reinterpret_cast<const enum TF_DataType *>(Tcontext_dense.data()), Tcontext_dense.size());
    TFE_OpSetAttrTypeList(op.get(), "feature_list_dense_types", reinterpret_cast<const enum TF_DataType *>(feature_list_dense_types.data()), feature_list_dense_types.size());
    
    std::vector<const int64_t*> context_dense_shapes_values; context_dense_shapes_values.reserve(context_dense_shapes.size());
    std::vector<int> context_dense_shapes_ndims; context_dense_shapes_ndims.reserve(context_dense_shapes.size());
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "context_dense_shapes", context_dense_shapes_values.data(), context_dense_shapes_ndims.data(), context_dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "feature_list_sparse_types", reinterpret_cast<const enum TF_DataType *>(feature_list_sparse_types.data()), feature_list_sparse_types.size());
    
    std::vector<const int64_t*> feature_list_dense_shapes_values; feature_list_dense_shapes_values.reserve(feature_list_dense_shapes.size());
    std::vector<int> feature_list_dense_shapes_ndims; feature_list_dense_shapes_ndims.reserve(feature_list_dense_shapes.size());
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "feature_list_dense_shapes", feature_list_dense_shapes_values.data(), feature_list_dense_shapes_ndims.data(), feature_list_dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "Ncontext_sparse", Ncontext_sparse);
    TFE_OpSetAttrInt(op.get(), "Ncontext_dense", Ncontext_dense);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_sparse", Nfeature_list_sparse);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_dense", Nfeature_list_dense);

    // Execute Op
    constexpr auto __kNumOutputs = 9;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ParseSequenceExampleV2(const Tensor& serialized, const Tensor& debug_name, const Tensor& context_sparse_keys, const Tensor& context_dense_keys, const Tensor& context_ragged_keys, const Tensor& feature_list_sparse_keys, const Tensor& feature_list_dense_keys, const Tensor& feature_list_ragged_keys, const Tensor& feature_list_dense_missing_assumed_empty, const std::vector<Tensor>& context_dense_defaults, const std::vector<datatype>& Tcontext_dense, const std::vector<datatype>& context_sparse_types, const std::vector<datatype>& context_ragged_value_types, const std::vector<datatype>& context_ragged_split_types, const std::vector< std::vector<int64_t>>& context_dense_shapes, const std::vector<datatype>& feature_list_dense_types, const std::vector<datatype>& feature_list_sparse_types, const std::vector<datatype>& feature_list_ragged_value_types, const std::vector<datatype>& feature_list_ragged_split_types, const std::vector< std::vector<int64_t>>& feature_list_dense_shapes, int64_t Ncontext_sparse=0, int64_t Nfeature_list_sparse=0, int64_t Nfeature_list_dense=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSequenceExampleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), debug_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), context_sparse_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), context_dense_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), context_ragged_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_sparse_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_dense_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_ragged_keys.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_dense_missing_assumed_empty.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_defaults_handles; context_dense_defaults_handles.reserve(context_dense_defaults.size());
    std::transform(context_dense_defaults.begin(), context_dense_defaults.end(), std::back_inserter(context_dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), context_dense_defaults_handles.data(), context_dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcontext_dense", reinterpret_cast<const enum TF_DataType *>(Tcontext_dense.data()), Tcontext_dense.size());
    TFE_OpSetAttrTypeList(op.get(), "context_sparse_types", reinterpret_cast<const enum TF_DataType *>(context_sparse_types.data()), context_sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "context_ragged_value_types", reinterpret_cast<const enum TF_DataType *>(context_ragged_value_types.data()), context_ragged_value_types.size());
    TFE_OpSetAttrTypeList(op.get(), "context_ragged_split_types", reinterpret_cast<const enum TF_DataType *>(context_ragged_split_types.data()), context_ragged_split_types.size());
    
    std::vector<const int64_t*> context_dense_shapes_values; context_dense_shapes_values.reserve(context_dense_shapes.size());
    std::vector<int> context_dense_shapes_ndims; context_dense_shapes_ndims.reserve(context_dense_shapes.size());
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "context_dense_shapes", context_dense_shapes_values.data(), context_dense_shapes_ndims.data(), context_dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "feature_list_dense_types", reinterpret_cast<const enum TF_DataType *>(feature_list_dense_types.data()), feature_list_dense_types.size());
    TFE_OpSetAttrTypeList(op.get(), "feature_list_sparse_types", reinterpret_cast<const enum TF_DataType *>(feature_list_sparse_types.data()), feature_list_sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "feature_list_ragged_value_types", reinterpret_cast<const enum TF_DataType *>(feature_list_ragged_value_types.data()), feature_list_ragged_value_types.size());
    TFE_OpSetAttrTypeList(op.get(), "feature_list_ragged_split_types", reinterpret_cast<const enum TF_DataType *>(feature_list_ragged_split_types.data()), feature_list_ragged_split_types.size());
    
    std::vector<const int64_t*> feature_list_dense_shapes_values; feature_list_dense_shapes_values.reserve(feature_list_dense_shapes.size());
    std::vector<int> feature_list_dense_shapes_ndims; feature_list_dense_shapes_ndims.reserve(feature_list_dense_shapes.size());
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "feature_list_dense_shapes", feature_list_dense_shapes_values.data(), feature_list_dense_shapes_ndims.data(), feature_list_dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "Ncontext_sparse", Ncontext_sparse);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_sparse", Nfeature_list_sparse);
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_dense", Nfeature_list_dense);

    // Execute Op
    constexpr auto __kNumOutputs = 14;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ParseSingleExample(const Tensor& serialized, const std::vector<Tensor>& dense_defaults, int64_t num_sparse, const std::vector< std::string>& sparse_keys, const std::vector< std::string>& dense_keys, const std::vector<datatype>& sparse_types, const std::vector<datatype>& Tdense, const std::vector< std::vector<int64_t>>& dense_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSingleExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_defaults_handles; dense_defaults_handles.reserve(dense_defaults.size());
    std::transform(dense_defaults.begin(), dense_defaults.end(), std::back_inserter(dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_defaults_handles.data(), dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_sparse", num_sparse);
    
    std::vector<std::size_t> sparse_keys_sizes; sparse_keys_sizes.reserve(sparse_keys.size());
    std::transform(sparse_keys.begin(), sparse_keys.end(), std::back_inserter(sparse_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "sparse_keys", reinterpret_cast<const void *const *>(sparse_keys.data()), sparse_keys_sizes.data(), sparse_keys.size());
    
    
    std::vector<std::size_t> dense_keys_sizes; dense_keys_sizes.reserve(dense_keys.size());
    std::transform(dense_keys.begin(), dense_keys.end(), std::back_inserter(dense_keys_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "dense_keys", reinterpret_cast<const void *const *>(dense_keys.data()), dense_keys_sizes.data(), dense_keys.size());
    
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tdense", reinterpret_cast<const enum TF_DataType *>(Tdense.data()), Tdense.size());
    
    std::vector<const int64_t*> dense_shapes_values; dense_shapes_values.reserve(dense_shapes.size());
    std::vector<int> dense_shapes_ndims; dense_shapes_ndims.reserve(dense_shapes.size());
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(dense_shapes.begin(), dense_shapes.end(), std::back_inserter(dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "dense_shapes", dense_shapes_values.data(), dense_shapes_ndims.data(), dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ParseSingleSequenceExample(const Tensor& serialized, const Tensor& feature_list_dense_missing_assumed_empty, const std::vector<Tensor>& context_sparse_keys, const std::vector<Tensor>& context_dense_keys, const std::vector<Tensor>& feature_list_sparse_keys, const std::vector<Tensor>& feature_list_dense_keys, const std::vector<Tensor>& context_dense_defaults, const Tensor& debug_name, const std::vector<datatype>& context_sparse_types, const std::vector<datatype>& Tcontext_dense, const std::vector<datatype>& feature_list_dense_types, const std::vector< std::vector<int64_t>>& context_dense_shapes, const std::vector<datatype>& feature_list_sparse_types, const std::vector< std::vector<int64_t>>& feature_list_dense_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseSingleSequenceExample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), feature_list_dense_missing_assumed_empty.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_sparse_keys_handles; context_sparse_keys_handles.reserve(context_sparse_keys.size());
    std::transform(context_sparse_keys.begin(), context_sparse_keys.end(), std::back_inserter(context_sparse_keys_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), context_sparse_keys_handles.data(), context_sparse_keys.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_keys_handles; context_dense_keys_handles.reserve(context_dense_keys.size());
    std::transform(context_dense_keys.begin(), context_dense_keys.end(), std::back_inserter(context_dense_keys_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), context_dense_keys_handles.data(), context_dense_keys.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> feature_list_sparse_keys_handles; feature_list_sparse_keys_handles.reserve(feature_list_sparse_keys.size());
    std::transform(feature_list_sparse_keys.begin(), feature_list_sparse_keys.end(), std::back_inserter(feature_list_sparse_keys_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), feature_list_sparse_keys_handles.data(), feature_list_sparse_keys.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> feature_list_dense_keys_handles; feature_list_dense_keys_handles.reserve(feature_list_dense_keys.size());
    std::transform(feature_list_dense_keys.begin(), feature_list_dense_keys.end(), std::back_inserter(feature_list_dense_keys_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), feature_list_dense_keys_handles.data(), feature_list_dense_keys.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> context_dense_defaults_handles; context_dense_defaults_handles.reserve(context_dense_defaults.size());
    std::transform(context_dense_defaults.begin(), context_dense_defaults.end(), std::back_inserter(context_dense_defaults_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), context_dense_defaults_handles.data(), context_dense_defaults.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), debug_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "context_sparse_types", reinterpret_cast<const enum TF_DataType *>(context_sparse_types.data()), context_sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "Tcontext_dense", reinterpret_cast<const enum TF_DataType *>(Tcontext_dense.data()), Tcontext_dense.size());
    TFE_OpSetAttrTypeList(op.get(), "feature_list_dense_types", reinterpret_cast<const enum TF_DataType *>(feature_list_dense_types.data()), feature_list_dense_types.size());
    
    std::vector<const int64_t*> context_dense_shapes_values; context_dense_shapes_values.reserve(context_dense_shapes.size());
    std::vector<int> context_dense_shapes_ndims; context_dense_shapes_ndims.reserve(context_dense_shapes.size());
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(context_dense_shapes.begin(), context_dense_shapes.end(), std::back_inserter(context_dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "context_dense_shapes", context_dense_shapes_values.data(), context_dense_shapes_ndims.data(), context_dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrTypeList(op.get(), "feature_list_sparse_types", reinterpret_cast<const enum TF_DataType *>(feature_list_sparse_types.data()), feature_list_sparse_types.size());
    
    std::vector<const int64_t*> feature_list_dense_shapes_values; feature_list_dense_shapes_values.reserve(feature_list_dense_shapes.size());
    std::vector<int> feature_list_dense_shapes_ndims; feature_list_dense_shapes_ndims.reserve(feature_list_dense_shapes.size());
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_values), [](const auto& v) { return v.data();});
    std::transform(feature_list_dense_shapes.begin(), feature_list_dense_shapes.end(), std::back_inserter(feature_list_dense_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "feature_list_dense_shapes", feature_list_dense_shapes_values.data(), feature_list_dense_shapes_ndims.data(), feature_list_dense_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "Ncontext_sparse", context_sparse_keys.size());
    TFE_OpSetAttrInt(op.get(), "Ncontext_dense", context_dense_keys.size());
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_sparse", feature_list_sparse_keys.size());
    TFE_OpSetAttrInt(op.get(), "Nfeature_list_dense", feature_list_dense_keys.size());

    // Execute Op
    constexpr auto __kNumOutputs = 8;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor ParseTensor(const Tensor& serialized, datatype out_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ParseTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), serialized.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Placeholder(datatype dtype, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Placeholder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PlaceholderV2(datatype dtype, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PlaceholderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PlaceholderWithDefault(const Tensor& input, datatype dtype, const std::vector<int64_t>& shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PlaceholderWithDefault", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Polygamma(const Tensor& a, const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Polygamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PopulationCount(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PopulationCount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Pow(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Pow", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PrefetchDataset(const Tensor& input_dataset, const Tensor& buffer_size, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, int64_t slack_period=0, bool legacy_autotune=true, int64_t buffer_size_min=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrefetchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "slack_period", slack_period);
    TFE_OpSetAttrBool(op.get(), "legacy_autotune", (unsigned char)legacy_autotune);
    TFE_OpSetAttrInt(op.get(), "buffer_size_min", buffer_size_min);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Prelinearize(const Tensor& input, datatype dtype, const std::vector<int64_t>& shape, const std::vector<int64_t>& layout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Prelinearize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layout", layout.data(), layout.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PrelinearizeTuple(const std::vector<Tensor>& inputs, const std::vector<datatype>& dtypes, const std::vector< std::vector<int64_t>>& shapes, const std::vector<int64_t>& layouts) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrelinearizeTuple", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrIntList(op.get(), "layouts", layouts.data(), layouts.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PreventGradient(const Tensor& input, const std::string& message="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PreventGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Print(const Tensor& input, const std::vector<Tensor>& data, const std::vector<datatype>& U, const std::string& message="", int64_t first_n=-1, int64_t summarize=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Print", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), data.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "U", reinterpret_cast<const enum TF_DataType *>(U.data()), U.size());
    TFE_OpSetAttrString(op.get(), "message", (void*) message.c_str(), message.size());
    TFE_OpSetAttrInt(op.get(), "first_n", first_n);
    TFE_OpSetAttrInt(op.get(), "summarize", summarize);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void PrintV2(const Tensor& input, const std::string& output_stream="stderr", const std::string& end="\n") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrintV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "output_stream", (void*) output_stream.c_str(), output_stream.size());
    TFE_OpSetAttrString(op.get(), "end", (void*) end.c_str(), end.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor PriorityQueue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PriorityQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PriorityQueueV2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PriorityQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PrivateThreadPoolDataset(const Tensor& input_dataset, const Tensor& num_threads, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PrivateThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_threads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Prod(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Prod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PyFunc(const std::vector<Tensor>& input, const std::string& token, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PyFunc", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), input.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "token", (void*) token.c_str(), token.size());
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), Tin.size());
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), Tout.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor PyFuncStateless(const std::vector<Tensor>& input, const std::string& token, const std::vector<datatype>& Tin, const std::vector<datatype>& Tout) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "PyFuncStateless", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), input.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "token", (void*) token.c_str(), token.size());
    TFE_OpSetAttrTypeList(op.get(), "Tin", reinterpret_cast<const enum TF_DataType *>(Tin.data()), Tin.size());
    TFE_OpSetAttrTypeList(op.get(), "Tout", reinterpret_cast<const enum TF_DataType *>(Tout.data()), Tout.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> Qr(const Tensor& input, bool full_matrices=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Qr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "full_matrices", (unsigned char)full_matrices);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor QuantizeAndDequantize(const Tensor& input, bool signed_input=true, int64_t num_bits=8, bool range_given=false, float input_min=0.0000e+00, float input_max=0.0000e+00) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrFloat(op.get(), "input_min", input_min);
    TFE_OpSetAttrFloat(op.get(), "input_max", input_max);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QuantizeAndDequantizeV2(const Tensor& input, const Tensor& input_min, const Tensor& input_max, bool signed_input=true, int64_t num_bits=8, bool range_given=false, const std::string& round_mode="HALF_TO_EVEN", bool narrow_range=false, int64_t axis=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrString(op.get(), "round_mode", (void*) round_mode.c_str(), round_mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QuantizeAndDequantizeV3(const Tensor& input, const Tensor& input_min, const Tensor& input_max, const Tensor& num_bits, bool signed_input=true, bool range_given=true, bool narrow_range=false, int64_t axis=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_bits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QuantizeAndDequantizeV4(const Tensor& input, const Tensor& input_min, const Tensor& input_max, bool signed_input=true, int64_t num_bits=8, bool range_given=false, const std::string& round_mode="HALF_TO_EVEN", bool narrow_range=false, int64_t axis=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV4", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "signed_input", (unsigned char)signed_input);
    TFE_OpSetAttrInt(op.get(), "num_bits", num_bits);
    TFE_OpSetAttrBool(op.get(), "range_given", (unsigned char)range_given);
    TFE_OpSetAttrString(op.get(), "round_mode", (void*) round_mode.c_str(), round_mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> QuantizeAndDequantizeV4Grad(const Tensor& gradients, const Tensor& input, const Tensor& input_min, const Tensor& input_max, int64_t axis=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeAndDequantizeV4Grad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizeDownAndShrinkRange(const Tensor& input, const Tensor& input_min, const Tensor& input_max, datatype Tinput, datatype out_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeDownAndShrinkRange", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizeV2(const Tensor& input, const Tensor& min_range, const Tensor& max_range, const std::string& mode="MIN_COMBINED", const std::string& round_mode="HALF_AWAY_FROM_ZERO", bool narrow_range=false, int64_t axis=-1, float ensure_minimum_range=1.0000e-02) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_range.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrString(op.get(), "round_mode", (void*) round_mode.c_str(), round_mode.size());
    TFE_OpSetAttrBool(op.get(), "narrow_range", (unsigned char)narrow_range);
    TFE_OpSetAttrInt(op.get(), "axis", axis);
    TFE_OpSetAttrFloat(op.get(), "ensure_minimum_range", ensure_minimum_range);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedAdd(const Tensor& x, const Tensor& y, const Tensor& min_x, const Tensor& max_x, const Tensor& min_y, const Tensor& max_y, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedAvgPool(const Tensor& input, const Tensor& min_input, const Tensor& max_input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedAvgPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedBatchNormWithGlobalNormalization(const Tensor& t, const Tensor& t_min, const Tensor& t_max, const Tensor& m, const Tensor& m_min, const Tensor& m_max, const Tensor& v, const Tensor& v_min, const Tensor& v_max, const Tensor& beta, const Tensor& beta_min, const Tensor& beta_max, const Tensor& gamma, const Tensor& gamma_min, const Tensor& gamma_max, datatype Tinput, datatype out_type, float variance_epsilon, bool scale_after_normalization) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedBatchNormWithGlobalNormalization", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gamma_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrBool(op.get(), "scale_after_normalization", (unsigned char)scale_after_normalization);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedBiasAdd(const Tensor& input, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_bias, const Tensor& max_bias, datatype T1, datatype T2, datatype out_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedBiasAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConcat(const Tensor& concat_dim, const std::vector<Tensor>& values, const std::vector<Tensor>& input_mins, const std::vector<Tensor>& input_maxes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), concat_dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_mins_handles; input_mins_handles.reserve(input_mins.size());
    std::transform(input_mins.begin(), input_mins.end(), std::back_inserter(input_mins_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_mins_handles.data(), input_mins.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> input_maxes_handles; input_maxes_handles.reserve(input_maxes.size());
    std::transform(input_maxes.begin(), input_maxes.end(), std::back_inserter(input_maxes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_maxes_handles.data(), input_maxes.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", values.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2D(const Tensor& input, const Tensor& filter, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DAndRelu(const Tensor& input, const Tensor& filter, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DAndReluAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(11)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DPerChannel(const Tensor& input, const Tensor& filter, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DPerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBias(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBiasAndRelu(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBiasAndReluAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype Tinput, datatype Tfilter, datatype Tbias, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBiasAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype Tinput, datatype Tfilter, datatype Tbias, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(11)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBiasSignedSumAndReluAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, const Tensor& summand, const Tensor& min_summand, const Tensor& max_summand, datatype Tinput, datatype Tfilter, datatype Tbias, datatype Tsummand, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasSignedSumAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Tsummand", Tsummand);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBiasSumAndRelu(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& summand, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasSumAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedConv2DWithBiasSumAndReluAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, const Tensor& summand, const Tensor& min_summand, const Tensor& max_summand, datatype Tinput, datatype Tfilter, datatype Tbias, datatype Tsummand, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedConv2DWithBiasSumAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_summand.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Tsummand", Tsummand);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedDepthwiseConv2D(const Tensor& input, const Tensor& filter, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedDepthwiseConv2DWithBias(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2DWithBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedDepthwiseConv2DWithBiasAndRelu(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, datatype Tinput, datatype Tfilter, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2DWithBiasAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize(const Tensor& input, const Tensor& filter, const Tensor& bias, const Tensor& min_input, const Tensor& max_input, const Tensor& min_filter, const Tensor& max_filter, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype Tinput, datatype Tfilter, datatype Tbias, const std::vector<int64_t>& strides, const std::string& padding, const std::vector<int64_t>& dilations, const std::vector<int64_t>& padding_list, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_filter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "Tfilter", Tfilter);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());
    TFE_OpSetAttrIntList(op.get(), "dilations", dilations.data(), dilations.size());
    TFE_OpSetAttrIntList(op.get(), "padding_list", padding_list.data(), padding_list.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedInstanceNorm(const Tensor& x, const Tensor& x_min, const Tensor& x_max, bool output_range_given=false, float given_y_min=0.0000e+00, float given_y_max=0.0000e+00, float variance_epsilon=1.0000e-05, float min_separation=1.0000e-03) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedInstanceNorm", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), x_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "output_range_given", (unsigned char)output_range_given);
    TFE_OpSetAttrFloat(op.get(), "given_y_min", given_y_min);
    TFE_OpSetAttrFloat(op.get(), "given_y_max", given_y_max);
    TFE_OpSetAttrFloat(op.get(), "variance_epsilon", variance_epsilon);
    TFE_OpSetAttrFloat(op.get(), "min_separation", min_separation);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedMatMul(const Tensor& a, const Tensor& b, const Tensor& min_a, const Tensor& max_a, const Tensor& min_b, const Tensor& max_b, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13), bool transpose_a=false, bool transpose_b=false, datatype Tactivation=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrType(op.get(), "Tactivation", Tactivation);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedMatMulWithBias(const Tensor& a, const Tensor& b, const Tensor& bias, const Tensor& min_a, const Tensor& max_a, const Tensor& min_b, const Tensor& max_b, datatype T1, datatype T2, datatype Tbias, datatype Toutput=static_cast<datatype>(13), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBias", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor QuantizedMatMulWithBiasAndDequantize(const Tensor& a, const Tensor& b, const Tensor& bias, const Tensor& min_a, const Tensor& max_a, const Tensor& min_b, const Tensor& max_b, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype T1, datatype T2, datatype Tbias, datatype Toutput, bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndDequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> QuantizedMatMulWithBiasAndRelu(const Tensor& a, const Tensor& b, const Tensor& bias, const Tensor& min_a, const Tensor& max_a, const Tensor& min_b, const Tensor& max_b, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedMatMulWithBiasAndReluAndRequantize(const Tensor& a, const Tensor& b, const Tensor& bias, const Tensor& min_a, const Tensor& max_a, const Tensor& min_b, const Tensor& max_b, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype T1, datatype T2, datatype Tbias, datatype Toutput=static_cast<datatype>(12), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndReluAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedMatMulWithBiasAndRequantize(const Tensor& a, const Tensor& b, const Tensor& bias, const Tensor& min_a, const Tensor& max_a, const Tensor& min_b, const Tensor& max_b, const Tensor& min_freezed_output, const Tensor& max_freezed_output, datatype T1, datatype T2, datatype Tbias, datatype Toutput=static_cast<datatype>(12), bool transpose_a=false, bool transpose_b=false, const std::string& input_quant_mode="MIN_FIRST") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMatMulWithBiasAndRequantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bias.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_freezed_output.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Tbias", Tbias);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrString(op.get(), "input_quant_mode", (void*) input_quant_mode.c_str(), input_quant_mode.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedMaxPool(const Tensor& input, const Tensor& min_input, const Tensor& max_input, const std::vector<int64_t>& ksize, const std::vector<int64_t>& strides, const std::string& padding) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMaxPool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "ksize", ksize.data(), ksize.size());
    TFE_OpSetAttrIntList(op.get(), "strides", strides.data(), strides.size());
    TFE_OpSetAttrString(op.get(), "padding", (void*) padding.c_str(), padding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedMul(const Tensor& x, const Tensor& y, const Tensor& min_x, const Tensor& max_x, const Tensor& min_y, const Tensor& max_y, datatype T1, datatype T2, datatype Toutput=static_cast<datatype>(13)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "T1", T1);
    TFE_OpSetAttrType(op.get(), "T2", T2);
    TFE_OpSetAttrType(op.get(), "Toutput", Toutput);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedRelu(const Tensor& features, const Tensor& min_features, const Tensor& max_features, datatype Tinput, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedRelu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedRelu6(const Tensor& features, const Tensor& min_features, const Tensor& max_features, datatype Tinput, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedRelu6", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedReluX(const Tensor& features, const Tensor& max_value, const Tensor& min_features, const Tensor& max_features, datatype Tinput, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedReluX", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max_features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedReshape(const Tensor& input_tensor, const Tensor& shape, const Tensor& input_min, const Tensor& input_max, datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedReshape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> QuantizedResizeBilinear(const Tensor& images, const Tensor& size, const Tensor& min, const Tensor& max, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QuantizedResizeBilinear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline void QueueClose(const Tensor& handle, bool cancel_pending_enqueues=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "cancel_pending_enqueues", (unsigned char)cancel_pending_enqueues);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void QueueCloseV2(const Tensor& handle, bool cancel_pending_enqueues=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueCloseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "cancel_pending_enqueues", (unsigned char)cancel_pending_enqueues);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor QueueDequeue(const Tensor& handle, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueDequeueMany(const Tensor& handle, const Tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueDequeueManyV2(const Tensor& handle, const Tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueManyV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueDequeueUpTo(const Tensor& handle, const Tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueDequeueUpToV2(const Tensor& handle, const Tensor& n, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueUpToV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), n.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueDequeueV2(const Tensor& handle, const std::vector<datatype>& component_types, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueDequeueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void QueueEnqueue(const Tensor& handle, const std::vector<Tensor>& components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), Tcomponents.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void QueueEnqueueMany(const Tensor& handle, const std::vector<Tensor>& components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueueMany", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), Tcomponents.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void QueueEnqueueManyV2(const Tensor& handle, const std::vector<Tensor>& components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueueManyV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), Tcomponents.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void QueueEnqueueV2(const Tensor& handle, const std::vector<Tensor>& components, const std::vector<datatype>& Tcomponents, int64_t timeout_ms=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueEnqueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Tcomponents", reinterpret_cast<const enum TF_DataType *>(Tcomponents.data()), Tcomponents.size());
    TFE_OpSetAttrInt(op.get(), "timeout_ms", timeout_ms);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor QueueIsClosed(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueIsClosed", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueIsClosedV2(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueIsClosedV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueSize(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor QueueSizeV2(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "QueueSizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RFFT(const Tensor& input, const Tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFT", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RFFT2D(const Tensor& input, const Tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFT2D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RFFT3D(const Tensor& input, const Tensor& fft_length, datatype Treal=static_cast<datatype>(1), datatype Tcomplex=static_cast<datatype>(8)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RFFT3D", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), fft_length.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);
    TFE_OpSetAttrType(op.get(), "Tcomplex", Tcomplex);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RGBToHSV(const Tensor& images) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RGBToHSV", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RaggedBincount(const Tensor& splits, const Tensor& values, const Tensor& size, const Tensor& weights, datatype Tidx, bool binary_output=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedBincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), splits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> RaggedCountSparseOutput(const Tensor& splits, const Tensor& values, const Tensor& weights, bool binary_output, datatype output_type, int64_t minlength=-1, int64_t maxlength=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedCountSparseOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), splits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);
    TFE_OpSetAttrInt(op.get(), "minlength", minlength);
    TFE_OpSetAttrInt(op.get(), "maxlength", maxlength);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RaggedCross(const std::vector<Tensor>& ragged_values, const std::vector<Tensor>& ragged_row_splits, const std::vector<Tensor>& sparse_indices, const std::vector<Tensor>& sparse_values, const std::vector<Tensor>& sparse_shape, const std::vector<Tensor>& dense_inputs, const std::string& input_order, bool hashed_output, int64_t num_buckets, int64_t hash_key, const std::vector<datatype>& ragged_values_types, const std::vector<datatype>& ragged_splits_types, const std::vector<datatype>& sparse_values_types, const std::vector<datatype>& dense_types, datatype out_values_type, datatype out_row_splits_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedCross", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> ragged_values_handles; ragged_values_handles.reserve(ragged_values.size());
    std::transform(ragged_values.begin(), ragged_values.end(), std::back_inserter(ragged_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), ragged_values_handles.data(), ragged_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> ragged_row_splits_handles; ragged_row_splits_handles.reserve(ragged_row_splits.size());
    std::transform(ragged_row_splits.begin(), ragged_row_splits.end(), std::back_inserter(ragged_row_splits_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), ragged_row_splits_handles.data(), ragged_row_splits.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_indices_handles; sparse_indices_handles.reserve(sparse_indices.size());
    std::transform(sparse_indices.begin(), sparse_indices.end(), std::back_inserter(sparse_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_indices_handles.data(), sparse_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_values_handles; sparse_values_handles.reserve(sparse_values.size());
    std::transform(sparse_values.begin(), sparse_values.end(), std::back_inserter(sparse_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_values_handles.data(), sparse_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_shape_handles; sparse_shape_handles.reserve(sparse_shape.size());
    std::transform(sparse_shape.begin(), sparse_shape.end(), std::back_inserter(sparse_shape_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_shape_handles.data(), sparse_shape.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), dense_inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "Nsparse", sparse_indices.size());
    TFE_OpSetAttrString(op.get(), "input_order", (void*) input_order.c_str(), input_order.size());
    TFE_OpSetAttrBool(op.get(), "hashed_output", (unsigned char)hashed_output);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrInt(op.get(), "hash_key", hash_key);
    TFE_OpSetAttrTypeList(op.get(), "ragged_values_types", reinterpret_cast<const enum TF_DataType *>(ragged_values_types.data()), ragged_values_types.size());
    TFE_OpSetAttrTypeList(op.get(), "ragged_splits_types", reinterpret_cast<const enum TF_DataType *>(ragged_splits_types.data()), ragged_splits_types.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_values_types", reinterpret_cast<const enum TF_DataType *>(sparse_values_types.data()), sparse_values_types.size());
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), dense_types.size());
    TFE_OpSetAttrType(op.get(), "out_values_type", out_values_type);
    TFE_OpSetAttrType(op.get(), "out_row_splits_type", out_row_splits_type);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RaggedGather(const std::vector<Tensor>& params_nested_splits, const Tensor& params_dense_values, const Tensor& indices, datatype Tvalues, datatype Tindices, int64_t OUTPUT_RAGGED_RANK, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> params_nested_splits_handles; params_nested_splits_handles.reserve(params_nested_splits.size());
    std::transform(params_nested_splits.begin(), params_nested_splits.end(), std::back_inserter(params_nested_splits_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), params_nested_splits_handles.data(), params_nested_splits.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), params_dense_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrInt(op.get(), "PARAMS_RAGGED_RANK", params_nested_splits.size());
    TFE_OpSetAttrInt(op.get(), "OUTPUT_RAGGED_RANK", OUTPUT_RAGGED_RANK);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RaggedRange(const Tensor& starts, const Tensor& limits, const Tensor& deltas, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedRange", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), starts.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), limits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), deltas.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RaggedTensorFromVariant(const Tensor& encoded_ragged, int64_t input_ragged_rank, int64_t output_ragged_rank, datatype Tvalues, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorFromVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), encoded_ragged.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "input_ragged_rank", input_ragged_rank);
    TFE_OpSetAttrInt(op.get(), "output_ragged_rank", output_ragged_rank);
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RaggedTensorToSparse(const std::vector<Tensor>& rt_nested_splits, const Tensor& rt_dense_values, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> rt_nested_splits_handles; rt_nested_splits_handles.reserve(rt_nested_splits.size());
    std::transform(rt_nested_splits.begin(), rt_nested_splits.end(), std::back_inserter(rt_nested_splits_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), rt_nested_splits_handles.data(), rt_nested_splits.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rt_dense_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "RAGGED_RANK", rt_nested_splits.size());
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor RaggedTensorToTensor(const Tensor& shape, const Tensor& values, const Tensor& default_value, const std::vector<Tensor>& row_partition_tensors, datatype Tindex, datatype Tshape, const std::vector< std::string>& row_partition_types) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> row_partition_tensors_handles; row_partition_tensors_handles.reserve(row_partition_tensors.size());
    std::transform(row_partition_tensors.begin(), row_partition_tensors.end(), std::back_inserter(row_partition_tensors_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), row_partition_tensors_handles.data(), row_partition_tensors.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindex", Tindex);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);
    TFE_OpSetAttrInt(op.get(), "num_row_partition_tensors", row_partition_tensors.size());
    
    std::vector<std::size_t> row_partition_types_sizes; row_partition_types_sizes.reserve(row_partition_types.size());
    std::transform(row_partition_types.begin(), row_partition_types.end(), std::back_inserter(row_partition_types_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "row_partition_types", reinterpret_cast<const void *const *>(row_partition_types.data()), row_partition_types_sizes.data(), row_partition_types.size());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RaggedTensorToVariant(const std::vector<Tensor>& rt_nested_splits, const Tensor& rt_dense_values, datatype Tvalues, bool batched_input, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> rt_nested_splits_handles; rt_nested_splits_handles.reserve(rt_nested_splits.size());
    std::transform(rt_nested_splits.begin(), rt_nested_splits.end(), std::back_inserter(rt_nested_splits_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), rt_nested_splits_handles.data(), rt_nested_splits.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rt_dense_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "RAGGED_RANK", rt_nested_splits.size());
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrBool(op.get(), "batched_input", (unsigned char)batched_input);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RaggedTensorToVariantGradient(const Tensor& encoded_ragged_grad, const Tensor& row_splits, const Tensor& dense_values_shape, datatype Tvalues, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RaggedTensorToVariantGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), encoded_ragged_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), row_splits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_values_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomCrop(const Tensor& image, const Tensor& size, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomCrop", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomDataset(const Tensor& seed, const Tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomGamma(const Tensor& shape, const Tensor& alpha, datatype S, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomGamma", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomGammaGrad(const Tensor& alpha, const Tensor& sample) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomGammaGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomPoisson(const Tensor& shape, const Tensor& rate, datatype S, datatype dtype, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomPoisson", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomPoissonV2(const Tensor& shape, const Tensor& rate, datatype S, int64_t seed=0, int64_t seed2=0, datatype R=static_cast<datatype>(2), datatype dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomPoissonV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrType(op.get(), "R", R);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomShuffle(const Tensor& value, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomShuffle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomShuffleQueue(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, int64_t min_after_dequeue=0, int64_t seed=0, int64_t seed2=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomShuffleQueue", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "min_after_dequeue", min_after_dequeue);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomShuffleQueueV2(const std::vector<datatype>& component_types, const std::vector< std::vector<int64_t>>& shapes, int64_t capacity=-1, int64_t min_after_dequeue=0, int64_t seed=0, int64_t seed2=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomShuffleQueueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "component_types", reinterpret_cast<const enum TF_DataType *>(component_types.data()), component_types.size());
    
    std::vector<const int64_t*> shapes_values; shapes_values.reserve(shapes.size());
    std::vector<int> shapes_ndims; shapes_ndims.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_values), [](const auto& v) { return v.data();});
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "shapes", shapes_values.data(), shapes_ndims.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "min_after_dequeue", min_after_dequeue);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomStandardNormal(const Tensor& shape, datatype dtype, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomStandardNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomUniform(const Tensor& shape, datatype dtype, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomUniform", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RandomUniformInt(const Tensor& shape, const Tensor& minval, const Tensor& maxval, datatype Tout, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RandomUniformInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Range(const Tensor& start, const Tensor& limit, const Tensor& delta, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Range", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), limit.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RangeDataset(const Tensor& start, const Tensor& stop, const Tensor& step, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RangeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), start.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stop.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Rank(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Rank", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReadFile(const Tensor& filename) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReadFile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReadVariableOp(const Tensor& resource, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReadVariableOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReaderNumRecordsProduced(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumRecordsProduced", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReaderNumRecordsProducedV2(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumRecordsProducedV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReaderNumWorkUnitsCompleted(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumWorkUnitsCompleted", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReaderNumWorkUnitsCompletedV2(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderNumWorkUnitsCompletedV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> ReaderRead(const Tensor& reader_handle, const Tensor& queue_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderRead", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ReaderReadUpTo(const Tensor& reader_handle, const Tensor& queue_handle, const Tensor& num_records) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReadUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_records.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ReaderReadUpToV2(const Tensor& reader_handle, const Tensor& queue_handle, const Tensor& num_records) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReadUpToV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_records.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> ReaderReadV2(const Tensor& reader_handle, const Tensor& queue_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReadV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), queue_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline void ReaderReset(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderReset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ReaderResetV2(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderResetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ReaderRestoreState(const Tensor& reader_handle, const Tensor& state) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderRestoreState", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), state.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ReaderRestoreStateV2(const Tensor& reader_handle, const Tensor& state) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderRestoreStateV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), state.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor ReaderSerializeState(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderSerializeState", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReaderSerializeStateV2(const Tensor& reader_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReaderSerializeStateV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reader_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Real(const Tensor& input, datatype Tout=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Real", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tout", Tout);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RealDiv(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RealDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RebatchDataset(const Tensor& input_dataset, const Tensor& num_replicas, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool use_fallback=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RebatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_replicas.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "use_fallback", (unsigned char)use_fallback);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RebatchDatasetV2(const Tensor& input_dataset, const Tensor& batch_sizes, const Tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RebatchDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_sizes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Reciprocal(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Reciprocal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReciprocalGrad(const Tensor& y, const Tensor& dy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReciprocalGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RecordInput(const std::string& file_pattern, int64_t file_random_seed=301, float file_shuffle_shift_ratio=0.0000e+00, int64_t file_buffer_size=10000, int64_t file_parallelism=16, int64_t batch_size=32, const std::string& compression_type="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RecordInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "file_pattern", (void*) file_pattern.c_str(), file_pattern.size());
    TFE_OpSetAttrInt(op.get(), "file_random_seed", file_random_seed);
    TFE_OpSetAttrFloat(op.get(), "file_shuffle_shift_ratio", file_shuffle_shift_ratio);
    TFE_OpSetAttrInt(op.get(), "file_buffer_size", file_buffer_size);
    TFE_OpSetAttrInt(op.get(), "file_parallelism", file_parallelism);
    TFE_OpSetAttrInt(op.get(), "batch_size", batch_size);
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Recv(datatype tensor_type, const std::string& tensor_name, const std::string& send_device, int64_t send_device_incarnation, const std::string& recv_device, bool client_terminated=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Recv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "tensor_type", tensor_type);
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrString(op.get(), "send_device", (void*) send_device.c_str(), send_device.size());
    TFE_OpSetAttrInt(op.get(), "send_device_incarnation", send_device_incarnation);
    TFE_OpSetAttrString(op.get(), "recv_device", (void*) recv_device.c_str(), recv_device.size());
    TFE_OpSetAttrBool(op.get(), "client_terminated", (unsigned char)client_terminated);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RecvTPUEmbeddingActivations(int64_t num_outputs, const std::string& config) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RecvTPUEmbeddingActivations", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_outputs", num_outputs);
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReduceJoin(const Tensor& inputs, const Tensor& reduction_indices, bool keep_dims=false, const std::string& separator="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReduceJoin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RefEnter(const Tensor& data, const std::string& frame_name, bool is_constant=false, int64_t parallel_iterations=10) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefEnter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "frame_name", (void*) frame_name.c_str(), frame_name.size());
    TFE_OpSetAttrBool(op.get(), "is_constant", (unsigned char)is_constant);
    TFE_OpSetAttrInt(op.get(), "parallel_iterations", parallel_iterations);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RefExit(const Tensor& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefExit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RefIdentity(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefIdentity", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> RefMerge(const std::vector<Tensor>& inputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefMerge", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor RefNextIteration(const Tensor& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefNextIteration", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RefSelect(const Tensor& index, const std::vector<Tensor>& inputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefSelect", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> RefSwitch(const Tensor& data, const Tensor& pred) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RefSwitch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pred.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor RegexFullMatch(const Tensor& input, const Tensor& pattern) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegexFullMatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pattern.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RegexReplace(const Tensor& input, const Tensor& pattern, const Tensor& rewrite, bool replace_global=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegexReplace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pattern.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rewrite.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "replace_global", (unsigned char)replace_global);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RegisterDataset(const Tensor& dataset, const Tensor& address, const Tensor& protocol, int64_t external_state_policy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RegisterDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), address.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), protocol.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Relu(const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Relu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Relu6(const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Relu6", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Relu6Grad(const Tensor& gradients, const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Relu6Grad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReluGrad(const Tensor& gradients, const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RepeatDataset(const Tensor& input_dataset, const Tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RepeatDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> RequantizationRange(const Tensor& input, const Tensor& input_min, const Tensor& input_max, datatype Tinput) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RequantizationRange", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RequantizationRangePerChannel(const Tensor& input, const Tensor& input_min, const Tensor& input_max, float clip_value_max) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RequantizationRangePerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloat(op.get(), "clip_value_max", clip_value_max);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> Requantize(const Tensor& input, const Tensor& input_min, const Tensor& input_max, const Tensor& requested_output_min, const Tensor& requested_output_max, datatype Tinput, datatype out_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Requantize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tinput", Tinput);
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RequantizePerChannel(const Tensor& input, const Tensor& input_min, const Tensor& input_max, const Tensor& requested_output_min, const Tensor& requested_output_max, datatype out_type=static_cast<datatype>(12)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RequantizePerChannel", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_min.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), requested_output_max.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Reshape(const Tensor& input_tensor, const Tensor& shape, datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Reshape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeArea(const Tensor& images, const Tensor& size, bool align_corners=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeArea", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeBicubic(const Tensor& images, const Tensor& size, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBicubic", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeBicubicGrad(const Tensor& grads, const Tensor& original_image, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBicubicGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), original_image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeBilinear(const Tensor& images, const Tensor& size, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBilinear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeBilinearGrad(const Tensor& grads, const Tensor& original_image, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeBilinearGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), original_image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeNearestNeighbor(const Tensor& images, const Tensor& size, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeNearestNeighbor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResizeNearestNeighborGrad(const Tensor& grads, const Tensor& size, bool align_corners=false, bool half_pixel_centers=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResizeNearestNeighborGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "align_corners", (unsigned char)align_corners);
    TFE_OpSetAttrBool(op.get(), "half_pixel_centers", (unsigned char)half_pixel_centers);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ResourceAccumulatorApplyGradient(const Tensor& handle, const Tensor& local_step, const Tensor& gradient, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorApplyGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), local_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor ResourceAccumulatorNumAccumulated(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorNumAccumulated", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ResourceAccumulatorSetGlobalStep(const Tensor& handle, const Tensor& new_global_step) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorSetGlobalStep", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), new_global_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor ResourceAccumulatorTakeGradient(const Tensor& handle, const Tensor& num_required, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceAccumulatorTakeGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_required.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ResourceApplyAdaMax(const Tensor& var, const Tensor& m, const Tensor& v, const Tensor& beta1_power, const Tensor& lr, const Tensor& beta1, const Tensor& beta2, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdaMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAdadelta(const Tensor& var, const Tensor& accum, const Tensor& accum_update, const Tensor& lr, const Tensor& rho, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAdagradDA(const Tensor& var, const Tensor& gradient_accumulator, const Tensor& gradient_squared_accumulator, const Tensor& grad, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& global_step, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAdagradV2(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& epsilon, const Tensor& grad, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAdam(const Tensor& var, const Tensor& m, const Tensor& v, const Tensor& beta1_power, const Tensor& beta2_power, const Tensor& lr, const Tensor& beta1, const Tensor& beta2, const Tensor& epsilon, const Tensor& grad, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdam", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAdamWithAmsgrad(const Tensor& var, const Tensor& m, const Tensor& v, const Tensor& vhat, const Tensor& beta1_power, const Tensor& beta2_power, const Tensor& lr, const Tensor& beta1, const Tensor& beta2, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAdamWithAmsgrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), v.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), vhat.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyAddSign(const Tensor& var, const Tensor& m, const Tensor& lr, const Tensor& alpha, const Tensor& sign_decay, const Tensor& beta, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyAddSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyCenteredRMSProp(const Tensor& var, const Tensor& mg, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyFtrl(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyFtrlV2(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& l2_shrinkage, const Tensor& lr_power, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyGradientDescent(const Tensor& var, const Tensor& alpha, const Tensor& delta, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyKerasMomentum(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& momentum, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyKerasMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyMomentum(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& momentum, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyPowerSign(const Tensor& var, const Tensor& m, const Tensor& lr, const Tensor& logbase, const Tensor& sign_decay, const Tensor& beta, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyPowerSign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), m.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), logbase.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sign_decay.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyProximalAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyProximalGradientDescent(const Tensor& var, const Tensor& alpha, const Tensor& l1, const Tensor& l2, const Tensor& delta, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceApplyRMSProp(const Tensor& var, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor ResourceConditionalAccumulator(datatype dtype, const std::vector<int64_t>& shape, const std::string& container="", const std::string& shared_name="", const std::string& reduction_type="MEAN") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceConditionalAccumulator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "reduction_type", (void*) reduction_type.c_str(), reduction_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResourceCountUpTo(const Tensor& resource, int64_t limit) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceCountUpTo", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "limit", limit);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResourceGather(const Tensor& resource, const Tensor& indices, datatype dtype, datatype Tindices, int64_t batch_dims=0, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrInt(op.get(), "batch_dims", batch_dims);
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ResourceGatherNd(const Tensor& resource, const Tensor& indices, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceGatherNd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ResourceScatterAdd(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterDiv(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterMax(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterMin(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterMul(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterNdAdd(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterNdMax(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterNdMin(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterNdSub(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterNdUpdate(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterNdUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterSub(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceScatterUpdate(const Tensor& resource, const Tensor& indices, const Tensor& updates, datatype dtype, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceScatterUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyAdadelta(const Tensor& var, const Tensor& accum, const Tensor& accum_update, const Tensor& lr, const Tensor& rho, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyAdagradDA(const Tensor& var, const Tensor& gradient_accumulator, const Tensor& gradient_squared_accumulator, const Tensor& grad, const Tensor& indices, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& global_step, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyAdagradV2(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyCenteredRMSProp(const Tensor& var, const Tensor& mg, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyFtrl(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& indices, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyFtrlV2(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& indices, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& l2_shrinkage, const Tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyKerasMomentum(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& indices, const Tensor& momentum, datatype Tindices, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyKerasMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyMomentum(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& indices, const Tensor& momentum, datatype Tindices, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyProximalAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyProximalGradientDescent(const Tensor& var, const Tensor& alpha, const Tensor& l1, const Tensor& l2, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceSparseApplyRMSProp(const Tensor& var, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceSparseApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void ResourceStridedSliceAssign(const Tensor& ref, const Tensor& begin, const Tensor& end, const Tensor& strides, const Tensor& value, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ResourceStridedSliceAssign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Restore(const Tensor& file_pattern, const Tensor& input_tensor_name, datatype dt, int64_t preferred_shard=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Restore", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), file_pattern.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dt", dt);
    TFE_OpSetAttrInt(op.get(), "preferred_shard", preferred_shard);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RestoreSlice(const Tensor& file_pattern, const Tensor& input_tensor_name, const Tensor& shape_and_slice, datatype dt, int64_t preferred_shard=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RestoreSlice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), file_pattern.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_and_slice.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dt", dt);
    TFE_OpSetAttrInt(op.get(), "preferred_shard", preferred_shard);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RestoreV2(const Tensor& prefix, const Tensor& input_tensor_names, const Tensor& shape_and_slices, const std::vector<datatype>& dtypes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RestoreV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), prefix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_and_slices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> RetrieveTPUEmbeddingADAMParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingADAMParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingADAMParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingADAMParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingAdadeltaParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdadeltaParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingAdagradParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingAdagradParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingAdagradParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingCenteredRMSPropParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingCenteredRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingFTRLParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingFTRLParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingFTRLParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingFTRLParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingFrequencyEstimatorParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingFrequencyEstimatorParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingFrequencyEstimatorParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingFrequencyEstimatorParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingMDLAdagradLightParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingMDLAdagradLightParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingMomentumParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingMomentumParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingMomentumParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingMomentumParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingProximalAdagradParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingProximalAdagradParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingProximalYogiParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingProximalYogiParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingProximalYogiParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingProximalYogiParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingRMSPropParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingRMSPropParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor RetrieveTPUEmbeddingStochasticGradientDescentParameters(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingStochasticGradientDescentParameters", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> RetrieveTPUEmbeddingStochasticGradientDescentParametersGradAccumDebug(int64_t num_shards, int64_t shard_id, int64_t table_id=-1, const std::string& table_name="", const std::string& config="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RetrieveTPUEmbeddingStochasticGradientDescentParametersGradAccumDebug", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_shards", num_shards);
    TFE_OpSetAttrInt(op.get(), "shard_id", shard_id);
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrString(op.get(), "table_name", (void*) table_name.c_str(), table_name.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Reverse(const Tensor& input_tensor, const Tensor& dims) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Reverse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dims.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReverseSequence(const Tensor& input, const Tensor& seq_lengths, int64_t seq_dim, int64_t batch_dim=0, datatype Tlen=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReverseSequence", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seq_lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "seq_dim", seq_dim);
    TFE_OpSetAttrInt(op.get(), "batch_dim", batch_dim);
    TFE_OpSetAttrType(op.get(), "Tlen", Tlen);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ReverseV2(const Tensor& input_tensor, const Tensor& axis, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ReverseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RightShift(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RightShift", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Rint(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Rint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RngReadAndSkip(const Tensor& resource, const Tensor& alg, const Tensor& delta) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RngReadAndSkip", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void RngSkip(const Tensor& resource, const Tensor& algorithm, const Tensor& delta) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RngSkip", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Roll(const Tensor& input, const Tensor& shift, const Tensor& axis, datatype Tshift, datatype Taxis) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Roll", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shift.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tshift", Tshift);
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Round(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Round", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Rsqrt(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Rsqrt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor RsqrtGrad(const Tensor& y, const Tensor& dy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "RsqrtGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SampleDistortedBoundingBox(const Tensor& image_size, const Tensor& bounding_boxes, const std::vector<float>& aspect_ratio_range, const std::vector<float>& area_range, int64_t seed=0, int64_t seed2=0, float min_object_covered=1.0000e-01, int64_t max_attempts=100, bool use_image_if_no_bounding_boxes=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SampleDistortedBoundingBox", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bounding_boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "aspect_ratio_range", aspect_ratio_range.data(), aspect_ratio_range.size());
    TFE_OpSetAttrFloatList(op.get(), "area_range", area_range.data(), area_range.size());
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrFloat(op.get(), "min_object_covered", min_object_covered);
    TFE_OpSetAttrInt(op.get(), "max_attempts", max_attempts);
    TFE_OpSetAttrBool(op.get(), "use_image_if_no_bounding_boxes", (unsigned char)use_image_if_no_bounding_boxes);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SampleDistortedBoundingBoxV2(const Tensor& image_size, const Tensor& bounding_boxes, const Tensor& min_object_covered, const std::vector<float>& aspect_ratio_range, const std::vector<float>& area_range, int64_t seed=0, int64_t seed2=0, int64_t max_attempts=100, bool use_image_if_no_bounding_boxes=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SampleDistortedBoundingBoxV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bounding_boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_object_covered.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrFloatList(op.get(), "aspect_ratio_range", aspect_ratio_range.data(), aspect_ratio_range.size());
    TFE_OpSetAttrFloatList(op.get(), "area_range", area_range.data(), area_range.size());
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrInt(op.get(), "max_attempts", max_attempts);
    TFE_OpSetAttrBool(op.get(), "use_image_if_no_bounding_boxes", (unsigned char)use_image_if_no_bounding_boxes);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SamplingDataset(const Tensor& input_dataset, const Tensor& rate, const Tensor& seed, const Tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SamplingDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void Save(const Tensor& filename, const Tensor& input_tensor_names, const std::vector<Tensor>& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Save", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), data.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void SaveSlices(const Tensor& filename, const Tensor& input_tensor_names, const Tensor& shapes_and_slices, const std::vector<Tensor>& data) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SaveSlices", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shapes_and_slices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> data_handles; data_handles.reserve(data.size());
    std::transform(data.begin(), data.end(), std::back_inserter(data_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), data_handles.data(), data.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void SaveV2(const Tensor& prefix, const Tensor& input_tensor_names, const Tensor& shape_and_slices, const std::vector<Tensor>& tensors, const std::vector<datatype>& dtypes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SaveV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), prefix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor_names.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_and_slices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> tensors_handles; tensors_handles.reserve(tensors.size());
    std::transform(tensors.begin(), tensors.end(), std::back_inserter(tensors_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), tensors_handles.data(), tensors.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor ScalarSummary(const Tensor& tags, const Tensor& values) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScalarSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tags.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScaleAndTranslate(const Tensor& images, const Tensor& size, const Tensor& scale, const Tensor& translation, const std::string& kernel_type="lanczos3", bool antialias=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScaleAndTranslate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), images.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), translation.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "kernel_type", (void*) kernel_type.c_str(), kernel_type.size());
    TFE_OpSetAttrBool(op.get(), "antialias", (unsigned char)antialias);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScaleAndTranslateGrad(const Tensor& grads, const Tensor& original_image, const Tensor& scale, const Tensor& translation, const std::string& kernel_type="lanczos3", bool antialias=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScaleAndTranslateGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grads.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), original_image.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), scale.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), translation.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "kernel_type", (void*) kernel_type.c_str(), kernel_type.size());
    TFE_OpSetAttrBool(op.get(), "antialias", (unsigned char)antialias);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterAdd(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterDiv(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterMax(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterMin(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterMul(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNd(const Tensor& indices, const Tensor& updates, const Tensor& shape, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNdAdd(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNdMax(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNdMin(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNdNonAliasingAdd(const Tensor& input, const Tensor& indices, const Tensor& updates, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdNonAliasingAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNdSub(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterNdUpdate(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterNdUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterSub(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ScatterUpdate(const Tensor& ref, const Tensor& indices, const Tensor& updates, datatype Tindices, bool use_locking=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ScatterUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SdcaFprint(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaFprint", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SdcaOptimizer(const std::vector<Tensor>& sparse_example_indices, const std::vector<Tensor>& sparse_feature_indices, const std::vector<Tensor>& sparse_feature_values, const std::vector<Tensor>& dense_features, const Tensor& example_weights, const Tensor& example_labels, const std::vector<Tensor>& sparse_indices, const std::vector<Tensor>& sparse_weights, const std::vector<Tensor>& dense_weights, const Tensor& example_state_data, const std::string& loss_type, float l1, float l2, int64_t num_loss_partitions, int64_t num_inner_iterations, bool adaptative=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaOptimizer", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sparse_example_indices_handles; sparse_example_indices_handles.reserve(sparse_example_indices.size());
    std::transform(sparse_example_indices.begin(), sparse_example_indices.end(), std::back_inserter(sparse_example_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_example_indices_handles.data(), sparse_example_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_indices_handles; sparse_feature_indices_handles.reserve(sparse_feature_indices.size());
    std::transform(sparse_feature_indices.begin(), sparse_feature_indices.end(), std::back_inserter(sparse_feature_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_feature_indices_handles.data(), sparse_feature_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_values_handles; sparse_feature_values_handles.reserve(sparse_feature_values.size());
    std::transform(sparse_feature_values.begin(), sparse_feature_values.end(), std::back_inserter(sparse_feature_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_feature_values_handles.data(), sparse_feature_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_features_handles; dense_features_handles.reserve(dense_features.size());
    std::transform(dense_features.begin(), dense_features.end(), std::back_inserter(dense_features_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_features_handles.data(), dense_features.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_labels.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_indices_handles; sparse_indices_handles.reserve(sparse_indices.size());
    std::transform(sparse_indices.begin(), sparse_indices.end(), std::back_inserter(sparse_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_indices_handles.data(), sparse_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_weights_handles; sparse_weights_handles.reserve(sparse_weights.size());
    std::transform(sparse_weights.begin(), sparse_weights.end(), std::back_inserter(sparse_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_weights_handles.data(), sparse_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_weights_handles; dense_weights_handles.reserve(dense_weights.size());
    std::transform(dense_weights.begin(), dense_weights.end(), std::back_inserter(dense_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_weights_handles.data(), dense_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_state_data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "loss_type", (void*) loss_type.c_str(), loss_type.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features", sparse_example_indices.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features_with_values", sparse_feature_values.size());
    TFE_OpSetAttrInt(op.get(), "num_dense_features", dense_features.size());
    TFE_OpSetAttrFloat(op.get(), "l1", l1);
    TFE_OpSetAttrFloat(op.get(), "l2", l2);
    TFE_OpSetAttrInt(op.get(), "num_loss_partitions", num_loss_partitions);
    TFE_OpSetAttrInt(op.get(), "num_inner_iterations", num_inner_iterations);
    TFE_OpSetAttrBool(op.get(), "adaptative", (unsigned char)adaptative);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SdcaOptimizerV2(const std::vector<Tensor>& sparse_example_indices, const std::vector<Tensor>& sparse_feature_indices, const std::vector<Tensor>& sparse_feature_values, const std::vector<Tensor>& dense_features, const Tensor& example_weights, const Tensor& example_labels, const std::vector<Tensor>& sparse_indices, const std::vector<Tensor>& sparse_weights, const std::vector<Tensor>& dense_weights, const Tensor& example_state_data, const std::string& loss_type, float l1, float l2, int64_t num_loss_partitions, int64_t num_inner_iterations, bool adaptive=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaOptimizerV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> sparse_example_indices_handles; sparse_example_indices_handles.reserve(sparse_example_indices.size());
    std::transform(sparse_example_indices.begin(), sparse_example_indices.end(), std::back_inserter(sparse_example_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_example_indices_handles.data(), sparse_example_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_indices_handles; sparse_feature_indices_handles.reserve(sparse_feature_indices.size());
    std::transform(sparse_feature_indices.begin(), sparse_feature_indices.end(), std::back_inserter(sparse_feature_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_feature_indices_handles.data(), sparse_feature_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_feature_values_handles; sparse_feature_values_handles.reserve(sparse_feature_values.size());
    std::transform(sparse_feature_values.begin(), sparse_feature_values.end(), std::back_inserter(sparse_feature_values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_feature_values_handles.data(), sparse_feature_values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_features_handles; dense_features_handles.reserve(dense_features.size());
    std::transform(dense_features.begin(), dense_features.end(), std::back_inserter(dense_features_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_features_handles.data(), dense_features.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_labels.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_indices_handles; sparse_indices_handles.reserve(sparse_indices.size());
    std::transform(sparse_indices.begin(), sparse_indices.end(), std::back_inserter(sparse_indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_indices_handles.data(), sparse_indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> sparse_weights_handles; sparse_weights_handles.reserve(sparse_weights.size());
    std::transform(sparse_weights.begin(), sparse_weights.end(), std::back_inserter(sparse_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), sparse_weights_handles.data(), sparse_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_weights_handles; dense_weights_handles.reserve(dense_weights.size());
    std::transform(dense_weights.begin(), dense_weights.end(), std::back_inserter(dense_weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_weights_handles.data(), dense_weights.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), example_state_data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "loss_type", (void*) loss_type.c_str(), loss_type.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features", sparse_example_indices.size());
    TFE_OpSetAttrInt(op.get(), "num_sparse_features_with_values", sparse_feature_values.size());
    TFE_OpSetAttrInt(op.get(), "num_dense_features", dense_features.size());
    TFE_OpSetAttrFloat(op.get(), "l1", l1);
    TFE_OpSetAttrFloat(op.get(), "l2", l2);
    TFE_OpSetAttrInt(op.get(), "num_loss_partitions", num_loss_partitions);
    TFE_OpSetAttrInt(op.get(), "num_inner_iterations", num_inner_iterations);
    TFE_OpSetAttrBool(op.get(), "adaptive", (unsigned char)adaptive);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline void SdcaShrinkL1(const std::vector<Tensor>& weights, float l1, float l2) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SdcaShrinkL1", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> weights_handles; weights_handles.reserve(weights.size());
    std::transform(weights.begin(), weights.end(), std::back_inserter(weights_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), weights_handles.data(), weights.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_features", weights.size());
    TFE_OpSetAttrFloat(op.get(), "l1", l1);
    TFE_OpSetAttrFloat(op.get(), "l2", l2);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor SegmentMax(const Tensor& data, const Tensor& segment_ids, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SegmentMean(const Tensor& data, const Tensor& segment_ids, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMean", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SegmentMin(const Tensor& data, const Tensor& segment_ids, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SegmentProd(const Tensor& data, const Tensor& segment_ids, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentProd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SegmentSum(const Tensor& data, const Tensor& segment_ids, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SegmentSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Select(const Tensor& condition, const Tensor& t, const Tensor& e) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Select", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), condition.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), e.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SelectV2(const Tensor& condition, const Tensor& t, const Tensor& e) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SelectV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), condition.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), t.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), e.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SelfAdjointEig(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SelfAdjointEig", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SelfAdjointEigV2(const Tensor& input, bool compute_v=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SelfAdjointEigV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_v", (unsigned char)compute_v);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Selu(const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Selu", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SeluGrad(const Tensor& gradients, const Tensor& outputs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SeluGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), outputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void Send(const Tensor& input_tensor, const std::string& tensor_name, const std::string& send_device, int64_t send_device_incarnation, const std::string& recv_device, bool client_terminated=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Send", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "tensor_name", (void*) tensor_name.c_str(), tensor_name.size());
    TFE_OpSetAttrString(op.get(), "send_device", (void*) send_device.c_str(), send_device.size());
    TFE_OpSetAttrInt(op.get(), "send_device_incarnation", send_device_incarnation);
    TFE_OpSetAttrString(op.get(), "recv_device", (void*) recv_device.c_str(), recv_device.size());
    TFE_OpSetAttrBool(op.get(), "client_terminated", (unsigned char)client_terminated);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void SendTPUEmbeddingGradients(const std::vector<Tensor>& inputs, const std::vector<Tensor>& learning_rates, const std::string& config) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SendTPUEmbeddingGradients", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> learning_rates_handles; learning_rates_handles.reserve(learning_rates.size());
    std::transform(learning_rates.begin(), learning_rates.end(), std::back_inserter(learning_rates_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), learning_rates_handles.data(), learning_rates.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrString(op.get(), "config", (void*) config.c_str(), config.size());
    TFE_OpSetAttrInt(op.get(), "NN", learning_rates.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor SerializeIterator(const Tensor& resource_handle, int64_t external_state_policy=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeIterator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "external_state_policy", external_state_policy);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SerializeManySparse(const Tensor& sparse_indices, const Tensor& sparse_values, const Tensor& sparse_shape, datatype out_type=static_cast<datatype>(7)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeManySparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SerializeSparse(const Tensor& sparse_indices, const Tensor& sparse_values, const Tensor& sparse_shape, datatype out_type=static_cast<datatype>(7)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SerializeTensor(const Tensor& input_tensor) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SerializeTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SetSize(const Tensor& set_indices, const Tensor& set_values, const Tensor& set_shape, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SetSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SetStatsAggregatorDataset(const Tensor& input_dataset, const Tensor& stats_aggregator, const Tensor& tag, const Tensor& counter_prefix, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SetStatsAggregatorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stats_aggregator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter_prefix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Shape(const Tensor& input, datatype out_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Shape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShapeN(const std::vector<Tensor>& input, datatype out_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShapeN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_handles; input_handles.reserve(input.size());
    std::transform(input.begin(), input.end(), std::back_inserter(input_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_handles.data(), input.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", input.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShardDataset(const Tensor& input_dataset, const Tensor& num_shards, const Tensor& index, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool require_non_empty=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShardDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_shards.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "require_non_empty", (unsigned char)require_non_empty);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShardedFilename(const Tensor& basename, const Tensor& shard, const Tensor& num_shards) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShardedFilename", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), basename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shard.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_shards.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShardedFilespec(const Tensor& basename, const Tensor& num_shards) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShardedFilespec", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), basename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_shards.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShuffleAndRepeatDataset(const Tensor& input_dataset, const Tensor& buffer_size, const Tensor& seed, const Tensor& seed2, const Tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleAndRepeatDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShuffleAndRepeatDatasetV2(const Tensor& input_dataset, const Tensor& buffer_size, const Tensor& seed, const Tensor& seed2, const Tensor& count, const Tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleAndRepeatDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShuffleDataset(const Tensor& input_dataset, const Tensor& buffer_size, const Tensor& seed, const Tensor& seed2, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShuffleDatasetV2(const Tensor& input_dataset, const Tensor& buffer_size, const Tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleDatasetV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ShuffleDatasetV3(const Tensor& input_dataset, const Tensor& buffer_size, const Tensor& seed, const Tensor& seed2, const Tensor& seed_generator, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, bool reshuffle_each_iteration=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShuffleDatasetV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed_generator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "reshuffle_each_iteration", (unsigned char)reshuffle_each_iteration);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void ShutdownDistributedTPU() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ShutdownDistributedTPU", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Sigmoid(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sigmoid", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SigmoidGrad(const Tensor& y, const Tensor& dy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SigmoidGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Sign(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Sin(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Sinh(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sinh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Size(const Tensor& input, datatype out_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Size", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SkipDataset(const Tensor& input_dataset, const Tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SkipDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SleepDataset(const Tensor& input_dataset, const Tensor& sleep_microseconds, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SleepDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sleep_microseconds.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Slice(const Tensor& input, const Tensor& begin, const Tensor& size, datatype Index) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Slice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SlidingWindowDataset(const Tensor& input_dataset, const Tensor& window_size, const Tensor& window_shift, const Tensor& window_stride, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SlidingWindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_shift.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), window_stride.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Snapshot(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Snapshot", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SnapshotDataset(const Tensor& input_dataset, const Tensor& path, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes, const std::string& compression="", const std::string& reader_path_prefix="", const std::string& writer_path_prefix="", int64_t shard_size_bytes=10737418240, int64_t pending_snapshot_expiry_seconds=86400, int64_t num_reader_threads=1, int64_t reader_buffer_size=1, int64_t num_writer_threads=1, int64_t writer_buffer_size=1, bool shuffle_on_read=false, int64_t seed=0, int64_t seed2=0, const std::string& mode="auto", const std::string& snapshot_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SnapshotDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), path.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "compression", (void*) compression.c_str(), compression.size());
    TFE_OpSetAttrString(op.get(), "reader_path_prefix", (void*) reader_path_prefix.c_str(), reader_path_prefix.size());
    TFE_OpSetAttrString(op.get(), "writer_path_prefix", (void*) writer_path_prefix.c_str(), writer_path_prefix.size());
    TFE_OpSetAttrInt(op.get(), "shard_size_bytes", shard_size_bytes);
    TFE_OpSetAttrInt(op.get(), "pending_snapshot_expiry_seconds", pending_snapshot_expiry_seconds);
    TFE_OpSetAttrInt(op.get(), "num_reader_threads", num_reader_threads);
    TFE_OpSetAttrInt(op.get(), "reader_buffer_size", reader_buffer_size);
    TFE_OpSetAttrInt(op.get(), "num_writer_threads", num_writer_threads);
    TFE_OpSetAttrInt(op.get(), "writer_buffer_size", writer_buffer_size);
    TFE_OpSetAttrBool(op.get(), "shuffle_on_read", (unsigned char)shuffle_on_read);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);
    TFE_OpSetAttrString(op.get(), "mode", (void*) mode.c_str(), mode.size());
    TFE_OpSetAttrString(op.get(), "snapshot_name", (void*) snapshot_name.c_str(), snapshot_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SobolSample(const Tensor& dim, const Tensor& num_results, const Tensor& skip, datatype dtype=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SobolSample", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_results.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), skip.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Softmax(const Tensor& logits) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Softmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SoftmaxCrossEntropyWithLogits(const Tensor& features, const Tensor& labels) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SoftmaxCrossEntropyWithLogits", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Softplus(const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Softplus", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SoftplusGrad(const Tensor& gradients, const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SoftplusGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Softsign(const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Softsign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SoftsignGrad(const Tensor& gradients, const Tensor& features) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SoftsignGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), gradients.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SpaceToBatch(const Tensor& input, const Tensor& paddings, int64_t block_size, datatype Tpaddings=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SpaceToBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SpaceToBatchND(const Tensor& input, const Tensor& block_shape, const Tensor& paddings, datatype Tblock_shape=static_cast<datatype>(3), datatype Tpaddings=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SpaceToBatchND", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), block_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), paddings.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tblock_shape", Tblock_shape);
    TFE_OpSetAttrType(op.get(), "Tpaddings", Tpaddings);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SpaceToDepth(const Tensor& input, int64_t block_size, const std::string& data_format="NHWC") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SpaceToDepth", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "block_size", block_size);
    TFE_OpSetAttrString(op.get(), "data_format", (void*) data_format.c_str(), data_format.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void SparseAccumulatorApplyGradient(const Tensor& handle, const Tensor& local_step, const Tensor& gradient_indices, const Tensor& gradient_values, const Tensor& gradient_shape, datatype dtype, bool has_known_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAccumulatorApplyGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), local_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrBool(op.get(), "has_known_shape", (unsigned char)has_known_shape);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline std::vector<Tensor> SparseAccumulatorTakeGradient(const Tensor& handle, const Tensor& num_required, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAccumulatorTakeGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_required.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseAdd(const Tensor& a_indices, const Tensor& a_values, const Tensor& a_shape, const Tensor& b_indices, const Tensor& b_values, const Tensor& b_shape, const Tensor& thresh, datatype Treal) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), thresh.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Treal", Treal);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseAddGrad(const Tensor& backprop_val_grad, const Tensor& a_indices, const Tensor& b_indices, const Tensor& sum_indices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseAddGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), backprop_val_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sum_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseApplyAdadelta(const Tensor& var, const Tensor& accum, const Tensor& accum_update, const Tensor& lr, const Tensor& rho, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdadelta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum_update.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyAdagradDA(const Tensor& var, const Tensor& gradient_accumulator, const Tensor& gradient_squared_accumulator, const Tensor& grad, const Tensor& indices, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& global_step, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdagradDA", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), gradient_squared_accumulator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), global_step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyAdagradV2(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false, bool update_slots=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyAdagradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "update_slots", (unsigned char)update_slots);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyCenteredRMSProp(const Tensor& var, const Tensor& mg, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyCenteredRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyFtrl(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& indices, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyFtrl", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyFtrlV2(const Tensor& var, const Tensor& accum, const Tensor& linear, const Tensor& grad, const Tensor& indices, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& l2_shrinkage, const Tensor& lr_power, datatype Tindices, bool use_locking=false, bool multiply_linear_by_lr=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyFtrlV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), linear.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2_shrinkage.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr_power.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "multiply_linear_by_lr", (unsigned char)multiply_linear_by_lr);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyMomentum(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& grad, const Tensor& indices, const Tensor& momentum, datatype Tindices, bool use_locking=false, bool use_nesterov=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyMomentum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);
    TFE_OpSetAttrBool(op.get(), "use_nesterov", (unsigned char)use_nesterov);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyProximalAdagrad(const Tensor& var, const Tensor& accum, const Tensor& lr, const Tensor& l1, const Tensor& l2, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyProximalAdagrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), accum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyProximalGradientDescent(const Tensor& var, const Tensor& alpha, const Tensor& l1, const Tensor& l2, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyProximalGradientDescent", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l1.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), l2.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseApplyRMSProp(const Tensor& var, const Tensor& ms, const Tensor& mom, const Tensor& lr, const Tensor& rho, const Tensor& momentum, const Tensor& epsilon, const Tensor& grad, const Tensor& indices, datatype Tindices, bool use_locking=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseApplyRMSProp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), var.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), ms.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), mom.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lr.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rho.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), momentum.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), epsilon.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "use_locking", (unsigned char)use_locking);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseBincount(const Tensor& indices, const Tensor& values, const Tensor& dense_shape, const Tensor& size, const Tensor& weights, datatype Tidx, bool binary_output=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseBincount", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseConcat(const std::vector<Tensor>& indices, const std::vector<Tensor>& values, const std::vector<Tensor>& shapes, int64_t concat_dim) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "concat_dim", concat_dim);
    TFE_OpSetAttrInt(op.get(), "N", indices.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseConditionalAccumulator(datatype dtype, const std::vector<int64_t>& shape, const std::string& container="", const std::string& shared_name="", const std::string& reduction_type="MEAN") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseConditionalAccumulator", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "reduction_type", (void*) reduction_type.c_str(), reduction_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseCountSparseOutput(const Tensor& indices, const Tensor& values, const Tensor& dense_shape, const Tensor& weights, bool binary_output, datatype output_type, int64_t minlength=-1, int64_t maxlength=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCountSparseOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), weights.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "binary_output", (unsigned char)binary_output);
    TFE_OpSetAttrType(op.get(), "output_type", output_type);
    TFE_OpSetAttrInt(op.get(), "minlength", minlength);
    TFE_OpSetAttrInt(op.get(), "maxlength", maxlength);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseCross(const std::vector<Tensor>& indices, const std::vector<Tensor>& values, const std::vector<Tensor>& shapes, const std::vector<Tensor>& dense_inputs, bool hashed_output, int64_t num_buckets, int64_t hash_key, const std::vector<datatype>& sparse_types, const std::vector<datatype>& dense_types, datatype out_type, datatype internal_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCross", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), dense_inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());
    TFE_OpSetAttrBool(op.get(), "hashed_output", (unsigned char)hashed_output);
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrInt(op.get(), "hash_key", hash_key);
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), dense_types.size());
    TFE_OpSetAttrType(op.get(), "out_type", out_type);
    TFE_OpSetAttrType(op.get(), "internal_type", internal_type);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseCrossHashed(const std::vector<Tensor>& indices, const std::vector<Tensor>& values, const std::vector<Tensor>& shapes, const std::vector<Tensor>& dense_inputs, const Tensor& num_buckets, const Tensor& strong_hash, const Tensor& salt, const std::vector<datatype>& sparse_types, const std::vector<datatype>& dense_types) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCrossHashed", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), dense_inputs.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_buckets.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strong_hash.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), salt.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), dense_types.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseCrossV2(const std::vector<Tensor>& indices, const std::vector<Tensor>& values, const std::vector<Tensor>& shapes, const std::vector<Tensor>& dense_inputs, const Tensor& sep, const std::vector<datatype>& sparse_types, const std::vector<datatype>& dense_types) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseCrossV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> indices_handles; indices_handles.reserve(indices.size());
    std::transform(indices.begin(), indices.end(), std::back_inserter(indices_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), indices_handles.data(), indices.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> shapes_handles; shapes_handles.reserve(shapes.size());
    std::transform(shapes.begin(), shapes.end(), std::back_inserter(shapes_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), shapes_handles.data(), shapes.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<TFE_TensorHandle*> dense_inputs_handles; dense_inputs_handles.reserve(dense_inputs.size());
    std::transform(dense_inputs.begin(), dense_inputs.end(), std::back_inserter(dense_inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), dense_inputs_handles.data(), dense_inputs.size(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sep.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", indices.size());
    TFE_OpSetAttrTypeList(op.get(), "sparse_types", reinterpret_cast<const enum TF_DataType *>(sparse_types.data()), sparse_types.size());
    TFE_OpSetAttrTypeList(op.get(), "dense_types", reinterpret_cast<const enum TF_DataType *>(dense_types.data()), dense_types.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseDenseCwiseAdd(const Tensor& sp_indices, const Tensor& sp_values, const Tensor& sp_shape, const Tensor& dense) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseDenseCwiseAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseDenseCwiseDiv(const Tensor& sp_indices, const Tensor& sp_values, const Tensor& sp_shape, const Tensor& dense) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseDenseCwiseDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseDenseCwiseMul(const Tensor& sp_indices, const Tensor& sp_values, const Tensor& sp_shape, const Tensor& dense) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseDenseCwiseMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseFillEmptyRows(const Tensor& indices, const Tensor& values, const Tensor& dense_shape, const Tensor& default_value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseFillEmptyRows", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 4;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseFillEmptyRowsGrad(const Tensor& reverse_index_map, const Tensor& grad_values) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseFillEmptyRowsGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), reverse_index_map.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseMatMul(const Tensor& a, const Tensor& b, bool transpose_a=false, bool transpose_b=false, bool a_is_sparse=false, bool b_is_sparse=false, datatype Ta=static_cast<datatype>(1), datatype Tb=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "a_is_sparse", (unsigned char)a_is_sparse);
    TFE_OpSetAttrBool(op.get(), "b_is_sparse", (unsigned char)b_is_sparse);
    TFE_OpSetAttrType(op.get(), "Ta", Ta);
    TFE_OpSetAttrType(op.get(), "Tb", Tb);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixAdd(const Tensor& a, const Tensor& b, const Tensor& alpha, const Tensor& beta) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), beta.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixMatMul(const Tensor& a, const Tensor& b, bool transpose_a=false, bool transpose_b=false, bool adjoint_a=false, bool adjoint_b=false, bool transpose_output=false, bool conjugate_output=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "adjoint_a", (unsigned char)adjoint_a);
    TFE_OpSetAttrBool(op.get(), "adjoint_b", (unsigned char)adjoint_b);
    TFE_OpSetAttrBool(op.get(), "transpose_output", (unsigned char)transpose_output);
    TFE_OpSetAttrBool(op.get(), "conjugate_output", (unsigned char)conjugate_output);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixMul(const Tensor& a, const Tensor& b) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixNNZ(const Tensor& sparse_matrix) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixNNZ", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_matrix.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixOrderingAMD(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixOrderingAMD", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixSoftmax(const Tensor& logits, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSoftmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixSoftmaxGrad(const Tensor& softmax, const Tensor& grad_softmax, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSoftmaxGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), softmax.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad_softmax.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixSparseCholesky(const Tensor& input, const Tensor& permutation, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSparseCholesky", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), permutation.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixSparseMatMul(const Tensor& a, const Tensor& b, datatype type, bool transpose_a=false, bool transpose_b=false, bool adjoint_a=false, bool adjoint_b=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixSparseMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);
    TFE_OpSetAttrBool(op.get(), "transpose_a", (unsigned char)transpose_a);
    TFE_OpSetAttrBool(op.get(), "transpose_b", (unsigned char)transpose_b);
    TFE_OpSetAttrBool(op.get(), "adjoint_a", (unsigned char)adjoint_a);
    TFE_OpSetAttrBool(op.get(), "adjoint_b", (unsigned char)adjoint_b);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixTranspose(const Tensor& input, datatype type, bool conjugate=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixTranspose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);
    TFE_OpSetAttrBool(op.get(), "conjugate", (unsigned char)conjugate);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseMatrixZeros(const Tensor& dense_shape, datatype type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseMatrixZeros", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), dense_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "type", type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseReduceMax(const Tensor& input_indices, const Tensor& input_values, const Tensor& input_shape, const Tensor& reduction_axes, bool keep_dims=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseReduceMaxSparse(const Tensor& input_indices, const Tensor& input_values, const Tensor& input_shape, const Tensor& reduction_axes, bool keep_dims=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceMaxSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseReduceSum(const Tensor& input_indices, const Tensor& input_values, const Tensor& input_shape, const Tensor& reduction_axes, bool keep_dims=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseReduceSumSparse(const Tensor& input_indices, const Tensor& input_values, const Tensor& input_shape, const Tensor& reduction_axes, bool keep_dims=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReduceSumSparse", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_axes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseReorder(const Tensor& input_indices, const Tensor& input_values, const Tensor& input_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReorder", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseReshape(const Tensor& input_indices, const Tensor& input_shape, const Tensor& new_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseReshape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), new_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseSegmentMean(const Tensor& data, const Tensor& indices, const Tensor& segment_ids, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMean", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentMeanGrad(const Tensor& grad, const Tensor& indices, const Tensor& segment_ids, const Tensor& output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMeanGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_dim0.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentMeanWithNumSegments(const Tensor& data, const Tensor& indices, const Tensor& segment_ids, const Tensor& num_segments, datatype Tidx=static_cast<datatype>(3), datatype Tnumsegments=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentMeanWithNumSegments", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentSqrtN(const Tensor& data, const Tensor& indices, const Tensor& segment_ids, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtN", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentSqrtNGrad(const Tensor& grad, const Tensor& indices, const Tensor& segment_ids, const Tensor& output_dim0, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtNGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_dim0.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentSqrtNWithNumSegments(const Tensor& data, const Tensor& indices, const Tensor& segment_ids, const Tensor& num_segments, datatype Tidx=static_cast<datatype>(3), datatype Tnumsegments=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSqrtNWithNumSegments", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentSum(const Tensor& data, const Tensor& indices, const Tensor& segment_ids, datatype Tidx=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSegmentSumWithNumSegments(const Tensor& data, const Tensor& indices, const Tensor& segment_ids, const Tensor& num_segments, datatype Tidx=static_cast<datatype>(3), datatype Tnumsegments=static_cast<datatype>(3), datatype Tsegmentids=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSegmentSumWithNumSegments", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);
    TFE_OpSetAttrType(op.get(), "Tsegmentids", Tsegmentids);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseSlice(const Tensor& indices, const Tensor& values, const Tensor& shape, const Tensor& start, const Tensor& size) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSlice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), start.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseSliceGrad(const Tensor& backprop_val_grad, const Tensor& input_indices, const Tensor& input_start, const Tensor& output_indices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSliceGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), backprop_val_grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_start.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseSoftmax(const Tensor& sp_indices, const Tensor& sp_values, const Tensor& sp_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSoftmax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sp_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sp_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseSoftmaxCrossEntropyWithLogits(const Tensor& features, const Tensor& labels, datatype Tlabels=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSoftmaxCrossEntropyWithLogits", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), features.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), labels.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tlabels", Tlabels);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseSparseMaximum(const Tensor& a_indices, const Tensor& a_values, const Tensor& a_shape, const Tensor& b_indices, const Tensor& b_values, const Tensor& b_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSparseMaximum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseSparseMinimum(const Tensor& a_indices, const Tensor& a_values, const Tensor& a_shape, const Tensor& b_indices, const Tensor& b_values, const Tensor& b_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSparseMinimum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> SparseSplit(const Tensor& split_dim, const Tensor& indices, const Tensor& values, const Tensor& shape, int64_t num_split) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), split_dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_split", num_split);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor SparseTensorDenseAdd(const Tensor& a_indices, const Tensor& a_values, const Tensor& a_shape, const Tensor& b, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorDenseAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseTensorDenseMatMul(const Tensor& a_indices, const Tensor& a_values, const Tensor& a_shape, const Tensor& b, datatype Tindices=static_cast<datatype>(9), bool adjoint_a=false, bool adjoint_b=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorDenseMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), a_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), a_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "adjoint_a", (unsigned char)adjoint_a);
    TFE_OpSetAttrBool(op.get(), "adjoint_b", (unsigned char)adjoint_b);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseTensorSliceDataset(const Tensor& indices, const Tensor& values, const Tensor& dense_shape, datatype Tvalues) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorSliceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tvalues", Tvalues);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseTensorToCSRSparseMatrix(const Tensor& indices, const Tensor& values, const Tensor& dense_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseTensorToCSRSparseMatrix", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dense_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SparseToDense(const Tensor& sparse_indices, const Tensor& output_shape, const Tensor& sparse_values, const Tensor& default_value, datatype Tindices, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseToDense", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), output_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sparse_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), default_value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> SparseToSparseSetOperation(const Tensor& set1_indices, const Tensor& set1_values, const Tensor& set1_shape, const Tensor& set2_indices, const Tensor& set2_values, const Tensor& set2_shape, const std::string& set_operation, bool validate_indices=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SparseToSparseSetOperation", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), set1_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set1_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set1_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), set2_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "set_operation", (void*) set_operation.c_str(), set_operation.size());
    TFE_OpSetAttrBool(op.get(), "validate_indices", (unsigned char)validate_indices);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Spence(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Spence", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Split(const Tensor& split_dim, const Tensor& value, int64_t num_split) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Split", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), split_dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_split", num_split);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SplitV(const Tensor& value, const Tensor& size_splits, const Tensor& split_dim, int64_t num_split, datatype Tlen=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SplitV", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size_splits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), split_dim.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_split", num_split);
    TFE_OpSetAttrType(op.get(), "Tlen", Tlen);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SqlDataset(const Tensor& driver_name, const Tensor& data_source_name, const Tensor& query, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SqlDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), driver_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), data_source_name.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), query.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Sqrt(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sqrt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SqrtGrad(const Tensor& y, const Tensor& dy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SqrtGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Square(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Square", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SquaredDifference(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SquaredDifference", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Squeeze(const Tensor& input, const std::vector<int64_t>& squeeze_dims) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Squeeze", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrIntList(op.get(), "squeeze_dims", squeeze_dims.data(), squeeze_dims.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Stack(datatype elem_type, const std::string& stack_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Stack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);
    TFE_OpSetAttrString(op.get(), "stack_name", (void*) stack_name.c_str(), stack_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void StackClose(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void StackCloseV2(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackCloseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor StackPop(const Tensor& handle, datatype elem_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPop", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StackPopV2(const Tensor& handle, datatype elem_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPopV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StackPush(const Tensor& handle, const Tensor& elem, bool swap_memory=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPush", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), elem.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "swap_memory", (unsigned char)swap_memory);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StackPushV2(const Tensor& handle, const Tensor& elem, bool swap_memory=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackPushV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), elem.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "swap_memory", (unsigned char)swap_memory);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StackV2(const Tensor& max_size, datatype elem_type, const std::string& stack_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StackV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), max_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "elem_type", elem_type);
    TFE_OpSetAttrString(op.get(), "stack_name", (void*) stack_name.c_str(), stack_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void Stage(const std::vector<Tensor>& values, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Stage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> values_handles; values_handles.reserve(values.size());
    std::transform(values.begin(), values.end(), std::back_inserter(values_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), values_handles.data(), values.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void StageClear(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StageClear", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor StagePeek(const Tensor& index, const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StagePeek", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StageSize(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StageSize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulRandomBinomial(const Tensor& resource, const Tensor& algorithm, const Tensor& shape, const Tensor& counts, const Tensor& probs, datatype S, datatype dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulRandomBinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counts.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), probs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulStandardNormal(const Tensor& resource, const Tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulStandardNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulStandardNormalV2(const Tensor& resource, const Tensor& algorithm, const Tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulStandardNormalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulTruncatedNormal(const Tensor& resource, const Tensor& algorithm, const Tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulUniform(const Tensor& resource, const Tensor& algorithm, const Tensor& shape, datatype dtype=static_cast<datatype>(1), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulUniform", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulUniformFullInt(const Tensor& resource, const Tensor& algorithm, const Tensor& shape, datatype dtype=static_cast<datatype>(23), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulUniformFullInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatefulUniformInt(const Tensor& resource, const Tensor& algorithm, const Tensor& shape, const Tensor& minval, const Tensor& maxval, datatype dtype=static_cast<datatype>(9), datatype shape_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatefulUniformInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), algorithm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "shape_dtype", shape_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessMultinomial(const Tensor& logits, const Tensor& num_samples, const Tensor& seed, datatype Tseed=static_cast<datatype>(9), datatype output_dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessMultinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), logits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_samples.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrType(op.get(), "output_dtype", output_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessParameterizedTruncatedNormal(const Tensor& shape, const Tensor& seed, const Tensor& means, const Tensor& stddevs, const Tensor& minvals, const Tensor& maxvals, datatype S, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessParameterizedTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), means.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stddevs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minvals.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxvals.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomBinomial(const Tensor& shape, const Tensor& seed, const Tensor& counts, const Tensor& probs, datatype S, datatype Tseed=static_cast<datatype>(9), datatype dtype=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomBinomial", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counts.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), probs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "S", S);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomGammaV2(const Tensor& shape, const Tensor& seed, const Tensor& alpha, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGammaV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alpha.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomGetAlg() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGetAlg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> StatelessRandomGetKeyCounter(const Tensor& seed, datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGetKeyCounter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> StatelessRandomGetKeyCounterAlg(const Tensor& seed, datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomGetKeyCounterAlg", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor StatelessRandomNormal(const Tensor& shape, const Tensor& seed, datatype dtype=static_cast<datatype>(1), datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomNormalV2(const Tensor& shape, const Tensor& key, const Tensor& counter, const Tensor& alg, datatype dtype=static_cast<datatype>(1), datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomNormalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomPoisson(const Tensor& shape, const Tensor& seed, const Tensor& lam, datatype Rtype, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomPoisson", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lam.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Rtype", Rtype);
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomUniform(const Tensor& shape, const Tensor& seed, datatype dtype=static_cast<datatype>(1), datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniform", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomUniformFullInt(const Tensor& shape, const Tensor& seed, datatype dtype=static_cast<datatype>(23), datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformFullInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomUniformFullIntV2(const Tensor& shape, const Tensor& key, const Tensor& counter, const Tensor& alg, datatype dtype=static_cast<datatype>(23), datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformFullIntV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomUniformInt(const Tensor& shape, const Tensor& seed, const Tensor& minval, const Tensor& maxval, datatype dtype, datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformInt", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomUniformIntV2(const Tensor& shape, const Tensor& key, const Tensor& counter, const Tensor& alg, const Tensor& minval, const Tensor& maxval, datatype dtype, datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformIntV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), minval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maxval.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessRandomUniformV2(const Tensor& shape, const Tensor& key, const Tensor& counter, const Tensor& alg, datatype dtype=static_cast<datatype>(1), datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessRandomUniformV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> StatelessSampleDistortedBoundingBox(const Tensor& image_size, const Tensor& bounding_boxes, const Tensor& min_object_covered, const Tensor& seed, datatype Tseed, const std::vector<float>& aspect_ratio_range, const std::vector<float>& area_range, int64_t max_attempts=100, bool use_image_if_no_bounding_boxes=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessSampleDistortedBoundingBox", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), image_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bounding_boxes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), min_object_covered.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);
    TFE_OpSetAttrFloatList(op.get(), "aspect_ratio_range", aspect_ratio_range.data(), aspect_ratio_range.size());
    TFE_OpSetAttrFloatList(op.get(), "area_range", area_range.data(), area_range.size());
    TFE_OpSetAttrInt(op.get(), "max_attempts", max_attempts);
    TFE_OpSetAttrBool(op.get(), "use_image_if_no_bounding_boxes", (unsigned char)use_image_if_no_bounding_boxes);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor StatelessTruncatedNormal(const Tensor& shape, const Tensor& seed, datatype dtype=static_cast<datatype>(1), datatype Tseed=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessTruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), seed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tseed", Tseed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatelessTruncatedNormalV2(const Tensor& shape, const Tensor& key, const Tensor& counter, const Tensor& alg, datatype dtype=static_cast<datatype>(1), datatype Tshape=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatelessTruncatedNormalV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), key.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), counter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), alg.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrType(op.get(), "Tshape", Tshape);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StaticRegexFullMatch(const Tensor& input, const std::string& pattern) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StaticRegexFullMatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "pattern", (void*) pattern.c_str(), pattern.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StaticRegexReplace(const Tensor& input, const std::string& pattern, const std::string& rewrite, bool replace_global=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StaticRegexReplace", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "pattern", (void*) pattern.c_str(), pattern.size());
    TFE_OpSetAttrString(op.get(), "rewrite", (void*) rewrite.c_str(), rewrite.size());
    TFE_OpSetAttrBool(op.get(), "replace_global", (unsigned char)replace_global);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatsAggregatorHandle(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StatsAggregatorHandleV2(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorHandleV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void StatsAggregatorSetSummaryWriter(const Tensor& stats_aggregator, const Tensor& summary) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorSetSummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), stats_aggregator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summary.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor StatsAggregatorSummary(const Tensor& iterator) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StatsAggregatorSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), iterator.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StopGradient(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StopGradient", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StridedSlice(const Tensor& input, const Tensor& begin, const Tensor& end, const Tensor& strides, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StridedSlice", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StridedSliceAssign(const Tensor& ref, const Tensor& begin, const Tensor& end, const Tensor& strides, const Tensor& value, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StridedSliceAssign", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), ref.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StridedSliceGrad(const Tensor& shape, const Tensor& begin, const Tensor& end, const Tensor& strides, const Tensor& dy, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StridedSliceGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringFormat(const std::vector<Tensor>& inputs, const std::string& template_arg="%s", const std::string& placeholder="%s", int64_t summarize=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringFormat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "template", (void*) template_arg.c_str(), template_arg.size());
    TFE_OpSetAttrString(op.get(), "placeholder", (void*) placeholder.c_str(), placeholder.size());
    TFE_OpSetAttrInt(op.get(), "summarize", summarize);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringJoin(const std::vector<Tensor>& inputs, const std::string& separator="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringJoin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringLength(const Tensor& input, const std::string& unit="BYTE") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringLength", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "unit", (void*) unit.c_str(), unit.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringLower(const Tensor& input, const std::string& encoding="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringLower", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "encoding", (void*) encoding.c_str(), encoding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> StringNGrams(const Tensor& data, const Tensor& data_splits, const std::string& separator, const std::vector<int64_t>& ngram_widths, const std::string& left_pad, const std::string& right_pad, int64_t pad_width, bool preserve_short_sequences, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringNGrams", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), data_splits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());
    TFE_OpSetAttrIntList(op.get(), "ngram_widths", ngram_widths.data(), ngram_widths.size());
    TFE_OpSetAttrString(op.get(), "left_pad", (void*) left_pad.c_str(), left_pad.size());
    TFE_OpSetAttrString(op.get(), "right_pad", (void*) right_pad.c_str(), right_pad.size());
    TFE_OpSetAttrInt(op.get(), "pad_width", pad_width);
    TFE_OpSetAttrBool(op.get(), "preserve_short_sequences", (unsigned char)preserve_short_sequences);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> StringSplit(const Tensor& input, const Tensor& delimiter, bool skip_empty=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), delimiter.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "skip_empty", (unsigned char)skip_empty);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> StringSplitV2(const Tensor& input, const Tensor& sep, int64_t maxsplit=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringSplitV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sep.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "maxsplit", maxsplit);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor StringStrip(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringStrip", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringToHashBucket(const Tensor& string_input_tensor, int64_t num_buckets) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToHashBucket", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringToHashBucketFast(const Tensor& input, int64_t num_buckets) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToHashBucketFast", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringToHashBucketStrong(const Tensor& input, int64_t num_buckets, const std::vector<int64_t>& key) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToHashBucketStrong", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_buckets", num_buckets);
    TFE_OpSetAttrIntList(op.get(), "key", key.data(), key.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringToNumber(const Tensor& string_input_tensor, datatype out_type=static_cast<datatype>(1)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringToNumber", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), string_input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor StringUpper(const Tensor& input, const std::string& encoding="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "StringUpper", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "encoding", (void*) encoding.c_str(), encoding.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Sub(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Substr(const Tensor& input, const Tensor& pos, const Tensor& len, const std::string& unit="BYTE") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Substr", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pos.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), len.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "unit", (void*) unit.c_str(), unit.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Sum(const Tensor& input, const Tensor& reduction_indices, bool keep_dims=false, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Sum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), reduction_indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "keep_dims", (unsigned char)keep_dims);
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor SummaryWriter(const std::string& shared_name="", const std::string& container="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "SummaryWriter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> Svd(const Tensor& input, bool compute_uv=true, bool full_matrices=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Svd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "compute_uv", (unsigned char)compute_uv);
    TFE_OpSetAttrBool(op.get(), "full_matrices", (unsigned char)full_matrices);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> Switch(const Tensor& data, const Tensor& pred) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Switch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), pred.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TFRecordDataset(const Tensor& filenames, const Tensor& compression_type, const Tensor& buffer_size) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TFRecordReader(const std::string& container="", const std::string& shared_name="", const std::string& compression_type="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TFRecordReaderV2(const std::string& container="", const std::string& shared_name="", const std::string& compression_type="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TFRecordReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());
    TFE_OpSetAttrString(op.get(), "compression_type", (void*) compression_type.c_str(), compression_type.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TPUCompilationResult() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUCompilationResult", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TPUEmbeddingActivations(const Tensor& embedding_variable, const Tensor& sliced_activations, int64_t table_id, int64_t lookup_id) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUEmbeddingActivations", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), embedding_variable.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sliced_activations.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "table_id", table_id);
    TFE_OpSetAttrInt(op.get(), "lookup_id", lookup_id);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TPUOrdinalSelector() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUOrdinalSelector", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void TPUReplicateMetadata(int64_t num_replicas, const std::vector<int64_t>& device_assignment, const std::vector<int64_t>& computation_shape, const std::vector< std::string>& host_compute_core, const std::vector< std::string>& padding_map, int64_t num_cores_per_replica=1, const std::string& topology="", bool use_tpu=true, const std::string& step_marker_location="STEP_MARK_AT_ENTRY", bool allow_soft_placement=false, bool use_spmd_for_xla_partitioning=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUReplicateMetadata", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_replicas", num_replicas);
    TFE_OpSetAttrIntList(op.get(), "device_assignment", device_assignment.data(), device_assignment.size());
    TFE_OpSetAttrIntList(op.get(), "computation_shape", computation_shape.data(), computation_shape.size());
    
    std::vector<std::size_t> host_compute_core_sizes; host_compute_core_sizes.reserve(host_compute_core.size());
    std::transform(host_compute_core.begin(), host_compute_core.end(), std::back_inserter(host_compute_core_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "host_compute_core", reinterpret_cast<const void *const *>(host_compute_core.data()), host_compute_core_sizes.data(), host_compute_core.size());
    
    
    std::vector<std::size_t> padding_map_sizes; padding_map_sizes.reserve(padding_map.size());
    std::transform(padding_map.begin(), padding_map.end(), std::back_inserter(padding_map_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "padding_map", reinterpret_cast<const void *const *>(padding_map.data()), padding_map_sizes.data(), padding_map.size());
    
    TFE_OpSetAttrInt(op.get(), "num_cores_per_replica", num_cores_per_replica);
    TFE_OpSetAttrString(op.get(), "topology", (void*) topology.c_str(), topology.size());
    TFE_OpSetAttrBool(op.get(), "use_tpu", (unsigned char)use_tpu);
    TFE_OpSetAttrString(op.get(), "step_marker_location", (void*) step_marker_location.c_str(), step_marker_location.size());
    TFE_OpSetAttrBool(op.get(), "allow_soft_placement", (unsigned char)allow_soft_placement);
    TFE_OpSetAttrBool(op.get(), "use_spmd_for_xla_partitioning", (unsigned char)use_spmd_for_xla_partitioning);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor TPUReplicatedInput(const std::vector<Tensor>& inputs, bool is_mirrored_variable=false, int64_t index=-1, bool is_packed=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUReplicatedInput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> inputs_handles; inputs_handles.reserve(inputs.size());
    std::transform(inputs.begin(), inputs.end(), std::back_inserter(inputs_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), inputs_handles.data(), inputs.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "N", inputs.size());
    TFE_OpSetAttrBool(op.get(), "is_mirrored_variable", (unsigned char)is_mirrored_variable);
    TFE_OpSetAttrInt(op.get(), "index", index);
    TFE_OpSetAttrBool(op.get(), "is_packed", (unsigned char)is_packed);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TPUReplicatedOutput(const Tensor& input, int64_t num_replicas) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TPUReplicatedOutput", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_replicas", num_replicas);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TakeDataset(const Tensor& input_dataset, const Tensor& count, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TakeDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), count.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TakeManySparseFromTensorsMap(const Tensor& sparse_handles, datatype dtype, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TakeManySparseFromTensorsMap", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sparse_handles.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Tan(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Tan", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Tanh(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Tanh", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TanhGrad(const Tensor& y, const Tensor& dy) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TanhGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dy.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TemporaryVariable(const std::vector<int64_t>& shape, datatype dtype, const std::string& var_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TemporaryVariable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "var_name", (void*) var_name.c_str(), var_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArray(const Tensor& size, datatype dtype, const std::vector<int64_t>& element_shape, bool dynamic_size=false, bool clear_after_read=true, const std::string& tensor_array_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArray", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "dynamic_size", (unsigned char)dynamic_size);
    TFE_OpSetAttrBool(op.get(), "clear_after_read", (unsigned char)clear_after_read);
    TFE_OpSetAttrString(op.get(), "tensor_array_name", (void*) tensor_array_name.c_str(), tensor_array_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void TensorArrayClose(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayClose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void TensorArrayCloseV2(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayCloseV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void TensorArrayCloseV3(const Tensor& handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayCloseV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline std::vector<Tensor> TensorArrayConcat(const Tensor& handle, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape_except0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape_except0", element_shape_except0.data(), element_shape_except0.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> TensorArrayConcatV2(const Tensor& handle, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape_except0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayConcatV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape_except0", element_shape_except0.data(), element_shape_except0.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> TensorArrayConcatV3(const Tensor& handle, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape_except0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayConcatV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape_except0", element_shape_except0.data(), element_shape_except0.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TensorArrayGather(const Tensor& handle, const Tensor& indices, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayGatherV2(const Tensor& handle, const Tensor& indices, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGatherV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayGatherV3(const Tensor& handle, const Tensor& indices, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGatherV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayGrad(const Tensor& handle, const Tensor& flow_in, const std::string& source) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayGradV2(const Tensor& handle, const Tensor& flow_in, const std::string& source) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGradV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TensorArrayGradV3(const Tensor& handle, const Tensor& flow_in, const std::string& source) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGradV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> TensorArrayGradWithShape(const Tensor& handle, const Tensor& flow_in, const Tensor& shape_to_prepend, const std::string& source) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayGradWithShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shape_to_prepend.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "source", (void*) source.c_str(), source.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TensorArrayPack(const Tensor& handle, const Tensor& flow_in, datatype dtype, const std::vector<int64_t>& element_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayPack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayRead(const Tensor& handle, const Tensor& index, const Tensor& flow_in, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayRead", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayReadV2(const Tensor& handle, const Tensor& index, const Tensor& flow_in, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayReadV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayReadV3(const Tensor& handle, const Tensor& index, const Tensor& flow_in, datatype dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayReadV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayScatter(const Tensor& handle, const Tensor& indices, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayScatter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayScatterV2(const Tensor& handle, const Tensor& indices, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayScatterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayScatterV3(const Tensor& handle, const Tensor& indices, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayScatterV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArraySize(const Tensor& handle, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArraySizeV2(const Tensor& handle, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySizeV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArraySizeV3(const Tensor& handle, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySizeV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArraySplit(const Tensor& handle, const Tensor& value, const Tensor& lengths, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArraySplitV2(const Tensor& handle, const Tensor& value, const Tensor& lengths, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySplitV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArraySplitV3(const Tensor& handle, const Tensor& value, const Tensor& lengths, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArraySplitV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayUnpack(const Tensor& handle, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayUnpack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayV2(const Tensor& size, datatype dtype, const std::vector<int64_t>& element_shape, bool dynamic_size=false, bool clear_after_read=true, const std::string& tensor_array_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "dynamic_size", (unsigned char)dynamic_size);
    TFE_OpSetAttrBool(op.get(), "clear_after_read", (unsigned char)clear_after_read);
    TFE_OpSetAttrString(op.get(), "tensor_array_name", (void*) tensor_array_name.c_str(), tensor_array_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TensorArrayV3(const Tensor& size, datatype dtype, const std::vector<int64_t>& element_shape, bool dynamic_size=false, bool clear_after_read=true, bool identical_element_shapes=false, const std::string& tensor_array_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrBool(op.get(), "dynamic_size", (unsigned char)dynamic_size);
    TFE_OpSetAttrBool(op.get(), "clear_after_read", (unsigned char)clear_after_read);
    TFE_OpSetAttrBool(op.get(), "identical_element_shapes", (unsigned char)identical_element_shapes);
    TFE_OpSetAttrString(op.get(), "tensor_array_name", (void*) tensor_array_name.c_str(), tensor_array_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TensorArrayWrite(const Tensor& handle, const Tensor& index, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayWrite", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayWriteV2(const Tensor& handle, const Tensor& index, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayWriteV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorArrayWriteV3(const Tensor& handle, const Tensor& index, const Tensor& value, const Tensor& flow_in) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorArrayWriteV3", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), flow_in.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorDataset(const std::vector<Tensor>& components, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), Toutput_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TensorListConcat(const Tensor& input_handle, datatype element_dtype, const std::vector<int64_t>& element_shape) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListConcat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    
    TFE_OpSetAttrShape(op.get(), "element_shape", element_shape.data(), element_shape.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TensorListConcatLists(const Tensor& input_a, const Tensor& input_b, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListConcatLists", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_a.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_b.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TensorListConcatV2(const Tensor& input_handle, const Tensor& element_shape, const Tensor& leading_dims, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListConcatV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), leading_dims.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TensorListElementShape(const Tensor& input_handle, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListElementShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListFromTensor(const Tensor& input_tensor, const Tensor& element_shape, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListFromTensor", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListGather(const Tensor& input_handle, const Tensor& indices, const Tensor& element_shape, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListGather", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListGetItem(const Tensor& input_handle, const Tensor& index, const Tensor& element_shape, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListGetItem", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListLength(const Tensor& input_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListLength", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TensorListPopBack(const Tensor& input_handle, const Tensor& element_shape, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListPopBack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor TensorListPushBack(const Tensor& input_handle, const Tensor& input_tensor, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListPushBack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListPushBackBatch(const Tensor& input_handles, const Tensor& input_tensor, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListPushBackBatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handles.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListReserve(const Tensor& element_shape, const Tensor& num_elements, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListReserve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_elements.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListResize(const Tensor& input_handle, const Tensor& size) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListResize", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListScatter(const Tensor& input_tensor, const Tensor& indices, const Tensor& element_shape, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListScatter", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListScatterIntoExistingList(const Tensor& input_handle, const Tensor& input_tensor, const Tensor& indices, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListScatterIntoExistingList", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListScatterV2(const Tensor& input_tensor, const Tensor& indices, const Tensor& element_shape, const Tensor& num_elements, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListScatterV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_elements.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListSetItem(const Tensor& input_handle, const Tensor& index, const Tensor& item, datatype element_dtype) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListSetItem", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), item.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListSplit(const Tensor& input_tensor, const Tensor& element_shape, const Tensor& lengths, datatype element_dtype, datatype shape_type) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListSplit", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), lengths.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrType(op.get(), "shape_type", shape_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorListStack(const Tensor& input_handle, const Tensor& element_shape, datatype element_dtype, int64_t num_elements=-1) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorListStack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), element_shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "element_dtype", element_dtype);
    TFE_OpSetAttrInt(op.get(), "num_elements", num_elements);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorScatterAdd(const Tensor& input_tensor, const Tensor& indices, const Tensor& updates, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterAdd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorScatterMax(const Tensor& input_tensor, const Tensor& indices, const Tensor& updates, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorScatterMin(const Tensor& input_tensor, const Tensor& indices, const Tensor& updates, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorScatterSub(const Tensor& input_tensor, const Tensor& indices, const Tensor& updates, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterSub", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorScatterUpdate(const Tensor& input_tensor, const Tensor& indices, const Tensor& updates, datatype Tindices) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorScatterUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), updates.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorSliceDataset(const std::vector<Tensor>& components, const std::vector<datatype>& Toutput_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorSliceDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> components_handles; components_handles.reserve(components.size());
    std::transform(components.begin(), components.end(), std::back_inserter(components_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), components_handles.data(), components.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "Toutput_types", reinterpret_cast<const enum TF_DataType *>(Toutput_types.data()), Toutput_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorStridedSliceUpdate(const Tensor& input, const Tensor& begin, const Tensor& end, const Tensor& strides, const Tensor& value, datatype Index, int64_t begin_mask=0, int64_t end_mask=0, int64_t ellipsis_mask=0, int64_t new_axis_mask=0, int64_t shrink_axis_mask=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorStridedSliceUpdate", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), begin.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), end.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), strides.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Index", Index);
    TFE_OpSetAttrInt(op.get(), "begin_mask", begin_mask);
    TFE_OpSetAttrInt(op.get(), "end_mask", end_mask);
    TFE_OpSetAttrInt(op.get(), "ellipsis_mask", ellipsis_mask);
    TFE_OpSetAttrInt(op.get(), "new_axis_mask", new_axis_mask);
    TFE_OpSetAttrInt(op.get(), "shrink_axis_mask", shrink_axis_mask);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorSummary(const Tensor& input_tensor, const std::vector< std::string>& labels, const std::string& description="", const std::string& display_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    
    std::vector<std::size_t> labels_sizes; labels_sizes.reserve(labels.size());
    std::transform(labels.begin(), labels.end(), std::back_inserter(labels_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "labels", reinterpret_cast<const void *const *>(labels.data()), labels_sizes.data(), labels.size());
    
    TFE_OpSetAttrString(op.get(), "description", (void*) description.c_str(), description.size());
    TFE_OpSetAttrString(op.get(), "display_name", (void*) display_name.c_str(), display_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TensorSummaryV2(const Tensor& tag, const Tensor& input_tensor, const Tensor& serialized_summary_metadata) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TensorSummaryV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), serialized_summary_metadata.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TextLineDataset(const Tensor& filenames, const Tensor& compression_type, const Tensor& buffer_size) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TextLineDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filenames.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), compression_type.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), buffer_size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TextLineReader(int64_t skip_header_lines=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TextLineReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "skip_header_lines", skip_header_lines);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TextLineReaderV2(int64_t skip_header_lines=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TextLineReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "skip_header_lines", skip_header_lines);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ThreadPoolDataset(const Tensor& input_dataset, const Tensor& thread_pool, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ThreadPoolDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), thread_pool.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ThreadPoolHandle(int64_t num_threads, const std::string& display_name, int64_t max_intra_op_parallelism=1, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ThreadPoolHandle", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_threads", num_threads);
    TFE_OpSetAttrString(op.get(), "display_name", (void*) display_name.c_str(), display_name.size());
    TFE_OpSetAttrInt(op.get(), "max_intra_op_parallelism", max_intra_op_parallelism);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> ThreadUnsafeUnigramCandidateSampler(const Tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ThreadUnsafeUnigramCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Tile(const Tensor& input, const Tensor& multiples, datatype Tmultiples=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Tile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), multiples.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tmultiples", Tmultiples);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TileGrad(const Tensor& input, const Tensor& multiples) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TileGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), multiples.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Timestamp() {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Timestamp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ToBool(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ToBool", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> TopK(const Tensor& input, int64_t k, bool sorted=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TopK", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "k", k);
    TFE_OpSetAttrBool(op.get(), "sorted", (unsigned char)sorted);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> TopKV2(const Tensor& input, const Tensor& k, bool sorted=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TopKV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), k.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "sorted", (unsigned char)sorted);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Transpose(const Tensor& x, const Tensor& perm, datatype Tperm=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Transpose", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), perm.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tperm", Tperm);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TridiagonalMatMul(const Tensor& superdiag, const Tensor& maindiag, const Tensor& subdiag, const Tensor& rhs) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TridiagonalMatMul", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), superdiag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), maindiag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), subdiag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TridiagonalSolve(const Tensor& diagonals, const Tensor& rhs, bool partial_pivoting=true) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TridiagonalSolve", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), diagonals.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), rhs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrBool(op.get(), "partial_pivoting", (unsigned char)partial_pivoting);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TruncateDiv(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TruncateDiv", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TruncateMod(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TruncateMod", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor TruncatedNormal(const Tensor& shape, datatype dtype, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "TruncatedNormal", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), shape.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Unbatch(const Tensor& batched_input_tensor, const Tensor& batch_index, const Tensor& id, int64_t timeout_micros, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unbatch", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), batched_input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), id.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "timeout_micros", timeout_micros);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnbatchDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnbatchDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnbatchGrad(const Tensor& original_input, const Tensor& batch_index, const Tensor& grad, const Tensor& id, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnbatchGrad", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), original_input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), batch_index.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), grad.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), id.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UncompressElement(const Tensor& compressed, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UncompressElement", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), compressed.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> UnicodeDecode(const Tensor& input, const std::string& input_encoding, const std::string& errors="replace", int64_t replacement_char=65533, bool replace_control_characters=false, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeDecode", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "input_encoding", (void*) input_encoding.c_str(), input_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrBool(op.get(), "replace_control_characters", (unsigned char)replace_control_characters);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> UnicodeDecodeWithOffsets(const Tensor& input, const std::string& input_encoding, const std::string& errors="replace", int64_t replacement_char=65533, bool replace_control_characters=false, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeDecodeWithOffsets", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "input_encoding", (void*) input_encoding.c_str(), input_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrBool(op.get(), "replace_control_characters", (unsigned char)replace_control_characters);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor UnicodeEncode(const Tensor& input_values, const Tensor& input_splits, const std::string& output_encoding, const std::string& errors="replace", int64_t replacement_char=65533, datatype Tsplits=static_cast<datatype>(9)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeEncode", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_splits.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "output_encoding", (void*) output_encoding.c_str(), output_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrType(op.get(), "Tsplits", Tsplits);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnicodeScript(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeScript", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnicodeTranscode(const Tensor& input, const std::string& input_encoding, const std::string& output_encoding, const std::string& errors="replace", int64_t replacement_char=65533, bool replace_control_characters=false) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnicodeTranscode", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "input_encoding", (void*) input_encoding.c_str(), input_encoding.size());
    TFE_OpSetAttrString(op.get(), "output_encoding", (void*) output_encoding.c_str(), output_encoding.size());
    TFE_OpSetAttrString(op.get(), "errors", (void*) errors.c_str(), errors.size());
    TFE_OpSetAttrInt(op.get(), "replacement_char", replacement_char);
    TFE_OpSetAttrBool(op.get(), "replace_control_characters", (unsigned char)replace_control_characters);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> UniformCandidateSampler(const Tensor& true_classes, int64_t num_true, int64_t num_sampled, bool unique, int64_t range_max, int64_t seed=0, int64_t seed2=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniformCandidateSampler", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), true_classes.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num_true", num_true);
    TFE_OpSetAttrInt(op.get(), "num_sampled", num_sampled);
    TFE_OpSetAttrBool(op.get(), "unique", (unsigned char)unique);
    TFE_OpSetAttrInt(op.get(), "range_max", range_max);
    TFE_OpSetAttrInt(op.get(), "seed", seed);
    TFE_OpSetAttrInt(op.get(), "seed2", seed2);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> Unique(const Tensor& x, datatype out_idx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unique", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor UniqueDataset(const Tensor& input_dataset, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline std::vector<Tensor> UniqueV2(const Tensor& x, const Tensor& axis, datatype Taxis=static_cast<datatype>(9), datatype out_idx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    constexpr auto __kNumOutputs = 2;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> UniqueWithCounts(const Tensor& x, datatype out_idx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueWithCounts", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline std::vector<Tensor> UniqueWithCountsV2(const Tensor& x, const Tensor& axis, datatype Taxis=static_cast<datatype>(9), datatype out_idx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UniqueWithCountsV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), axis.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Taxis", Taxis);
    TFE_OpSetAttrType(op.get(), "out_idx", out_idx);

    // Execute Op
    constexpr auto __kNumOutputs = 3;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensors[__kNumOutputs] = {nullptr,};
    TFE_Execute(op.get(), __output_tensors, &__num_outputs, context::get_status());
    status_check(context::get_status());

    auto __outputs = std::vector<Tensor> {};
    __outputs.reserve(__num_outputs);
    for (auto i = 0; i < __num_outputs; ++i) {
        __outputs.emplace_back(Tensor {__output_tensors[i]});
    }

    return __outputs;
}

inline Tensor Unpack(const Tensor& value, int64_t num, int64_t axis=0) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unpack", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "num", num);
    TFE_OpSetAttrInt(op.get(), "axis", axis);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnravelIndex(const Tensor& indices, const Tensor& dims, datatype Tidx=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnravelIndex", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), indices.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), dims.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tidx", Tidx);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnsortedSegmentJoin(const Tensor& inputs, const Tensor& segment_ids, const Tensor& num_segments, datatype Tindices, const std::string& separator="", datatype Tnumsegments=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentJoin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrString(op.get(), "separator", (void*) separator.c_str(), separator.size());
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnsortedSegmentMax(const Tensor& data, const Tensor& segment_ids, const Tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentMax", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnsortedSegmentMin(const Tensor& data, const Tensor& segment_ids, const Tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentMin", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnsortedSegmentProd(const Tensor& data, const Tensor& segment_ids, const Tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentProd", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnsortedSegmentSum(const Tensor& data, const Tensor& segment_ids, const Tensor& num_segments, datatype Tindices, datatype Tnumsegments=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnsortedSegmentSum", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), data.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), segment_ids.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), num_segments.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "Tindices", Tindices);
    TFE_OpSetAttrType(op.get(), "Tnumsegments", Tnumsegments);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Unstage(const std::vector<datatype>& dtypes, int64_t capacity=0, int64_t memory_limit=0, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Unstage", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "dtypes", reinterpret_cast<const enum TF_DataType *>(dtypes.data()), dtypes.size());
    TFE_OpSetAttrInt(op.get(), "capacity", capacity);
    TFE_OpSetAttrInt(op.get(), "memory_limit", memory_limit);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UnwrapDatasetVariant(const Tensor& input_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UnwrapDatasetVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor UpperBound(const Tensor& sorted_inputs, const Tensor& values, datatype out_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "UpperBound", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), sorted_inputs.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor VarHandleOp(datatype dtype, const std::vector<int64_t>& shape, const std::vector< std::string>& allowed_devices, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VarHandleOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    
    std::vector<std::size_t> allowed_devices_sizes; allowed_devices_sizes.reserve(allowed_devices.size());
    std::transform(allowed_devices.begin(), allowed_devices.end(), std::back_inserter(allowed_devices_sizes), [](const auto& s) { return s.size();});
    TFE_OpSetAttrStringList(op.get(), "allowed_devices", reinterpret_cast<const void *const *>(allowed_devices.data()), allowed_devices_sizes.data(), allowed_devices.size());
    
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor VarIsInitializedOp(const Tensor& resource) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VarIsInitializedOp", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), resource.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Variable(const std::vector<int64_t>& shape, datatype dtype, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Variable", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor VariableShape(const Tensor& input, datatype out_type=static_cast<datatype>(3)) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VariableShape", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrType(op.get(), "out_type", out_type);

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor VariableV2(const std::vector<int64_t>& shape, datatype dtype, const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "VariableV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    
    TFE_OpSetAttrShape(op.get(), "shape", shape.data(), shape.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrType(op.get(), "dtype", dtype);
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Where(const Tensor& input) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Where", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor WholeFileReader(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WholeFileReader", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor WholeFileReaderV2(const std::string& container="", const std::string& shared_name="") {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WholeFileReaderV2", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    

    // Attributes
    TFE_OpSetAttrString(op.get(), "container", (void*) container.c_str(), container.size());
    TFE_OpSetAttrString(op.get(), "shared_name", (void*) shared_name.c_str(), shared_name.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor WindowDataset(const Tensor& input_dataset, const Tensor& size, const Tensor& shift, const Tensor& stride, const Tensor& drop_remainder, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WindowDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_dataset.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), size.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), shift.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), stride.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), drop_remainder.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor WorkerHeartbeat(const Tensor& request) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WorkerHeartbeat", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), request.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor WrapDatasetVariant(const Tensor& input_handle) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WrapDatasetVariant", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), input_handle.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline void WriteAudioSummary(const Tensor& writer, const Tensor& step, const Tensor& tag, const Tensor& input_tensor, const Tensor& sample_rate, int64_t max_outputs=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteAudioSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), sample_rate.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_outputs", max_outputs);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteFile(const Tensor& filename, const Tensor& contents) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteFile", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), filename.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), contents.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteGraphSummary(const Tensor& writer, const Tensor& step, const Tensor& input_tensor) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteGraphSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteHistogramSummary(const Tensor& writer, const Tensor& step, const Tensor& tag, const Tensor& values) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteHistogramSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), values.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteImageSummary(const Tensor& writer, const Tensor& step, const Tensor& tag, const Tensor& input_tensor, const Tensor& bad_color, int64_t max_images=3) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteImageSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), bad_color.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrInt(op.get(), "max_images", max_images);

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteRawProtoSummary(const Tensor& writer, const Tensor& step, const Tensor& input_tensor) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteRawProtoSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteScalarSummary(const Tensor& writer, const Tensor& step, const Tensor& tag, const Tensor& value) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteScalarSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), value.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline void WriteSummary(const Tensor& writer, const Tensor& step, const Tensor& input_tensor, const Tensor& tag, const Tensor& summary_metadata) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "WriteSummary", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), writer.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), step.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), input_tensor.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), tag.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), summary_metadata.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 0;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());
}

inline Tensor Xdivy(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Xdivy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Xlog1py(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Xlog1py", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Xlogy(const Tensor& x, const Tensor& y) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Xlogy", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), y.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ZerosLike(const Tensor& x) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ZerosLike", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor Zeta(const Tensor& x, const Tensor& q) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "Zeta", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    TFE_OpAddInput(op.get(), x.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    
    
    TFE_OpAddInput(op.get(), q.get_eager_handle().get(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

inline Tensor ZipDataset(const std::vector<Tensor>& input_datasets, const std::vector<datatype>& output_types, const std::vector< std::vector<int64_t>>& output_shapes) {
    // Define Op
    std::unique_ptr<TFE_Op, decltype(&TFE_DeleteOp)> op(TFE_NewOp(context::get_context(), "ZipDataset", context::get_status()), &TFE_DeleteOp);
    status_check(context::get_status());

    // Required input arguments
    
    std::vector<TFE_TensorHandle*> input_datasets_handles; input_datasets_handles.reserve(input_datasets.size());
    std::transform(input_datasets.begin(), input_datasets.end(), std::back_inserter(input_datasets_handles), [](const auto& t) { return t.get_eager_handle().get();});
    TFE_OpAddInputList(op.get(), input_datasets_handles.data(), input_datasets.size(), context::get_status());
    status_check(context::get_status());
    

    // Attributes
    TFE_OpSetAttrTypeList(op.get(), "output_types", reinterpret_cast<const enum TF_DataType *>(output_types.data()), output_types.size());
    
    std::vector<const int64_t*> output_shapes_values; output_shapes_values.reserve(output_shapes.size());
    std::vector<int> output_shapes_ndims; output_shapes_ndims.reserve(output_shapes.size());
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_values), [](const auto& v) { return v.data();});
    std::transform(output_shapes.begin(), output_shapes.end(), std::back_inserter(output_shapes_ndims), [](const auto& v) { return v.size();});
    TFE_OpSetAttrShapeList(op.get(), "output_shapes", output_shapes_values.data(), output_shapes_ndims.data(), output_shapes.size(), context::get_status());
    status_check(context::get_status());
    
    TFE_OpSetAttrInt(op.get(), "N", input_datasets.size());

    // Execute Op
    constexpr auto __kNumOutputs = 1;
    auto __num_outputs = __kNumOutputs;
    TFE_TensorHandle* __output_tensor = nullptr;
    TFE_Execute(op.get(), &__output_tensor, &__num_outputs, context::get_status());
    status_check(context::get_status());

    return Tensor {__output_tensor};
}

}  // cppflow::ops

#endif

